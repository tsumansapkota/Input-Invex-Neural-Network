{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, os, pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "import mylibrary.nnlib as tnn\n",
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data():\n",
    "    global train_data, train_label\n",
    "    randidx = random.sample(range(len(train_label)), k=len(train_label))\n",
    "    train_data = train_data[randidx]\n",
    "    train_label = train_label[randidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_seeds = [147, 258, 369]\n",
    "# network_seeds = [369]\n",
    "network_seed = 369\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "actf = nn.LeakyReLU\n",
    "# actf = nn.ELU\n",
    "\n",
    "learning_rate = 0.005\n",
    "lambda_ = 2\n",
    "criterion = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "use_mixup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_OneClass_Balanced(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label, class_index):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.class_index = class_index\n",
    "        \n",
    "        mask = (label==class_index)\n",
    "        self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self.class_data = torch.nonzero(mask).reshape(-1)\n",
    "        self.other_data = torch.nonzero(~mask).reshape(-1)\n",
    "        \n",
    "        random.seed(network_seed)\n",
    "        self._shuffle_data_()\n",
    "        self.count = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2*len(self.class_data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "#         randidx = np.random.permutation(len(self.other_data))\n",
    "        randidx = random.sample(range(len(self.other_data)), k=len(self.other_data))\n",
    "        self.other_data = self.other_data[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.class_data):\n",
    "            idx = self.class_data[idx]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            idx = self.other_data[idx-len(self.class_data)]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "            self.count += 1\n",
    "            if self.count >= len(self.class_data): \n",
    "                self._shuffle_data_()\n",
    "                self.count = 0\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "# test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_all = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "# test_loader_all = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # img, lbl = train_dataset[11010]\n",
    "# img, lbl = test_dataset[10]\n",
    "# print(lbl)\n",
    "# plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:200,  Loss:0.5145545601844788\n",
      "Train Acc:50.19%, Test Acc:97.86%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5180794596672058\n",
      "Train Acc:50.23%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.49276816844940186\n",
      "Train Acc:50.68%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.47931113839149475\n",
      "Train Acc:51.96%, Test Acc:98.62%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5393970608711243\n",
      "Train Acc:52.35%, Test Acc:98.62%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5352065563201904\n",
      "Train Acc:55.47%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5227574110031128\n",
      "Train Acc:54.43%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5396431684494019\n",
      "Train Acc:55.88%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5722149610519409\n",
      "Train Acc:58.11%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5416309237480164\n",
      "Train Acc:59.77%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5448659658432007\n",
      "Train Acc:61.73%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.47605592012405396\n",
      "Train Acc:64.13%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5507673025131226\n",
      "Train Acc:62.40%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5378962755203247\n",
      "Train Acc:63.92%, Test Acc:98.88%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5784996747970581\n",
      "Train Acc:65.60%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.556567907333374\n",
      "Train Acc:65.63%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5310576558113098\n",
      "Train Acc:66.98%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5406994819641113\n",
      "Train Acc:68.31%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.6000567674636841\n",
      "Train Acc:69.00%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5258157849311829\n",
      "Train Acc:69.90%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.4870152771472931\n",
      "Train Acc:70.71%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5273196697235107\n",
      "Train Acc:71.64%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5119759440422058\n",
      "Train Acc:72.58%, Test Acc:98.88%\n",
      "\n",
      "\n",
      "Class: 0 -> Train Acc 72.57731958762886 ; Test Acc 98.87755102040816 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5757366418838501\n",
      "Train Acc:50.97%, Test Acc:97.84%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5064451694488525\n",
      "Train Acc:56.80%, Test Acc:98.15%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5058391094207764\n",
      "Train Acc:62.93%, Test Acc:98.28%\n",
      "\n",
      "\n",
      "Epoch: 2:800,  Loss:0.5571690201759338\n",
      "Train Acc:65.60%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.49012553691864014\n",
      "Train Acc:69.81%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5635290741920471\n",
      "Train Acc:72.38%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5214437246322632\n",
      "Train Acc:73.52%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.540818989276886\n",
      "Train Acc:76.40%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.5392243266105652\n",
      "Train Acc:78.01%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.5327045321464539\n",
      "Train Acc:78.73%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5226210951805115\n",
      "Train Acc:79.40%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.46489349007606506\n",
      "Train Acc:81.38%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.538142204284668\n",
      "Train Acc:82.33%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.5718343257904053\n",
      "Train Acc:81.96%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.5286102294921875\n",
      "Train Acc:83.67%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.5281524062156677\n",
      "Train Acc:83.60%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.524649977684021\n",
      "Train Acc:84.00%, Test Acc:98.55%\n",
      "\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.523627519607544\n",
      "Train Acc:84.33%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.4969729483127594\n",
      "Train Acc:83.90%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.5229828357696533\n",
      "Train Acc:85.43%, Test Acc:98.55%\n",
      "\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.5000366568565369\n",
      "Train Acc:85.40%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.5335561633110046\n",
      "Train Acc:85.95%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.5385556817054749\n",
      "Train Acc:88.00%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.5867807865142822\n",
      "Train Acc:86.63%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.4605940878391266\n",
      "Train Acc:87.24%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.510169506072998\n",
      "Train Acc:87.57%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.530099093914032\n",
      "Train Acc:87.68%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Class: 1 -> Train Acc 88.0 ; Test Acc 98.54625550660792 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5231406688690186\n",
      "Train Acc:49.96%, Test Acc:93.36%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.581961452960968\n",
      "Train Acc:51.43%, Test Acc:94.04%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5545611381530762\n",
      "Train Acc:51.64%, Test Acc:94.38%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5147527456283569\n",
      "Train Acc:55.08%, Test Acc:94.48%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5548372864723206\n",
      "Train Acc:55.95%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.553816020488739\n",
      "Train Acc:59.60%, Test Acc:94.72%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5212799310684204\n",
      "Train Acc:57.76%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.553977370262146\n",
      "Train Acc:59.06%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5228715538978577\n",
      "Train Acc:60.03%, Test Acc:95.01%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5416966080665588\n",
      "Train Acc:60.48%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5455771684646606\n",
      "Train Acc:62.61%, Test Acc:95.40%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5674116611480713\n",
      "Train Acc:60.20%, Test Acc:94.48%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5802629590034485\n",
      "Train Acc:63.36%, Test Acc:95.06%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5579709410667419\n",
      "Train Acc:64.37%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5117195248603821\n",
      "Train Acc:64.52%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5128772258758545\n",
      "Train Acc:64.80%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.523897111415863\n",
      "Train Acc:67.00%, Test Acc:95.20%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5344842672348022\n",
      "Train Acc:65.20%, Test Acc:95.30%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5914225578308105\n",
      "Train Acc:66.75%, Test Acc:95.45%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5093531608581543\n",
      "Train Acc:67.07%, Test Acc:95.16%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5194254517555237\n",
      "Train Acc:66.99%, Test Acc:94.91%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.4712856709957123\n",
      "Train Acc:68.31%, Test Acc:95.06%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5671482682228088\n",
      "Train Acc:67.12%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Class: 2 -> Train Acc 68.3061224489796 ; Test Acc 95.44573643410853 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5477418899536133\n",
      "Train Acc:49.86%, Test Acc:93.47%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5663865804672241\n",
      "Train Acc:50.97%, Test Acc:94.16%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5414450168609619\n",
      "Train Acc:52.98%, Test Acc:94.11%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5298709869384766\n",
      "Train Acc:56.55%, Test Acc:94.21%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5383734703063965\n",
      "Train Acc:57.00%, Test Acc:94.31%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5409963726997375\n",
      "Train Acc:58.01%, Test Acc:94.50%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5370177626609802\n",
      "Train Acc:59.39%, Test Acc:94.70%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.4912644326686859\n",
      "Train Acc:60.44%, Test Acc:94.80%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.530971884727478\n",
      "Train Acc:60.36%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.4781021773815155\n",
      "Train Acc:63.94%, Test Acc:94.36%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5358640551567078\n",
      "Train Acc:63.31%, Test Acc:94.41%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.5537851452827454\n",
      "Train Acc:63.83%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.534007728099823\n",
      "Train Acc:64.87%, Test Acc:94.75%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5215175747871399\n",
      "Train Acc:64.94%, Test Acc:94.70%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5614319443702698\n",
      "Train Acc:66.46%, Test Acc:94.46%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.4917111098766327\n",
      "Train Acc:71.00%, Test Acc:94.50%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.5148254036903381\n",
      "Train Acc:67.77%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.5167309045791626\n",
      "Train Acc:68.51%, Test Acc:94.80%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.49834907054901123\n",
      "Train Acc:69.09%, Test Acc:94.26%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5384302735328674\n",
      "Train Acc:68.75%, Test Acc:95.00%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.50813227891922\n",
      "Train Acc:70.33%, Test Acc:94.75%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.5956133604049683\n",
      "Train Acc:69.72%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.517283022403717\n",
      "Train Acc:70.47%, Test Acc:94.95%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.5796144008636475\n",
      "Train Acc:69.67%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Class: 3 -> Train Acc 71.0 ; Test Acc 95.0 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5722525715827942\n",
      "Train Acc:49.66%, Test Acc:95.72%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.509173572063446\n",
      "Train Acc:51.34%, Test Acc:96.18%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5475192666053772\n",
      "Train Acc:53.64%, Test Acc:96.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5106757879257202\n",
      "Train Acc:55.33%, Test Acc:96.18%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5453128218650818\n",
      "Train Acc:59.28%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.521665096282959\n",
      "Train Acc:61.60%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5808333158493042\n",
      "Train Acc:60.13%, Test Acc:96.33%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5715281963348389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:61.60%, Test Acc:96.38%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5752459764480591\n",
      "Train Acc:63.23%, Test Acc:96.28%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.48756495118141174\n",
      "Train Acc:64.34%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5136403441429138\n",
      "Train Acc:65.23%, Test Acc:96.38%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5440595149993896\n",
      "Train Acc:67.37%, Test Acc:96.54%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5845538973808289\n",
      "Train Acc:68.62%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5023119449615479\n",
      "Train Acc:68.25%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.4997398257255554\n",
      "Train Acc:68.49%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5358188152313232\n",
      "Train Acc:69.97%, Test Acc:96.54%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5366041660308838\n",
      "Train Acc:69.98%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5245886445045471\n",
      "Train Acc:71.33%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.5042750835418701\n",
      "Train Acc:71.68%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.47352486848831177\n",
      "Train Acc:74.09%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5423820614814758\n",
      "Train Acc:72.73%, Test Acc:96.79%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5769064426422119\n",
      "Train Acc:73.30%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5346744656562805\n",
      "Train Acc:73.62%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Class: 4 -> Train Acc 74.0909090909091 ; Test Acc 96.79226069246437 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5801196098327637\n",
      "Train Acc:49.83%, Test Acc:92.43%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.6313232183456421\n",
      "Train Acc:50.21%, Test Acc:92.77%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5836358666419983\n",
      "Train Acc:51.46%, Test Acc:93.05%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5735167860984802\n",
      "Train Acc:52.43%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5309309959411621\n",
      "Train Acc:53.70%, Test Acc:93.05%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5707515478134155\n",
      "Train Acc:54.42%, Test Acc:92.83%\n",
      "\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.5534412860870361\n",
      "Train Acc:53.96%, Test Acc:92.83%\n",
      "\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.5295259356498718\n",
      "Train Acc:56.27%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.5768520832061768\n",
      "Train Acc:55.38%, Test Acc:93.22%\n",
      "\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.5614895224571228\n",
      "Train Acc:56.85%, Test Acc:93.50%\n",
      "\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.5277258157730103\n",
      "Train Acc:58.67%, Test Acc:93.72%\n",
      "\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.5733177661895752\n",
      "Train Acc:58.77%, Test Acc:92.71%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5186680555343628\n",
      "Train Acc:57.88%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.5154883861541748\n",
      "Train Acc:58.31%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.5437881350517273\n",
      "Train Acc:58.56%, Test Acc:93.39%\n",
      "\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.4924887418746948\n",
      "Train Acc:58.52%, Test Acc:93.22%\n",
      "\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.517260730266571\n",
      "Train Acc:59.19%, Test Acc:94.06%\n",
      "\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.5607610940933228\n",
      "Train Acc:58.86%, Test Acc:93.67%\n",
      "\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.5639969110488892\n",
      "Train Acc:60.16%, Test Acc:93.89%\n",
      "\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.5134164690971375\n",
      "Train Acc:59.81%, Test Acc:93.55%\n",
      "\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.5131828784942627\n",
      "Train Acc:62.00%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Class: 5 -> Train Acc 62.0 ; Test Acc 94.05829596412556 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5637227892875671\n",
      "Train Acc:49.91%, Test Acc:96.29%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5213305950164795\n",
      "Train Acc:50.80%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5507563948631287\n",
      "Train Acc:53.67%, Test Acc:96.66%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5327062606811523\n",
      "Train Acc:55.84%, Test Acc:96.87%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5393187999725342\n",
      "Train Acc:58.35%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5549942255020142\n",
      "Train Acc:59.87%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5694816708564758\n",
      "Train Acc:62.24%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5332455635070801\n",
      "Train Acc:63.83%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5384089946746826\n",
      "Train Acc:65.05%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5482410788536072\n",
      "Train Acc:67.50%, Test Acc:97.29%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5157971382141113\n",
      "Train Acc:68.30%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5370394587516785\n",
      "Train Acc:70.27%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.517962634563446\n",
      "Train Acc:70.05%, Test Acc:96.97%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.4806666970252991\n",
      "Train Acc:70.85%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5743381381034851\n",
      "Train Acc:72.51%, Test Acc:97.03%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5342861413955688\n",
      "Train Acc:73.18%, Test Acc:97.23%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5173391103744507\n",
      "Train Acc:74.00%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5424497127532959\n",
      "Train Acc:73.33%, Test Acc:97.18%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.4584876000881195\n",
      "Train Acc:73.25%, Test Acc:97.18%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5290852785110474\n",
      "Train Acc:75.51%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5226898193359375\n",
      "Train Acc:75.99%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5376988649368286\n",
      "Train Acc:76.67%, Test Acc:97.03%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5593709349632263\n",
      "Train Acc:75.63%, Test Acc:97.29%\n",
      "\n",
      "\n",
      "Class: 6 -> Train Acc 76.67164179104478 ; Test Acc 97.28601252609603 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5599358081817627\n",
      "Train Acc:49.88%, Test Acc:95.53%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.557117760181427\n",
      "Train Acc:51.74%, Test Acc:96.06%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.541958212852478\n",
      "Train Acc:54.61%, Test Acc:96.11%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.48048263788223267\n",
      "Train Acc:56.94%, Test Acc:95.91%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.5030351877212524\n",
      "Train Acc:59.74%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5394090414047241\n",
      "Train Acc:60.89%, Test Acc:96.11%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5543871521949768\n",
      "Train Acc:64.15%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5142567157745361\n",
      "Train Acc:66.30%, Test Acc:96.21%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5405014157295227\n",
      "Train Acc:68.33%, Test Acc:96.16%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.5951653122901917\n",
      "Train Acc:68.13%, Test Acc:96.40%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5305671691894531\n",
      "Train Acc:69.09%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.5531574487686157\n",
      "Train Acc:70.27%, Test Acc:95.96%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.4998423457145691\n",
      "Train Acc:72.13%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5117654800415039\n",
      "Train Acc:73.28%, Test Acc:96.45%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.5460245609283447\n",
      "Train Acc:72.02%, Test Acc:96.16%\n",
      "\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.5575208067893982\n",
      "Train Acc:72.78%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.5514141321182251\n",
      "Train Acc:73.17%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.5604078769683838\n",
      "Train Acc:74.28%, Test Acc:96.40%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5544518828392029\n",
      "Train Acc:75.14%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.5346813201904297\n",
      "Train Acc:75.34%, Test Acc:96.25%\n",
      "\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.5531907677650452\n",
      "Train Acc:75.91%, Test Acc:96.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.5012615919113159\n",
      "Train Acc:76.29%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.5591448545455933\n",
      "Train Acc:76.98%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.5300306081771851\n",
      "Train Acc:78.26%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.5091061592102051\n",
      "Train Acc:76.83%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Class: 7 -> Train Acc 78.25806451612904 ; Test Acc 96.49805447470817 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.6450304985046387\n",
      "Train Acc:50.01%, Test Acc:87.99%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5915955901145935\n",
      "Train Acc:50.91%, Test Acc:88.24%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.6078071594238281\n",
      "Train Acc:52.06%, Test Acc:89.68%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5573796629905701\n",
      "Train Acc:52.32%, Test Acc:89.58%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.6016493439674377\n",
      "Train Acc:53.43%, Test Acc:89.68%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5828666090965271\n",
      "Train Acc:54.72%, Test Acc:90.14%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5385180115699768\n",
      "Train Acc:55.01%, Test Acc:90.50%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.530825674533844\n",
      "Train Acc:56.04%, Test Acc:90.61%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5526193976402283\n",
      "Train Acc:56.99%, Test Acc:89.73%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.6052979826927185\n",
      "Train Acc:56.38%, Test Acc:90.45%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5396416783332825\n",
      "Train Acc:57.48%, Test Acc:90.55%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5757309198379517\n",
      "Train Acc:58.00%, Test Acc:90.76%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5447659492492676\n",
      "Train Acc:57.60%, Test Acc:90.71%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5651159882545471\n",
      "Train Acc:58.54%, Test Acc:90.50%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5971723794937134\n",
      "Train Acc:59.13%, Test Acc:90.86%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5524383187294006\n",
      "Train Acc:59.01%, Test Acc:91.07%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.622504472732544\n",
      "Train Acc:60.11%, Test Acc:90.76%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5428398847579956\n",
      "Train Acc:59.12%, Test Acc:91.02%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.5414087176322937\n",
      "Train Acc:58.65%, Test Acc:90.97%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.5529295802116394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:60.00%, Test Acc:91.07%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5907708406448364\n",
      "Train Acc:60.27%, Test Acc:91.12%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.527740478515625\n",
      "Train Acc:60.89%, Test Acc:91.12%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5166277885437012\n",
      "Train Acc:60.98%, Test Acc:91.22%\n",
      "\n",
      "\n",
      "Class: 8 -> Train Acc 60.977777777777774 ; Test Acc 91.22176591375771 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5678597092628479\n",
      "Train Acc:50.26%, Test Acc:91.28%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.523908793926239\n",
      "Train Acc:51.80%, Test Acc:92.17%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5640270113945007\n",
      "Train Acc:55.66%, Test Acc:92.67%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.511634111404419\n",
      "Train Acc:57.33%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5540332198143005\n",
      "Train Acc:59.38%, Test Acc:93.06%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5439659357070923\n",
      "Train Acc:60.40%, Test Acc:92.96%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5291340351104736\n",
      "Train Acc:62.60%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5902145504951477\n",
      "Train Acc:63.59%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.563675582408905\n",
      "Train Acc:65.00%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5548736453056335\n",
      "Train Acc:65.19%, Test Acc:93.16%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.4994131922721863\n",
      "Train Acc:65.79%, Test Acc:92.81%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5544479489326477\n",
      "Train Acc:66.40%, Test Acc:93.06%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5234802961349487\n",
      "Train Acc:68.09%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5429325699806213\n",
      "Train Acc:67.81%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5664948225021362\n",
      "Train Acc:68.97%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5179298520088196\n",
      "Train Acc:70.43%, Test Acc:93.16%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5418621301651001\n",
      "Train Acc:69.59%, Test Acc:92.96%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.505419135093689\n",
      "Train Acc:70.93%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5523645281791687\n",
      "Train Acc:71.32%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.49978867173194885\n",
      "Train Acc:71.41%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5472095012664795\n",
      "Train Acc:71.87%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.6039488911628723\n",
      "Train Acc:72.22%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5674902200698853\n",
      "Train Acc:73.26%, Test Acc:93.36%\n",
      "\n",
      "\n",
      "Class: 9 -> Train Acc 73.25641025641025 ; Test Acc 93.35976214073341 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_idx = 0\n",
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    logNet = LogisticRegression(784)\n",
    "    optimizer = torch.optim.Adam(logNet.parameters(), lr=learning_rate)\n",
    "\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(logNet(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = logNet(xx)\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print(\"\\n\")\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(logNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 72.57731958762886 ; Test Acc 98.87755102040816\n",
      "Class: 1 -> Train Acc 88.0 ; Test Acc 98.54625550660792\n",
      "Class: 2 -> Train Acc 68.3061224489796 ; Test Acc 95.44573643410853\n",
      "Class: 3 -> Train Acc 71.0 ; Test Acc 95.0\n",
      "Class: 4 -> Train Acc 74.0909090909091 ; Test Acc 96.79226069246437\n",
      "Class: 5 -> Train Acc 62.0 ; Test Acc 94.05829596412556\n",
      "Class: 6 -> Train Acc 76.67164179104478 ; Test Acc 97.28601252609603\n",
      "Class: 7 -> Train Acc 78.25806451612904 ; Test Acc 96.49805447470817\n",
      "Class: 8 -> Train Acc 60.977777777777774 ; Test Acc 91.22176591375771\n",
      "Class: 9 -> Train Acc 73.25641025641025 ; Test Acc 93.35976214073341\n",
      "Total Accuracy (Argmax) is : 0.9154000282287598\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    shuffle_data()\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(net(xx).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        \n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:200,  Loss:0.1902083456516266\n",
      "Train Acc:96.30%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.16477316617965698\n",
      "Train Acc:98.49%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.14492975175380707\n",
      "Train Acc:98.76%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11025704443454742\n",
      "Train Acc:99.30%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12073925137519836\n",
      "Train Acc:99.38%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13998454809188843\n",
      "Train Acc:99.33%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14511480927467346\n",
      "Train Acc:99.54%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11947750300168991\n",
      "Train Acc:99.52%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.12466155737638474\n",
      "Train Acc:99.62%, Test Acc:99.59%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.13368499279022217\n",
      "Train Acc:99.81%, Test Acc:99.08%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.08891221880912781\n",
      "Train Acc:99.82%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12346048653125763\n",
      "Train Acc:99.80%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12881770730018616\n",
      "Train Acc:99.83%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.13905762135982513\n",
      "Train Acc:99.88%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.12862369418144226\n",
      "Train Acc:99.90%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12938882410526276\n",
      "Train Acc:99.95%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13960690796375275\n",
      "Train Acc:99.98%, Test Acc:99.23%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14705486595630646\n",
      "Train Acc:99.96%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.12308577448129654\n",
      "Train Acc:100.00%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.10609354078769684\n",
      "Train Acc:99.95%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.11645776778459549\n",
      "Train Acc:99.92%, Test Acc:99.23%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.11739588528871536\n",
      "Train Acc:99.96%, Test Acc:99.39%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10554870963096619\n",
      "Train Acc:99.96%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.59183673469387 \n",
      "\n",
      "1\n",
      "Epoch: 0:200,  Loss:0.1425032764673233\n",
      "Train Acc:97.54%, Test Acc:99.03%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.18024057149887085\n",
      "Train Acc:99.05%, Test Acc:99.16%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10396085679531097\n",
      "Train Acc:99.33%, Test Acc:99.25%\n",
      "\n",
      "\n",
      "Epoch: 2:800,  Loss:0.1667274832725525\n",
      "Train Acc:99.29%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.11828016489744186\n",
      "Train Acc:99.43%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.11114610731601715\n",
      "Train Acc:99.52%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12431404739618301\n",
      "Train Acc:99.56%, Test Acc:99.21%\n",
      "\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.08999494463205338\n",
      "Train Acc:99.77%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.13094817101955414\n",
      "Train Acc:99.73%, Test Acc:99.16%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.15088516473770142\n",
      "Train Acc:99.85%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13319379091262817\n",
      "Train Acc:99.80%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.14544972777366638\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.12383203208446503\n",
      "Train Acc:99.82%, Test Acc:99.52%\n",
      "\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.13052725791931152\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.1400119811296463\n",
      "Train Acc:99.80%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.1131279394030571\n",
      "Train Acc:99.94%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.12418492138385773\n",
      "Train Acc:99.88%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.1175309494137764\n",
      "Train Acc:99.87%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.09147365391254425\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.10080915689468384\n",
      "Train Acc:99.90%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.10214205086231232\n",
      "Train Acc:99.96%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.1218646839261055\n",
      "Train Acc:99.95%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.08219657093286514\n",
      "Train Acc:100.00%, Test Acc:99.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.11717012524604797\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.11913299560546875\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.1223207488656044\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.07791361957788467\n",
      "Train Acc:99.96%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:200,  Loss:0.2650079131126404\n",
      "Train Acc:91.53%, Test Acc:93.85%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.17949020862579346\n",
      "Train Acc:94.35%, Test Acc:94.91%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.21905013918876648\n",
      "Train Acc:95.25%, Test Acc:94.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.22428405284881592\n",
      "Train Acc:94.34%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.24380725622177124\n",
      "Train Acc:95.18%, Test Acc:94.62%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.25583207607269287\n",
      "Train Acc:95.20%, Test Acc:95.16%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.20520855486392975\n",
      "Train Acc:95.18%, Test Acc:94.96%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.24707399308681488\n",
      "Train Acc:95.70%, Test Acc:95.83%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.19025787711143494\n",
      "Train Acc:96.58%, Test Acc:96.51%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.21622955799102783\n",
      "Train Acc:97.14%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.1838093400001526\n",
      "Train Acc:97.22%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.1830339878797531\n",
      "Train Acc:97.20%, Test Acc:96.75%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.21658693253993988\n",
      "Train Acc:97.63%, Test Acc:97.04%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.19069938361644745\n",
      "Train Acc:98.02%, Test Acc:97.34%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1710907369852066\n",
      "Train Acc:97.77%, Test Acc:97.19%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.13751934468746185\n",
      "Train Acc:97.89%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.20875801146030426\n",
      "Train Acc:98.19%, Test Acc:97.19%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.19916895031929016\n",
      "Train Acc:98.40%, Test Acc:97.04%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.14467047154903412\n",
      "Train Acc:98.41%, Test Acc:95.98%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.13490961492061615\n",
      "Train Acc:98.41%, Test Acc:97.58%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09605809301137924\n",
      "Train Acc:98.57%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.13726423680782318\n",
      "Train Acc:99.00%, Test Acc:97.43%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.18312187492847443\n",
      "Train Acc:98.68%, Test Acc:98.11%\n",
      "\n",
      "\n",
      "Class: 2 -> Train Acc 99.0 ; Test Acc 98.11046511627907 \n",
      "\n",
      "3\n",
      "Epoch: 0:200,  Loss:0.2091067135334015\n",
      "Train Acc:91.95%, Test Acc:95.00%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.21398845314979553\n",
      "Train Acc:96.09%, Test Acc:96.49%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.15884657204151154\n",
      "Train Acc:96.69%, Test Acc:97.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.15473070740699768\n",
      "Train Acc:97.61%, Test Acc:97.23%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.17709587514400482\n",
      "Train Acc:98.25%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.1611410528421402\n",
      "Train Acc:98.20%, Test Acc:98.12%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13801859319210052\n",
      "Train Acc:98.54%, Test Acc:97.57%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1486503928899765\n",
      "Train Acc:99.06%, Test Acc:96.78%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.17162330448627472\n",
      "Train Acc:99.10%, Test Acc:97.57%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1379823535680771\n",
      "Train Acc:99.50%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13652536273002625\n",
      "Train Acc:99.23%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.13030242919921875\n",
      "Train Acc:99.45%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12380668520927429\n",
      "Train Acc:99.56%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11410797387361526\n",
      "Train Acc:99.70%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.14267805218696594\n",
      "Train Acc:99.62%, Test Acc:96.68%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1022457405924797\n",
      "Train Acc:100.00%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.11268606036901474\n",
      "Train Acc:99.69%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.10178079456090927\n",
      "Train Acc:99.77%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.12797637283802032\n",
      "Train Acc:99.76%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.11219677329063416\n",
      "Train Acc:99.84%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12077539414167404\n",
      "Train Acc:99.89%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.14364905655384064\n",
      "Train Acc:99.77%, Test Acc:98.27%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.09243347495794296\n",
      "Train Acc:99.80%, Test Acc:98.12%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.1254236400127411\n",
      "Train Acc:99.79%, Test Acc:97.92%\n",
      "\n",
      "\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.46534653465346 \n",
      "\n",
      "4\n",
      "Epoch: 0:200,  Loss:0.1942884773015976\n",
      "Train Acc:93.83%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1209755688905716\n",
      "Train Acc:97.40%, Test Acc:97.10%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.12575745582580566\n",
      "Train Acc:98.41%, Test Acc:97.05%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.1885463148355484\n",
      "Train Acc:98.57%, Test Acc:97.86%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.1258462369441986\n",
      "Train Acc:99.19%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.126350998878479\n",
      "Train Acc:99.20%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14359787106513977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.27%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1950913816690445\n",
      "Train Acc:99.45%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11146356910467148\n",
      "Train Acc:99.57%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.14711014926433563\n",
      "Train Acc:99.64%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.113343246281147\n",
      "Train Acc:99.72%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12928034365177155\n",
      "Train Acc:99.73%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.10810442268848419\n",
      "Train Acc:99.77%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.13461264967918396\n",
      "Train Acc:99.82%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.12525875866413116\n",
      "Train Acc:99.83%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.14600667357444763\n",
      "Train Acc:99.77%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.08760692924261093\n",
      "Train Acc:99.84%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1081419587135315\n",
      "Train Acc:99.89%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.1541793942451477\n",
      "Train Acc:99.75%, Test Acc:98.73%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.10984005779027939\n",
      "Train Acc:100.00%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1074351817369461\n",
      "Train Acc:99.91%, Test Acc:98.73%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.14575433731079102\n",
      "Train Acc:99.91%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.083954356610775\n",
      "Train Acc:99.95%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 98.77800407331976 \n",
      "\n",
      "5\n",
      "Epoch: 0:200,  Loss:0.2653432786464691\n",
      "Train Acc:89.22%, Test Acc:92.49%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.18085817992687225\n",
      "Train Acc:94.11%, Test Acc:95.40%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.22077317535877228\n",
      "Train Acc:96.37%, Test Acc:96.19%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.16246886551380157\n",
      "Train Acc:97.44%, Test Acc:97.20%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.16317467391490936\n",
      "Train Acc:97.83%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.18375374376773834\n",
      "Train Acc:98.16%, Test Acc:96.52%\n",
      "\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.15390074253082275\n",
      "Train Acc:98.57%, Test Acc:97.53%\n",
      "\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.18342651426792145\n",
      "Train Acc:98.81%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.11918728798627853\n",
      "Train Acc:99.19%, Test Acc:97.93%\n",
      "\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.1653881072998047\n",
      "Train Acc:99.11%, Test Acc:97.93%\n",
      "\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.1895546019077301\n",
      "Train Acc:99.67%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.17011955380439758\n",
      "Train Acc:98.62%, Test Acc:97.59%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.14244131743907928\n",
      "Train Acc:99.16%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.14232788980007172\n",
      "Train Acc:99.24%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.1428632289171219\n",
      "Train Acc:99.30%, Test Acc:97.53%\n",
      "\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.19023753702640533\n",
      "Train Acc:99.48%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.1283695548772812\n",
      "Train Acc:99.59%, Test Acc:97.42%\n",
      "\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.1343390792608261\n",
      "Train Acc:99.66%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.1733662486076355\n",
      "Train Acc:99.80%, Test Acc:97.31%\n",
      "\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.1050264835357666\n",
      "Train Acc:99.83%, Test Acc:97.25%\n",
      "\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.13140344619750977\n",
      "Train Acc:99.77%, Test Acc:97.59%\n",
      "\n",
      "\n",
      "Class: 5 -> Train Acc 99.82978723404256 ; Test Acc 97.92600896860986 \n",
      "\n",
      "6\n",
      "Epoch: 0:200,  Loss:0.21975171566009521\n",
      "Train Acc:95.09%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.15290133655071259\n",
      "Train Acc:97.66%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.13201545178890228\n",
      "Train Acc:98.17%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.23125258088111877\n",
      "Train Acc:98.31%, Test Acc:98.64%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12622028589248657\n",
      "Train Acc:98.92%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1256931871175766\n",
      "Train Acc:99.47%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13129252195358276\n",
      "Train Acc:99.03%, Test Acc:98.54%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14880673587322235\n",
      "Train Acc:99.08%, Test Acc:98.75%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.21152105927467346\n",
      "Train Acc:99.18%, Test Acc:98.38%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.12566490471363068\n",
      "Train Acc:99.54%, Test Acc:98.85%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14844170212745667\n",
      "Train Acc:99.46%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11350587755441666\n",
      "Train Acc:99.60%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.13516652584075928\n",
      "Train Acc:99.40%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.08306332677602768\n",
      "Train Acc:99.47%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1243082731962204\n",
      "Train Acc:99.55%, Test Acc:98.85%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.09841680526733398\n",
      "Train Acc:99.63%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1040099635720253\n",
      "Train Acc:99.76%, Test Acc:98.96%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1320495903491974\n",
      "Train Acc:99.73%, Test Acc:98.70%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.13816772401332855\n",
      "Train Acc:99.50%, Test Acc:98.75%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.12540659308433533\n",
      "Train Acc:99.75%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1041460931301117\n",
      "Train Acc:99.70%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.09659463167190552\n",
      "Train Acc:99.78%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.13001559674739838\n",
      "Train Acc:99.88%, Test Acc:98.70%\n",
      "\n",
      "\n",
      "Class: 6 -> Train Acc 99.87628865979381 ; Test Acc 98.95615866388309 \n",
      "\n",
      "7\n",
      "Epoch: 0:200,  Loss:0.27841052412986755\n",
      "Train Acc:94.72%, Test Acc:96.94%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.19970981776714325\n",
      "Train Acc:97.89%, Test Acc:97.71%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.18252994120121002\n",
      "Train Acc:98.55%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.17395229637622833\n",
      "Train Acc:98.85%, Test Acc:98.35%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.0873308777809143\n",
      "Train Acc:98.76%, Test Acc:97.76%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.1079740971326828\n",
      "Train Acc:99.08%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12549486756324768\n",
      "Train Acc:99.27%, Test Acc:98.35%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.10918160527944565\n",
      "Train Acc:99.57%, Test Acc:98.44%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.12883906066417694\n",
      "Train Acc:99.40%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.11894822120666504\n",
      "Train Acc:99.52%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.1695152074098587\n",
      "Train Acc:99.66%, Test Acc:98.05%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12374649941921234\n",
      "Train Acc:99.56%, Test Acc:98.30%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12817677855491638\n",
      "Train Acc:99.58%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.14169339835643768\n",
      "Train Acc:99.59%, Test Acc:98.39%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.10039728134870529\n",
      "Train Acc:99.64%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.1316038817167282\n",
      "Train Acc:99.67%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.0883878543972969\n",
      "Train Acc:99.80%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.16316041350364685\n",
      "Train Acc:99.77%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.15016324818134308\n",
      "Train Acc:100.00%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.10201253741979599\n",
      "Train Acc:99.71%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.12771181762218475\n",
      "Train Acc:99.87%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.14596575498580933\n",
      "Train Acc:99.76%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.08972277492284775\n",
      "Train Acc:99.88%, Test Acc:98.30%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.10538426041603088\n",
      "Train Acc:99.81%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.1100492849946022\n",
      "Train Acc:99.89%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.44357976653697 \n",
      "\n",
      "8\n",
      "Epoch: 0:200,  Loss:0.28693848848342896\n",
      "Train Acc:87.46%, Test Acc:91.17%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.17757894098758698\n",
      "Train Acc:92.12%, Test Acc:93.63%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.30962327122688293\n",
      "Train Acc:94.29%, Test Acc:91.79%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.1659069061279297\n",
      "Train Acc:94.97%, Test Acc:94.71%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5102066993713379\n",
      "Train Acc:95.50%, Test Acc:94.30%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.11353139579296112\n",
      "Train Acc:96.80%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.25027263164520264\n",
      "Train Acc:96.28%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1976333111524582\n",
      "Train Acc:96.92%, Test Acc:95.79%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.14143520593643188\n",
      "Train Acc:97.12%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1587873101234436\n",
      "Train Acc:97.57%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.15649491548538208\n",
      "Train Acc:98.24%, Test Acc:96.51%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.14578481018543243\n",
      "Train Acc:98.52%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.16020254790782928\n",
      "Train Acc:98.80%, Test Acc:95.94%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.20853091776371002\n",
      "Train Acc:98.54%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.13930489122867584\n",
      "Train Acc:98.91%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.15137332677841187\n",
      "Train Acc:99.05%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.11882646381855011\n",
      "Train Acc:99.05%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1670100837945938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.31%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.13254430890083313\n",
      "Train Acc:99.30%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.15160377323627472\n",
      "Train Acc:99.60%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.14640316367149353\n",
      "Train Acc:99.41%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.13230390846729279\n",
      "Train Acc:99.58%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.13300004601478577\n",
      "Train Acc:99.70%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Class: 8 -> Train Acc 99.70370370370371 ; Test Acc 96.81724845995893 \n",
      "\n",
      "9\n",
      "Epoch: 0:200,  Loss:0.25558242201805115\n",
      "Train Acc:89.37%, Test Acc:92.77%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.3021601736545563\n",
      "Train Acc:93.90%, Test Acc:93.95%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.24361030757427216\n",
      "Train Acc:95.05%, Test Acc:94.90%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.21518684923648834\n",
      "Train Acc:95.74%, Test Acc:94.55%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.2558193504810333\n",
      "Train Acc:95.71%, Test Acc:95.14%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.21317631006240845\n",
      "Train Acc:97.00%, Test Acc:95.09%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.1474662572145462\n",
      "Train Acc:96.36%, Test Acc:95.19%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.16789157688617706\n",
      "Train Acc:97.20%, Test Acc:95.24%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.16784095764160156\n",
      "Train Acc:97.27%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.23495197296142578\n",
      "Train Acc:97.48%, Test Acc:95.64%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.1686965376138687\n",
      "Train Acc:97.52%, Test Acc:95.39%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.1322912871837616\n",
      "Train Acc:98.00%, Test Acc:95.14%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.1451498121023178\n",
      "Train Acc:97.84%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.18508347868919373\n",
      "Train Acc:97.88%, Test Acc:94.55%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1693272590637207\n",
      "Train Acc:97.99%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1751531958580017\n",
      "Train Acc:98.45%, Test Acc:95.44%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.18300408124923706\n",
      "Train Acc:98.79%, Test Acc:95.74%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.18110504746437073\n",
      "Train Acc:98.67%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1183856874704361\n",
      "Train Acc:98.29%, Test Acc:95.99%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.15409910678863525\n",
      "Train Acc:98.55%, Test Acc:95.94%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1327930986881256\n",
      "Train Acc:98.56%, Test Acc:95.74%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.23475204408168793\n",
      "Train Acc:98.71%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.1514241099357605\n",
      "Train Acc:99.05%, Test Acc:95.79%\n",
      "\n",
      "\n",
      "Class: 9 -> Train Acc 99.05128205128206 ; Test Acc 95.98612487611497 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = ConvexNN([784,200,100,1], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "        \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = sigmoid(Net(xx))\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print(\"\\n\")\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.59183673469387\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.0 ; Test Acc 98.11046511627907\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.46534653465346\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 98.77800407331976\n",
      "Class: 5 -> Train Acc 99.82978723404256 ; Test Acc 97.92600896860986\n",
      "Class: 6 -> Train Acc 99.87628865979381 ; Test Acc 98.95615866388309\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.44357976653697\n",
      "Class: 8 -> Train Acc 99.70370370370371 ; Test Acc 96.81724845995893\n",
      "Class: 9 -> Train Acc 99.05128205128206 ; Test Acc 95.98612487611497\n",
      "Total Accuracy (Argmax) is : 0.9660000205039978\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:200,  Loss:0.21731796860694885\n",
      "Train Acc:97.29%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.12151513993740082\n",
      "Train Acc:98.92%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.11258745193481445\n",
      "Train Acc:99.44%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11354289203882217\n",
      "Train Acc:99.73%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.1234457939863205\n",
      "Train Acc:99.73%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13944566249847412\n",
      "Train Acc:99.87%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.11360175162553787\n",
      "Train Acc:99.91%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.18856018781661987\n",
      "Train Acc:99.89%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.09785205125808716\n",
      "Train Acc:100.00%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1420046091079712\n",
      "Train Acc:99.96%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.09902246296405792\n",
      "Train Acc:99.94%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11073046922683716\n",
      "Train Acc:99.93%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12462783604860306\n",
      "Train Acc:99.98%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.08134999871253967\n",
      "Train Acc:99.99%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1232866495847702\n",
      "Train Acc:100.00%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1171824187040329\n",
      "Train Acc:99.71%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.11756277084350586\n",
      "Train Acc:99.90%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.10405978560447693\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.1250312775373459\n",
      "Train Acc:100.00%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.09437660872936249\n",
      "Train Acc:99.98%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09628170728683472\n",
      "Train Acc:100.00%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.06665828824043274\n",
      "Train Acc:99.84%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.09571699053049088\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062 \n",
      "\n",
      "1\n",
      "Epoch: 0:200,  Loss:0.11280658096075058\n",
      "Train Acc:97.72%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.13739743828773499\n",
      "Train Acc:99.22%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10042721033096313\n",
      "Train Acc:99.27%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 2:800,  Loss:0.1422419399023056\n",
      "Train Acc:99.37%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.12545478343963623\n",
      "Train Acc:99.60%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.10372818261384964\n",
      "Train Acc:99.72%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12780943512916565\n",
      "Train Acc:99.72%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.11142679303884506\n",
      "Train Acc:99.75%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.1020035445690155\n",
      "Train Acc:99.84%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.12312080711126328\n",
      "Train Acc:99.85%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13604655861854553\n",
      "Train Acc:99.95%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.08337539434432983\n",
      "Train Acc:99.88%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.13039080798625946\n",
      "Train Acc:99.86%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.11987624317407608\n",
      "Train Acc:99.94%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.11296398937702179\n",
      "Train Acc:100.00%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.13903076946735382\n",
      "Train Acc:99.94%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.1057850643992424\n",
      "Train Acc:99.94%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.08330119401216507\n",
      "Train Acc:99.89%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.11049840599298477\n",
      "Train Acc:100.00%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.12739701569080353\n",
      "Train Acc:99.96%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.09945078194141388\n",
      "Train Acc:99.99%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.12603551149368286\n",
      "Train Acc:100.00%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.08994874358177185\n",
      "Train Acc:100.00%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.11847402900457382\n",
      "Train Acc:99.96%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.12035040557384491\n",
      "Train Acc:100.00%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.10556330531835556\n",
      "Train Acc:99.94%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.09094478189945221\n",
      "Train Acc:99.82%, Test Acc:99.25%\n",
      "\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.47136563876651 \n",
      "\n",
      "2\n",
      "Epoch: 0:200,  Loss:0.1684650480747223\n",
      "Train Acc:96.09%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.12850791215896606\n",
      "Train Acc:98.57%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.12702776491641998\n",
      "Train Acc:98.97%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.09711179882287979\n",
      "Train Acc:99.06%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.16804620623588562\n",
      "Train Acc:99.55%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1257413923740387\n",
      "Train Acc:100.00%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12565919756889343\n",
      "Train Acc:99.64%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14851370453834534\n",
      "Train Acc:99.73%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.09349962323904037\n",
      "Train Acc:99.80%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11712131649255753\n",
      "Train Acc:99.98%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14417347311973572\n",
      "Train Acc:99.88%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12189299613237381\n",
      "Train Acc:99.60%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.1315024048089981\n",
      "Train Acc:99.78%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.12759016454219818\n",
      "Train Acc:99.78%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.10396552830934525\n",
      "Train Acc:99.82%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12977881729602814\n",
      "Train Acc:99.94%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13544465601444244\n",
      "Train Acc:99.96%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14338910579681396\n",
      "Train Acc:99.87%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1589537113904953\n",
      "Train Acc:99.88%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.13581565022468567\n",
      "Train Acc:100.00%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12278570979833603\n",
      "Train Acc:99.96%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.12121792882680893\n",
      "Train Acc:99.82%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10366504639387131\n",
      "Train Acc:99.76%, Test Acc:99.03%\n",
      "\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798 \n",
      "\n",
      "3\n",
      "Epoch: 0:200,  Loss:0.1435774713754654\n",
      "Train Acc:94.09%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1256464123725891\n",
      "Train Acc:97.81%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.16631370782852173\n",
      "Train Acc:98.54%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.13129572570323944\n",
      "Train Acc:98.94%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12458263337612152\n",
      "Train Acc:99.25%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.17660072445869446\n",
      "Train Acc:99.18%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.10919982194900513\n",
      "Train Acc:99.48%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.09465283155441284\n",
      "Train Acc:99.58%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.10094752907752991\n",
      "Train Acc:99.67%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.10662947595119476\n",
      "Train Acc:99.62%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.15003475546836853\n",
      "Train Acc:99.55%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12275232374668121\n",
      "Train Acc:99.62%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12814965844154358\n",
      "Train Acc:99.76%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11584683507680893\n",
      "Train Acc:99.94%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.10709387809038162\n",
      "Train Acc:100.00%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.10648562759160995\n",
      "Train Acc:100.00%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.12555497884750366\n",
      "Train Acc:99.91%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.10103989392518997\n",
      "Train Acc:99.73%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1310451626777649\n",
      "Train Acc:99.75%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.09903814643621445\n",
      "Train Acc:99.50%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.13354596495628357\n",
      "Train Acc:100.00%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.11327266693115234\n",
      "Train Acc:99.94%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.09847085177898407\n",
      "Train Acc:99.97%, Test Acc:98.76%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.1424856036901474\n",
      "Train Acc:99.92%, Test Acc:98.56%\n",
      "\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.76237623762376 \n",
      "\n",
      "4\n",
      "Epoch: 0:200,  Loss:0.1681768298149109\n",
      "Train Acc:95.36%, Test Acc:97.56%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1408187448978424\n",
      "Train Acc:98.53%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.20413099229335785\n",
      "Train Acc:98.77%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11021895706653595\n",
      "Train Acc:99.47%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.13520574569702148\n",
      "Train Acc:99.75%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13206472992897034\n",
      "Train Acc:99.73%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.10592928528785706\n",
      "Train Acc:99.65%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11278918385505676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.76%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11900530755519867\n",
      "Train Acc:99.95%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11467210948467255\n",
      "Train Acc:99.86%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10531017929315567\n",
      "Train Acc:99.66%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.09614083170890808\n",
      "Train Acc:99.97%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.12361001968383789\n",
      "Train Acc:99.92%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.10536752641201019\n",
      "Train Acc:99.88%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1102680116891861\n",
      "Train Acc:99.86%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12229945510625839\n",
      "Train Acc:99.91%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1066506952047348\n",
      "Train Acc:99.89%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1212250292301178\n",
      "Train Acc:99.84%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.10433226823806763\n",
      "Train Acc:100.00%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.12613998353481293\n",
      "Train Acc:100.00%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.10448730736970901\n",
      "Train Acc:99.97%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.1203690841794014\n",
      "Train Acc:99.90%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10706324875354767\n",
      "Train Acc:99.90%, Test Acc:98.78%\n",
      "\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.13441955193483 \n",
      "\n",
      "5\n",
      "Epoch: 0:200,  Loss:0.21822695434093475\n",
      "Train Acc:95.17%, Test Acc:97.09%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.23354953527450562\n",
      "Train Acc:98.38%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.16614586114883423\n",
      "Train Acc:98.95%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11451909691095352\n",
      "Train Acc:99.15%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.15433953702449799\n",
      "Train Acc:99.61%, Test Acc:97.31%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1350758969783783\n",
      "Train Acc:99.65%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.09992661327123642\n",
      "Train Acc:99.63%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.11335296928882599\n",
      "Train Acc:99.88%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.14044827222824097\n",
      "Train Acc:99.62%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.10905716568231583\n",
      "Train Acc:99.87%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.09525914490222931\n",
      "Train Acc:100.00%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.11986715346574783\n",
      "Train Acc:100.00%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.1282791942358017\n",
      "Train Acc:100.00%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.152114138007164\n",
      "Train Acc:99.82%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.14088626205921173\n",
      "Train Acc:99.64%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.12044303119182587\n",
      "Train Acc:99.79%, Test Acc:97.93%\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.12156578153371811\n",
      "Train Acc:99.97%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.11189134418964386\n",
      "Train Acc:100.00%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.08633020520210266\n",
      "Train Acc:99.98%, Test Acc:99.05%\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.12988026440143585\n",
      "Train Acc:100.00%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.10677160322666168\n",
      "Train Acc:100.00%, Test Acc:98.43%\n",
      "\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 99.04708520179372 \n",
      "\n",
      "6\n",
      "Epoch: 0:200,  Loss:0.13739946484565735\n",
      "Train Acc:96.22%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.11977182328701019\n",
      "Train Acc:98.98%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.140008345246315\n",
      "Train Acc:99.24%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11301440000534058\n",
      "Train Acc:99.48%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.13390880823135376\n",
      "Train Acc:99.65%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.134500652551651\n",
      "Train Acc:99.87%, Test Acc:98.85%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13298209011554718\n",
      "Train Acc:99.78%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.19217710196971893\n",
      "Train Acc:99.90%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11624495685100555\n",
      "Train Acc:99.86%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.134815976023674\n",
      "Train Acc:99.94%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10387366265058517\n",
      "Train Acc:99.97%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11400971561670303\n",
      "Train Acc:99.93%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.126582071185112\n",
      "Train Acc:99.97%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11414030194282532\n",
      "Train Acc:99.72%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.08717513829469681\n",
      "Train Acc:99.88%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12429003417491913\n",
      "Train Acc:99.78%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.12219688296318054\n",
      "Train Acc:99.98%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12916158139705658\n",
      "Train Acc:99.91%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.09990602731704712\n",
      "Train Acc:100.00%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.08749870210886002\n",
      "Train Acc:99.96%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12428361177444458\n",
      "Train Acc:99.98%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.0785265862941742\n",
      "Train Acc:99.99%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.11814793944358826\n",
      "Train Acc:99.98%, Test Acc:99.16%\n",
      "\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.37369519832986 \n",
      "\n",
      "7\n",
      "Epoch: 0:200,  Loss:0.23387159407138824\n",
      "Train Acc:96.23%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.11251360177993774\n",
      "Train Acc:98.43%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.11175388097763062\n",
      "Train Acc:99.08%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.10608258843421936\n",
      "Train Acc:98.98%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.10791030526161194\n",
      "Train Acc:99.23%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.16897809505462646\n",
      "Train Acc:99.69%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.1307210475206375\n",
      "Train Acc:99.66%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11966505646705627\n",
      "Train Acc:99.81%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.1049933210015297\n",
      "Train Acc:100.00%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.1245899423956871\n",
      "Train Acc:99.80%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.11917341500520706\n",
      "Train Acc:99.77%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12248314172029495\n",
      "Train Acc:99.76%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.10068156570196152\n",
      "Train Acc:99.73%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.09575080126523972\n",
      "Train Acc:100.00%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.10259188711643219\n",
      "Train Acc:99.96%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.11519908159971237\n",
      "Train Acc:99.77%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.08855472505092621\n",
      "Train Acc:99.96%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.13204488158226013\n",
      "Train Acc:99.95%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.09479755163192749\n",
      "Train Acc:99.94%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.1319633573293686\n",
      "Train Acc:99.90%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.1189202293753624\n",
      "Train Acc:99.91%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.07868298143148422\n",
      "Train Acc:99.94%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.1193457767367363\n",
      "Train Acc:99.76%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.0858602225780487\n",
      "Train Acc:99.94%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.1218176856637001\n",
      "Train Acc:99.99%, Test Acc:98.54%\n",
      "\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.92996108949417 \n",
      "\n",
      "8\n",
      "Epoch: 0:200,  Loss:0.22651809453964233\n",
      "Train Acc:92.04%, Test Acc:96.82%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.19030813872814178\n",
      "Train Acc:97.18%, Test Acc:97.18%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10521306842565536\n",
      "Train Acc:98.68%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.09464947879314423\n",
      "Train Acc:98.57%, Test Acc:96.36%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12465474754571915\n",
      "Train Acc:99.07%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.14757469296455383\n",
      "Train Acc:99.68%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.17273205518722534\n",
      "Train Acc:99.36%, Test Acc:98.00%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.13638873398303986\n",
      "Train Acc:99.39%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11655915528535843\n",
      "Train Acc:99.69%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11591080576181412\n",
      "Train Acc:99.60%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14664477109909058\n",
      "Train Acc:99.86%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12127891182899475\n",
      "Train Acc:99.64%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.1178317666053772\n",
      "Train Acc:99.73%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.1195024698972702\n",
      "Train Acc:99.71%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1601637452840805\n",
      "Train Acc:99.72%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1264120191335678\n",
      "Train Acc:99.56%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1459723711013794\n",
      "Train Acc:99.55%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1323627531528473\n",
      "Train Acc:99.65%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.10712697356939316\n",
      "Train Acc:99.70%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.13125507533550262\n",
      "Train Acc:100.00%, Test Acc:98.72%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17:4200,  Loss:0.111699178814888\n",
      "Train Acc:99.85%, Test Acc:97.95%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.09885604679584503\n",
      "Train Acc:99.87%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10521125793457031\n",
      "Train Acc:99.93%, Test Acc:98.61%\n",
      "\n",
      "Class: 8 -> Train Acc 100.0 ; Test Acc 98.81930184804928 \n",
      "\n",
      "9\n",
      "Epoch: 0:200,  Loss:0.16223327815532684\n",
      "Train Acc:92.94%, Test Acc:96.78%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.13000811636447906\n",
      "Train Acc:97.56%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10350021719932556\n",
      "Train Acc:98.37%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.17198461294174194\n",
      "Train Acc:98.88%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.11707755923271179\n",
      "Train Acc:99.17%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.12492135167121887\n",
      "Train Acc:99.40%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14391696453094482\n",
      "Train Acc:99.33%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.12057922035455704\n",
      "Train Acc:99.63%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.14173611998558044\n",
      "Train Acc:99.58%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.09312642365694046\n",
      "Train Acc:99.79%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10936691612005234\n",
      "Train Acc:99.69%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11137087643146515\n",
      "Train Acc:99.80%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12472636997699738\n",
      "Train Acc:99.81%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.1349581480026245\n",
      "Train Acc:99.86%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.08916818350553513\n",
      "Train Acc:99.90%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12470358610153198\n",
      "Train Acc:99.81%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13914890587329865\n",
      "Train Acc:99.91%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12555952370166779\n",
      "Train Acc:99.80%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.10935596376657486\n",
      "Train Acc:99.76%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.12687718868255615\n",
      "Train Acc:99.68%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09335409849882126\n",
      "Train Acc:99.77%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.11881924420595169\n",
      "Train Acc:99.83%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.1114954873919487\n",
      "Train Acc:99.90%, Test Acc:98.41%\n",
      "\n",
      "Class: 9 -> Train Acc 99.91176470588236 ; Test Acc 98.86025768087215 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = nn.Sequential(nn.Linear(784, 200),\n",
    "                       actf(),\n",
    "                       nn.Linear(200,100),\n",
    "                       actf(),\n",
    "                       nn.Linear(100,1))\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = sigmoid(Net(xx))\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.47136563876651\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.76237623762376\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.13441955193483\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 99.04708520179372\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.37369519832986\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.92996108949417\n",
      "Class: 8 -> Train Acc 100.0 ; Test Acc 98.81930184804928\n",
      "Class: 9 -> Train Acc 99.91176470588236 ; Test Acc 98.86025768087215\n",
      "Total Accuracy (Argmax) is : 0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mixup = True\n",
    "use_check = False\n",
    "check_every = 2\n",
    "check_size = 100\n",
    "\n",
    "m_,s_ = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.1692323088645935, MinVal:0.6348922848701477, gp: 7.842011545342031e-13\n",
      "Train Acc:96.16%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.14545102417469025, MinVal:0.5404513478279114, gp: 5.950114012609475e-11\n",
      "Train Acc:99.00%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.10647765547037125, MinVal:0.2636297047138214, gp: 2.6961085950460983e-06\n",
      "Train Acc:99.55%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.11226221919059753, MinVal:0.4234794080257416, gp: 3.3187992354299922e-09\n",
      "Train Acc:99.64%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.09751855581998825, MinVal:0.7089232206344604, gp: 3.87337528045574e-14\n",
      "Train Acc:99.81%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.11645012348890305, MinVal:0.7324582934379578, gp: 1.8279521573163517e-14\n",
      "Train Acc:99.87%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.12763670086860657, MinVal:0.3044567406177521, gp: 3.8711553429493506e-07\n",
      "Train Acc:99.81%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.1256728321313858, MinVal:0.30716702342033386, gp: 4.7308208195318e-07\n",
      "Train Acc:99.90%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.10327164828777313, MinVal:0.3954397439956665, gp: 1.1165112390187915e-08\n",
      "Train Acc:99.88%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.11359228193759918, MinVal:0.30946749448776245, gp: 5.301056944517768e-07\n",
      "Train Acc:99.98%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.12895306944847107, MinVal:0.7259291410446167, gp: 1.8222102903735042e-14\n",
      "Train Acc:99.94%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.13472069799900055, MinVal:0.38631799817085266, gp: 1.443966546332831e-08\n",
      "Train Acc:99.97%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.11614534258842468, MinVal:0.4309486746788025, gp: 2.420476485909262e-09\n",
      "Train Acc:99.87%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.1102384477853775, MinVal:0.35288211703300476, gp: 5.465265928705776e-08\n",
      "Train Acc:99.97%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.11908917874097824, MinVal:0.41190826892852783, gp: 5.240556877339486e-09\n",
      "Train Acc:99.93%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.08274971693754196, MinVal:0.6280171275138855, gp: 1.7469884046328321e-12\n",
      "Train Acc:99.94%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.11425576359033585, MinVal:0.3641676604747772, gp: 4.3509931657581546e-08\n",
      "Train Acc:99.97%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.10918954014778137, MinVal:0.45994922518730164, gp: 7.621437925209307e-10\n",
      "Train Acc:100.00%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11737953871488571, MinVal:0.5009332299232483, gp: 2.769394713553197e-10\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.11663537472486496, MinVal:0.6923090815544128, gp: 8.007368368628115e-14\n",
      "Train Acc:99.87%, Test Acc:99.39%\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.48979591836735 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.14937958121299744, MinVal:0.7891765236854553, gp: 4.705850357148876e-15\n",
      "Train Acc:97.09%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.15712226927280426, MinVal:0.8262361884117126, gp: 4.634728706337076e-16\n",
      "Train Acc:99.07%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.11742351949214935, MinVal:0.5585561990737915, gp: 1.9945075105387566e-11\n",
      "Train Acc:99.38%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.1382444053888321, MinVal:0.6119322180747986, gp: 4.812341063836767e-12\n",
      "Train Acc:99.50%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.1073746383190155, MinVal:0.5989565849304199, gp: 4.290285141039796e-12\n",
      "Train Acc:99.73%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.10721004754304886, MinVal:0.142303466796875, gp: 0.00030178544693626463\n",
      "Train Acc:99.81%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.13832437992095947, MinVal:0.7818742394447327, gp: 3.785696443689901e-15\n",
      "Train Acc:99.88%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.09136034548282623, MinVal:0.5985921025276184, gp: 4.075298692257645e-12\n",
      "Train Acc:99.86%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.10147659480571747, MinVal:0.5895867347717285, gp: 5.796198590535262e-12\n",
      "Train Acc:99.90%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.11507879197597504, MinVal:0.31877416372299194, gp: 2.874408551178931e-07\n",
      "Train Acc:99.94%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.0891154557466507, MinVal:0.8372063040733337, gp: 3.0650649526049387e-16\n",
      "Train Acc:99.93%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.08585754036903381, MinVal:0.5260462164878845, gp: 1.3558931755142112e-10\n",
      "Train Acc:99.97%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.09984792768955231, MinVal:0.5494756698608398, gp: 2.859058476079035e-11\n",
      "Train Acc:99.99%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.1050400659441948, MinVal:0.5051796436309814, gp: 2.1184795584439087e-10\n",
      "Train Acc:99.98%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.13382720947265625, MinVal:0.5905866026878357, gp: 5.610510320219753e-12\n",
      "Train Acc:99.96%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.10128583014011383, MinVal:0.5019469857215881, gp: 2.563898537921716e-10\n",
      "Train Acc:99.97%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.11217545717954636, MinVal:0.470867782831192, gp: 7.175675609261134e-10\n",
      "Train Acc:99.92%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.09758877009153366, MinVal:1.060781717300415, gp: 4.105230494793333e-20\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.1235434040427208, MinVal:0.4740968942642212, gp: 6.162654830887959e-10\n",
      "Train Acc:99.96%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.08225927501916885, MinVal:0.879325270652771, gp: 5.3231163530375865e-17\n",
      "Train Acc:99.96%, Test Acc:99.43%\n",
      "\n",
      "Class: 1 -> Train Acc 99.98516760605162 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.20455807447433472, MinVal:0.7947201728820801, gp: 4.48229549247889e-15\n",
      "Train Acc:94.27%, Test Acc:97.19%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.1894223392009735, MinVal:0.2890232801437378, gp: 2.150926547983545e-06\n",
      "Train Acc:98.26%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.1975788176059723, MinVal:0.2849962115287781, gp: 2.408362433925504e-06\n",
      "Train Acc:98.84%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.10962957888841629, MinVal:0.5156780481338501, gp: 2.620478833925688e-10\n",
      "Train Acc:99.19%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.12091660499572754, MinVal:1.426398754119873, gp: 3.546938339961725e-26\n",
      "Train Acc:99.30%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.10374749451875687, MinVal:0.7118690013885498, gp: 9.185181234312376e-14\n",
      "Train Acc:99.38%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.08458521962165833, MinVal:0.9996100068092346, gp: 9.341147998311266e-19\n",
      "Train Acc:99.62%, Test Acc:98.45%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.20062588155269623, MinVal:0.26736876368522644, gp: 4.724308837467106e-06\n",
      "Train Acc:99.64%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.07659880816936493, MinVal:0.523410439491272, gp: 1.7459607370984287e-10\n",
      "Train Acc:99.82%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.15979644656181335, MinVal:1.567331075668335, gp: 1.2636389884401658e-28\n",
      "Train Acc:99.88%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.07377919554710388, MinVal:0.6888490915298462, gp: 2.3037249733716403e-13\n",
      "Train Acc:99.79%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.08139590919017792, MinVal:0.9129484295845032, gp: 3.563298864253881e-17\n",
      "Train Acc:99.94%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.1606416404247284, MinVal:1.0936317443847656, gp: 2.4826863195847326e-20\n",
      "Train Acc:99.92%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.1448880434036255, MinVal:0.5841851830482483, gp: 1.9296939046675732e-11\n",
      "Train Acc:99.91%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.07435861229896545, MinVal:0.840297520160675, gp: 5.409327631106925e-16\n",
      "Train Acc:99.86%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.05267924442887306, MinVal:0.4604933559894562, gp: 2.2740576088864373e-09\n",
      "Train Acc:99.77%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.07917898893356323, MinVal:0.4655865430831909, gp: 1.7530736862170215e-09\n",
      "Train Acc:99.86%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.11111050844192505, MinVal:0.5087257027626038, gp: 3.5266994879989966e-10\n",
      "Train Acc:99.96%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.0741930902004242, MinVal:0.44023457169532776, gp: 5.256768353945063e-09\n",
      "Train Acc:99.90%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.11856265366077423, MinVal:0.469480961561203, gp: 1.5502872319217431e-09\n",
      "Train Acc:99.95%, Test Acc:98.93%\n",
      "\n",
      "Class: 2 -> Train Acc 99.95803961060759 ; Test Acc 99.03100775193798 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.15131598711013794, MinVal:0.28388550877571106, gp: 3.2464959076605737e-06\n",
      "Train Acc:92.65%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.08617973327636719, MinVal:0.5015650987625122, gp: 5.503730804434781e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.53%, Test Acc:97.57%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.17326074838638306, MinVal:0.7949886918067932, gp: 5.109913872109384e-15\n",
      "Train Acc:98.46%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.1539234220981598, MinVal:0.6979528665542603, gp: 2.1355612861862633e-13\n",
      "Train Acc:98.70%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.10120690613985062, MinVal:0.5737210512161255, gp: 3.761188235862356e-11\n",
      "Train Acc:99.11%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.10354882478713989, MinVal:1.1201485395431519, gp: 1.0766840539138064e-20\n",
      "Train Acc:99.20%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.33571746945381165, MinVal:0.7658966779708862, gp: 2.0583403755850167e-14\n",
      "Train Acc:99.13%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.15525995194911957, MinVal:0.8028112053871155, gp: 3.2419660895731048e-15\n",
      "Train Acc:99.35%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.1693239063024521, MinVal:0.6658638119697571, gp: 7.704913638530153e-13\n",
      "Train Acc:99.45%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.06404782086610794, MinVal:0.6497134566307068, gp: 1.4695737031791833e-12\n",
      "Train Acc:99.67%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.09980639070272446, MinVal:0.572369396686554, gp: 3.241792945196664e-11\n",
      "Train Acc:99.83%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.135835200548172, MinVal:0.6177293658256531, gp: 8.699529811806439e-12\n",
      "Train Acc:99.76%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.05099234730005264, MinVal:0.29243966937065125, gp: 2.3147681531554554e-06\n",
      "Train Acc:99.62%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.09501287341117859, MinVal:0.40741732716560364, gp: 2.3845364793828594e-08\n",
      "Train Acc:99.91%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.055364493280649185, MinVal:0.7981569766998291, gp: 3.880414208950718e-15\n",
      "Train Acc:99.76%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.14964395761489868, MinVal:0.5524401068687439, gp: 9.250287341666663e-11\n",
      "Train Acc:99.67%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.08727560192346573, MinVal:0.8006352782249451, gp: 3.513176721921512e-15\n",
      "Train Acc:99.61%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.11431890726089478, MinVal:0.6947882771492004, gp: 2.4404940958747123e-13\n",
      "Train Acc:99.85%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.10655859857797623, MinVal:0.9008755683898926, gp: 1.2699547772826984e-16\n",
      "Train Acc:99.86%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.11962735652923584, MinVal:0.7258507609367371, gp: 7.395897994510667e-14\n",
      "Train Acc:99.94%, Test Acc:98.47%\n",
      "\n",
      "Class: 3 -> Train Acc 99.94291306475289 ; Test Acc 98.51485148514851 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.18136191368103027, MinVal:0.6308432221412659, gp: 1.400388052047452e-12\n",
      "Train Acc:94.52%, Test Acc:96.89%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.20130549371242523, MinVal:0.4308561086654663, gp: 3.2859479581759388e-09\n",
      "Train Acc:98.27%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.20428654551506042, MinVal:0.7047174572944641, gp: 9.900735016988432e-14\n",
      "Train Acc:98.76%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.11239311844110489, MinVal:0.3470868170261383, gp: 9.310649318194919e-08\n",
      "Train Acc:99.12%, Test Acc:98.68%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.11238445341587067, MinVal:0.19974075257778168, gp: 5.324034646037035e-05\n",
      "Train Acc:99.46%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.15296174585819244, MinVal:0.2073068767786026, gp: 3.2358799217035994e-05\n",
      "Train Acc:99.61%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.12351121753454208, MinVal:0.2609853148460388, gp: 2.9599013942060992e-06\n",
      "Train Acc:99.71%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.13935503363609314, MinVal:0.3201819062232971, gp: 7.145744689296407e-07\n",
      "Train Acc:99.51%, Test Acc:98.52%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.1012907475233078, MinVal:0.27714401483535767, gp: 1.5639542425560649e-06\n",
      "Train Acc:99.73%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.13095813989639282, MinVal:0.3085547685623169, gp: 5.317323825693165e-07\n",
      "Train Acc:99.77%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.11863049864768982, MinVal:0.36150941252708435, gp: 5.849931383750118e-08\n",
      "Train Acc:99.88%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.10888518393039703, MinVal:0.2650066316127777, gp: 2.426866103633074e-06\n",
      "Train Acc:99.96%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.10768093168735504, MinVal:0.40413227677345276, gp: 1.1444744707489463e-08\n",
      "Train Acc:99.87%, Test Acc:98.52%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.134560689330101, MinVal:0.6154618859291077, gp: 3.1829797044607977e-12\n",
      "Train Acc:99.83%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.10330948978662491, MinVal:0.3738461434841156, gp: 3.266443115990114e-08\n",
      "Train Acc:99.92%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.11424925923347473, MinVal:0.3446219861507416, gp: 1.9998579148250428e-07\n",
      "Train Acc:99.79%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.11163447797298431, MinVal:0.4117179811000824, gp: 1.77585501859312e-08\n",
      "Train Acc:99.94%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.13047046959400177, MinVal:0.4603786766529083, gp: 1.4749812482506286e-09\n",
      "Train Acc:99.97%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.13241563737392426, MinVal:0.374940425157547, gp: 5.2441873066300104e-08\n",
      "Train Acc:99.97%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.17121994495391846, MinVal:0.8096559047698975, gp: 1.437796817470641e-15\n",
      "Train Acc:99.71%, Test Acc:98.57%\n",
      "\n",
      "Class: 4 -> Train Acc 99.9743238616912 ; Test Acc 99.03258655804481 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.18898408114910126, MinVal:0.5911791324615479, gp: 4.831284677875303e-12\n",
      "Train Acc:93.37%, Test Acc:96.69%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.16284304857254028, MinVal:0.4534337818622589, gp: 1.3386417530014683e-09\n",
      "Train Acc:98.20%, Test Acc:96.36%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.1241195946931839, MinVal:0.32831379771232605, gp: 1.593867295923701e-07\n",
      "Train Acc:98.75%, Test Acc:97.70%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.2879490256309509, MinVal:0.07669788599014282, gp: 0.0013896053424105048\n",
      "Train Acc:99.05%, Test Acc:97.70%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.1232849508523941, MinVal:0.48865169286727905, gp: 2.6355895244023486e-10\n",
      "Train Acc:99.16%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.16074799001216888, MinVal:0.37137722969055176, gp: 3.710061236006368e-08\n",
      "Train Acc:99.48%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.12417952716350555, MinVal:0.3708826005458832, gp: 5.6144276783243185e-08\n",
      "Train Acc:99.54%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.13941307365894318, MinVal:0.27800121903419495, gp: 1.1701210951287067e-06\n",
      "Train Acc:99.70%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.15692822635173798, MinVal:0.47734335064888, gp: 6.199054047861807e-10\n",
      "Train Acc:99.85%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.14462973177433014, MinVal:0.49244070053100586, gp: 2.736948723214283e-10\n",
      "Train Acc:99.93%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.08674304187297821, MinVal:0.30638328194618225, gp: 6.653360173913825e-07\n",
      "Train Acc:99.93%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.1184978187084198, MinVal:0.25596901774406433, gp: 5.106517164676916e-06\n",
      "Train Acc:100.00%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.11959656327962875, MinVal:0.5783209800720215, gp: 1.5490388485805973e-11\n",
      "Train Acc:99.96%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.08478187769651413, MinVal:0.3166033923625946, gp: 2.536227441396477e-07\n",
      "Train Acc:99.97%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.09980843216180801, MinVal:0.4995601773262024, gp: 2.434066836976001e-10\n",
      "Train Acc:99.94%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.14185938239097595, MinVal:0.17817948758602142, gp: 5.6569548178231344e-05\n",
      "Train Acc:99.47%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.11431045830249786, MinVal:0.26972636580467224, gp: 1.6255494301731233e-06\n",
      "Train Acc:99.79%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.11153700202703476, MinVal:0.3331345021724701, gp: 1.3509659879673563e-07\n",
      "Train Acc:99.89%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.12827832996845245, MinVal:0.23093383014202118, gp: 7.420414476655424e-06\n",
      "Train Acc:99.92%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.15119397640228271, MinVal:0.4946289658546448, gp: 3.3418715017496936e-10\n",
      "Train Acc:99.97%, Test Acc:98.71%\n",
      "\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 98.87892376681614 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.13442397117614746, MinVal:0.7489018440246582, gp: 1.5612650197194614e-14\n",
      "Train Acc:95.76%, Test Acc:98.38%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.13354088366031647, MinVal:0.45790478587150574, gp: 1.0524083826624064e-09\n",
      "Train Acc:98.91%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.13357573747634888, MinVal:0.6962389945983887, gp: 9.029478960321732e-14\n",
      "Train Acc:99.31%, Test Acc:98.80%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:948,  Loss:0.14914003014564514, MinVal:0.9339919090270996, gp: 1.0007963105508638e-17\n",
      "Train Acc:99.56%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.16475002467632294, MinVal:0.6760039329528809, gp: 1.7137922754106166e-13\n",
      "Train Acc:99.71%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.11780828982591629, MinVal:0.9539639949798584, gp: 3.4170595358090996e-18\n",
      "Train Acc:99.78%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.15116865932941437, MinVal:0.6071357727050781, gp: 2.872603196979462e-12\n",
      "Train Acc:99.82%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.1063271313905716, MinVal:0.7239356637001038, gp: 3.132661569927621e-14\n",
      "Train Acc:99.87%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.08844780921936035, MinVal:0.5871967673301697, gp: 6.153289683341612e-12\n",
      "Train Acc:99.86%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.09612610936164856, MinVal:1.0892083644866943, gp: 1.1722016850167302e-20\n",
      "Train Acc:99.92%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.12497411668300629, MinVal:0.7679727673530579, gp: 4.725225812300844e-15\n",
      "Train Acc:99.93%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.11172374337911606, MinVal:0.8596523404121399, gp: 1.1054943308482114e-16\n",
      "Train Acc:99.85%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.08554484695196152, MinVal:1.074088454246521, gp: 2.0893761554825462e-20\n",
      "Train Acc:99.74%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.09097078442573547, MinVal:0.6850569844245911, gp: 1.1914980720811874e-13\n",
      "Train Acc:99.89%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.11966641992330551, MinVal:0.7535701394081116, gp: 1.5332382241541216e-14\n",
      "Train Acc:99.97%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.09180430322885513, MinVal:0.5470210909843445, gp: 2.979477775610917e-11\n",
      "Train Acc:99.97%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.12359567731618881, MinVal:0.8720894455909729, gp: 6.775772563622791e-17\n",
      "Train Acc:99.97%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.09623133391141891, MinVal:0.5788649916648865, gp: 8.737181117490778e-12\n",
      "Train Acc:99.98%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.10005027800798416, MinVal:0.7996137142181396, gp: 1.2191103805441177e-15\n",
      "Train Acc:99.98%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.1157580092549324, MinVal:0.6311584711074829, gp: 1.0289768169469138e-12\n",
      "Train Acc:99.96%, Test Acc:99.22%\n",
      "\n",
      "Class: 6 -> Train Acc 99.98310239945928 ; Test Acc 99.21711899791231 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.1362685114145279, MinVal:0.6346924304962158, gp: 1.4994939968523968e-12\n",
      "Train Acc:95.39%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.16040268540382385, MinVal:0.23334330320358276, gp: 9.39758956519654e-06\n",
      "Train Acc:98.57%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.23765653371810913, MinVal:0.844463050365448, gp: 2.4374648900619294e-16\n",
      "Train Acc:99.09%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.1700855940580368, MinVal:0.8825203776359558, gp: 1.0960233775322753e-16\n",
      "Train Acc:99.28%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.12796476483345032, MinVal:0.6275359392166138, gp: 1.427412550138174e-12\n",
      "Train Acc:99.52%, Test Acc:98.44%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.1345500349998474, MinVal:0.6014655232429504, gp: 4.073462487458324e-12\n",
      "Train Acc:99.63%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.13933689892292023, MinVal:0.8862304091453552, gp: 4.576550116006017e-17\n",
      "Train Acc:99.75%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.16103419661521912, MinVal:0.7253299355506897, gp: 2.855380591259421e-14\n",
      "Train Acc:99.86%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.08017157018184662, MinVal:0.658001720905304, gp: 4.2195882747099456e-13\n",
      "Train Acc:99.70%, Test Acc:98.39%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.09641002118587494, MinVal:0.834699273109436, gp: 3.799038324339899e-16\n",
      "Train Acc:99.86%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.06781066954135895, MinVal:0.6624426245689392, gp: 3.536992747299461e-13\n",
      "Train Acc:99.89%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.08334879577159882, MinVal:0.7253928184509277, gp: 2.848252300788508e-14\n",
      "Train Acc:99.82%, Test Acc:98.44%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.09385475516319275, MinVal:0.720305323600769, gp: 3.5795090578671224e-14\n",
      "Train Acc:99.84%, Test Acc:98.44%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.14464923739433289, MinVal:0.6047651767730713, gp: 3.818661099136422e-12\n",
      "Train Acc:99.89%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.11978220194578171, MinVal:0.9384933710098267, gp: 8.214557782516094e-18\n",
      "Train Acc:99.86%, Test Acc:98.39%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.1080923080444336, MinVal:0.640353798866272, gp: 8.683251600388742e-13\n",
      "Train Acc:99.92%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.1233147457242012, MinVal:0.7627256512641907, gp: 8.531982459674802e-15\n",
      "Train Acc:99.96%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.12844227254390717, MinVal:0.7435104846954346, gp: 1.552357960059314e-14\n",
      "Train Acc:99.92%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.10700391978025436, MinVal:0.5539175868034363, gp: 2.720264812017259e-11\n",
      "Train Acc:99.91%, Test Acc:98.39%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.091748908162117, MinVal:0.8235521912574768, gp: 5.751906400854783e-16\n",
      "Train Acc:99.99%, Test Acc:98.59%\n",
      "\n",
      "Class: 7 -> Train Acc 99.99201915403033 ; Test Acc 98.68677042801556 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.7265719771385193, MinVal:0.7382984161376953, gp: 2.549585163217488e-13\n",
      "Train Acc:91.11%, Test Acc:97.38%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.18748044967651367, MinVal:0.6192325353622437, gp: 2.9843107152149884e-11\n",
      "Train Acc:97.33%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.02470550686120987, MinVal:0.5767345428466797, gp: 1.6333955021874402e-10\n",
      "Train Acc:98.29%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.009815765544772148, MinVal:0.44901034235954285, gp: 2.7009431136093554e-08\n",
      "Train Acc:98.94%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.037004079669713974, MinVal:1.8842031955718994, gp: 3.162763794487338e-33\n",
      "Train Acc:99.23%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.019516538828611374, MinVal:0.7857982516288757, gp: 4.9897118500809995e-14\n",
      "Train Acc:99.23%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.15936778485774994, MinVal:0.7176067233085632, gp: 5.833390411338901e-13\n",
      "Train Acc:99.40%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.006272529251873493, MinVal:4.514374256134033, gp: 0.0\n",
      "Train Acc:98.96%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.14450490474700928, MinVal:2.0557198524475098, gp: 3.315278989191419e-36\n",
      "Train Acc:99.53%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.013400744646787643, MinVal:3.2265865802764893, gp: 0.0\n",
      "Train Acc:99.53%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.12227661162614822, MinVal:3.1594078540802, gp: 0.0\n",
      "Train Acc:99.49%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.012462163344025612, MinVal:1.1289582252502441, gp: 4.168836160254686e-20\n",
      "Train Acc:99.29%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.2822510004043579, MinVal:1.6490601301193237, gp: 3.845242212929625e-29\n",
      "Train Acc:99.78%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.022118808701634407, MinVal:2.45168137550354, gp: 4.372051208693429e-43\n",
      "Train Acc:99.83%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.02192053012549877, MinVal:1.7759701013565063, gp: 2.400312444605078e-31\n",
      "Train Acc:99.82%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.020592333748936653, MinVal:1.0355066061019897, gp: 1.7516016827856453e-18\n",
      "Train Acc:99.91%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.2251790314912796, MinVal:1.262006163597107, gp: 2.0363303259867108e-22\n",
      "Train Acc:99.95%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.03132738918066025, MinVal:0.7270721793174744, gp: 3.994749951836962e-13\n",
      "Train Acc:99.87%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.028522055596113205, MinVal:1.22096848487854, gp: 1.257559090582995e-21\n",
      "Train Acc:99.78%, Test Acc:98.87%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.017473232001066208, MinVal:1.5719356536865234, gp: 8.42173920162556e-28\n",
      "Train Acc:99.82%, Test Acc:98.56%\n",
      "\n",
      "Class: 8 -> Train Acc 99.94872671338233 ; Test Acc 98.870636550308 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.19713659584522247, MinVal:0.6202241778373718, gp: 1.268698362512366e-12\n",
      "Train Acc:92.39%, Test Acc:97.32%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.16437160968780518, MinVal:0.7478218674659729, gp: 8.926328812664409e-15\n",
      "Train Acc:97.25%, Test Acc:96.53%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.13442760705947876, MinVal:0.6809160113334656, gp: 1.0574037441002729e-13\n",
      "Train Acc:98.14%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.08500921726226807, MinVal:0.36218807101249695, gp: 6.55160192764015e-08\n",
      "Train Acc:98.71%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.1245371475815773, MinVal:0.6764745116233826, gp: 1.367381007684118e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.92%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.13855057954788208, MinVal:0.4298012852668762, gp: 2.4957966804350917e-09\n",
      "Train Acc:99.10%, Test Acc:97.22%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.09654280543327332, MinVal:0.2932624816894531, gp: 8.647716640552972e-07\n",
      "Train Acc:99.43%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.12180519849061966, MinVal:0.35416877269744873, gp: 5.718214879379957e-08\n",
      "Train Acc:99.58%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.16496817767620087, MinVal:0.7273879051208496, gp: 1.6435898459290013e-14\n",
      "Train Acc:99.55%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.18350648880004883, MinVal:0.51267009973526, gp: 8.824947023144958e-11\n",
      "Train Acc:99.54%, Test Acc:97.52%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.14697112143039703, MinVal:0.64967942237854, gp: 3.761438860036548e-13\n",
      "Train Acc:99.39%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.14486636221408844, MinVal:1.1981333494186401, gp: 1.0920546085417867e-22\n",
      "Train Acc:99.48%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.10552529245615005, MinVal:0.7577562928199768, gp: 4.877994980601735e-15\n",
      "Train Acc:99.65%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.12948842346668243, MinVal:0.7895697951316833, gp: 1.3664565262793316e-15\n",
      "Train Acc:99.82%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.14231449365615845, MinVal:0.9305605888366699, gp: 4.8585760223669914e-18\n",
      "Train Acc:99.88%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.12469637393951416, MinVal:1.2341147661209106, gp: 3.623872066303543e-23\n",
      "Train Acc:99.96%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.10880991071462631, MinVal:0.9935494065284729, gp: 4.187309235908012e-19\n",
      "Train Acc:99.94%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.09898307174444199, MinVal:0.9851894378662109, gp: 6.297165220134635e-19\n",
      "Train Acc:99.92%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.1265125274658203, MinVal:0.8702146410942078, gp: 7.622534857380664e-17\n",
      "Train Acc:99.32%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.10256906598806381, MinVal:0.8021634817123413, gp: 8.256911580548402e-16\n",
      "Train Acc:99.76%, Test Acc:98.32%\n",
      "\n",
      "Class: 9 -> Train Acc 99.95797613044209 ; Test Acc 98.61248761149653 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    lips_net = nn.Sequential(nn.Linear(784, 200),\n",
    "                       actf(),\n",
    "                       nn.Linear(200,100),\n",
    "                       actf(),\n",
    "                       nn.Linear(100,1))\n",
    "    Net = BasicInvexNet(784, lips_net, lambda_)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if use_check and epoch%check_every == 0:\n",
    "                rand_inp = torch.rand(check_size, 784)*m_+s_\n",
    "                Net(rand_inp)\n",
    "                Net.compute_penalty_and_clipper()\n",
    "                Net.gp.backward(retain_graph=True)\n",
    "            \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))   \n",
    "            Net.compute_penalty_and_clipper()\n",
    "            loss = criterion(yout, y_mix) + Net.gp\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        min_val, gp = float(Net.cond.min()) , float(Net.gp)\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}, MinVal:{min_val}, gp: {gp}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "#                     with torch.no_grad():\n",
    "            yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.48979591836735\n",
      "Class: 1 -> Train Acc 99.98516760605162 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.95803961060759 ; Test Acc 99.03100775193798\n",
      "Class: 3 -> Train Acc 99.94291306475289 ; Test Acc 98.51485148514851\n",
      "Class: 4 -> Train Acc 99.9743238616912 ; Test Acc 99.03258655804481\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 98.87892376681614\n",
      "Class: 6 -> Train Acc 99.98310239945928 ; Test Acc 99.21711899791231\n",
      "Class: 7 -> Train Acc 99.99201915403033 ; Test Acc 98.68677042801556\n",
      "Class: 8 -> Train Acc 99.94872671338233 ; Test Acc 98.870636550308\n",
      "Class: 9 -> Train Acc 99.95797613044209 ; Test Acc 98.61248761149653\n",
      "Total Accuracy (Argmax) is : 0.9753000140190125\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 70000 input points\n",
      "Class: 1 -> Correct 99.9971% on 70000 input points\n",
      "Class: 2 -> Correct 100.0000% on 70000 input points\n",
      "Class: 3 -> Correct 99.9843% on 70000 input points\n",
      "Class: 4 -> Correct 99.9971% on 70000 input points\n",
      "Class: 5 -> Correct 100.0000% on 70000 input points\n",
      "Class: 6 -> Correct 99.9986% on 70000 input points\n",
      "Class: 7 -> Correct 100.0000% on 70000 input points\n",
      "Class: 8 -> Correct 99.9986% on 70000 input points\n",
      "Class: 9 -> Correct 99.9871% on 70000 input points\n"
     ]
    }
   ],
   "source": [
    "## only on training and testing data\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:03<00:00, 316.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:10<00:00, 282.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1 -> Correct 99.9998% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:11<00:00, 278.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 2 -> Correct 89.5211% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:09<00:00, 287.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 3 -> Correct 73.8646% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:12<00:00, 274.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 4 -> Correct 99.9998% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:10<00:00, 283.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 5 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:11<00:00, 281.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 6 -> Correct 97.2588% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:10<00:00, 281.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 7 -> Correct 33.2285% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:12<00:00, 277.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 8 -> Correct 99.9999% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [01:09<00:00, 288.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 9 -> Correct 99.9985% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Check the constraint on large number of points, including training and test data.\n",
    "from tqdm import tqdm\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    for i in tqdm(range(20000)):\n",
    "        xx = torch.rand(batch_size, 784)\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
