{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, os, pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_seeds = [147, 258, 369]\n",
    "# network_seeds = [369]\n",
    "network_seed = 369\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "actf = nn.LeakyReLU\n",
    "# actf = nn.ELU\n",
    "\n",
    "learning_rate = 0.005\n",
    "lambda_ = 2\n",
    "criterion = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "use_mixup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_OneClass_Balanced(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label, class_index):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.class_index = class_index\n",
    "        \n",
    "        mask = (label==class_index)\n",
    "        self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self.class_data = torch.nonzero(mask).reshape(-1)\n",
    "        self.other_data = torch.nonzero(~mask).reshape(-1)\n",
    "        \n",
    "        random.seed(network_seed)\n",
    "        self._shuffle_data_()\n",
    "        self.count = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2*len(self.class_data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "#         randidx = np.random.permutation(len(self.other_data))\n",
    "        randidx = random.sample(range(len(self.other_data)), k=len(self.other_data))\n",
    "        self.other_data = self.other_data[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.class_data):\n",
    "            idx = self.class_data[idx]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            idx = self.other_data[idx-len(self.class_data)]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "            self.count += 1\n",
    "            if self.count >= len(self.class_data): \n",
    "                self._shuffle_data_()\n",
    "                self.count = 0\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "# test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_all = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "# test_loader_all = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # img, lbl = train_dataset[11010]\n",
    "# img, lbl = test_dataset[10]\n",
    "# print(lbl)\n",
    "# plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnivariateCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels:list, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        assert len(channels)>1\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(channels)-1):\n",
    "            la = nn.Conv2d(channels[i], channels[i+1], kernel_size=(5,5), stride=2, padding=1)\n",
    "            layers.append(la)\n",
    "            layers.append(actf())\n",
    "        layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(channels[-1], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1, 28, 28)\n",
    "        x = self.features(x)\n",
    "        s = x.shape\n",
    "        return self.fc(x.reshape(s[0], s[1]))    \n",
    "    \n",
    "\n",
    "class ConvexCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels:list, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        assert len(channels)>1\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(channels)-1):\n",
    "            la = nn.Conv2d(channels[i], channels[i+1], kernel_size=(5,5), stride=2, padding=1)\n",
    "            layers.append(la)\n",
    "            if i>0:\n",
    "                layers[-1].weight.data *= 0.2\n",
    "            layers.append(actf())\n",
    "        layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(channels[-1], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,28, 28)\n",
    "        for i in range(2, len(self.features)-1, 2):\n",
    "            self.features[i].weight.data.abs_()\n",
    "        for i in range(0, len(self.fc), 2):\n",
    "            self.fc[i].weight.data.abs_()\n",
    "            \n",
    "        x = self.features(x)\n",
    "        s = x.shape\n",
    "        return self.fc(x.reshape(s[0], s[1]))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5963],\n",
       "        [3.4754]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnn = UnivariateCNN([1, 16, 32, 64])\n",
    "cnn = ConvexCNN([1, 16, 32, 64])\n",
    "cnn(torch.randn(2,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 8, 8]), torch.Size([2, 1, 14, 14]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Sequential(nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2),\n",
    "             nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2))\n",
    "# b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=4)\n",
    "b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2, dilation=2)\n",
    "x = torch.randn(2,1,32,32)\n",
    "\n",
    "a(x).shape, b(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 4, 4]), torch.Size([2, 1, 4, 4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Sequential(nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2),\n",
    "                 nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2),\n",
    "                 nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2))\n",
    "b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=4, dilation=4)\n",
    "x = torch.randn(2,1,28,28)\n",
    "# nn.Conv2d()\n",
    "\n",
    "a(x).shape, b(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.502179741859436\n",
      "Train Acc:71.64%, Test Acc:74.69%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.41291874647140503\n",
      "Train Acc:84.88%, Test Acc:87.40%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.2867847979068756\n",
      "Train Acc:89.68%, Test Acc:75.87%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.23302306234836578\n",
      "Train Acc:91.80%, Test Acc:87.96%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.28443029522895813\n",
      "Train Acc:92.55%, Test Acc:88.98%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.2573814392089844\n",
      "Train Acc:92.99%, Test Acc:94.54%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.20436663925647736\n",
      "Train Acc:93.89%, Test Acc:90.31%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.2413509041070938\n",
      "Train Acc:93.53%, Test Acc:91.38%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.1579991579055786\n",
      "Train Acc:94.61%, Test Acc:90.51%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.17704105377197266\n",
      "Train Acc:94.43%, Test Acc:95.00%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.25889015197753906\n",
      "Train Acc:94.83%, Test Acc:93.88%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.1945742964744568\n",
      "Train Acc:95.03%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.11924849450588226\n",
      "Train Acc:95.13%, Test Acc:91.94%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.23458383977413177\n",
      "Train Acc:95.59%, Test Acc:93.16%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.20232556760311127\n",
      "Train Acc:95.27%, Test Acc:95.87%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.22026963531970978\n",
      "Train Acc:95.57%, Test Acc:94.69%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.1565781682729721\n",
      "Train Acc:95.69%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.2716021239757538\n",
      "Train Acc:95.88%, Test Acc:95.46%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.20637591183185577\n",
      "Train Acc:95.89%, Test Acc:96.07%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.20821385085582733\n",
      "Train Acc:96.08%, Test Acc:95.15%\n",
      "\n",
      "Class: 0 -> Train Acc 96.08306601384433 ; Test Acc 96.3265306122449 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.3049895763397217\n",
      "Train Acc:81.69%, Test Acc:92.51%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.23263108730316162\n",
      "Train Acc:95.31%, Test Acc:94.41%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.1536022573709488\n",
      "Train Acc:96.78%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.18918372690677643\n",
      "Train Acc:97.37%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.27494099736213684\n",
      "Train Acc:97.78%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.18580077588558197\n",
      "Train Acc:97.85%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.17363472282886505\n",
      "Train Acc:98.00%, Test Acc:98.33%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.1995394080877304\n",
      "Train Acc:97.95%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.1087968498468399\n",
      "Train Acc:98.04%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.10375559329986572\n",
      "Train Acc:98.05%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.18286070227622986\n",
      "Train Acc:98.06%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.2490338385105133\n",
      "Train Acc:98.10%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.13962045311927795\n",
      "Train Acc:98.11%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.17422325909137726\n",
      "Train Acc:98.15%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.18371887505054474\n",
      "Train Acc:98.30%, Test Acc:98.94%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.19604654610157013\n",
      "Train Acc:98.16%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.24602441489696503\n",
      "Train Acc:98.29%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.23272641003131866\n",
      "Train Acc:98.48%, Test Acc:98.94%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.1423395425081253\n",
      "Train Acc:98.21%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.13498681783676147\n",
      "Train Acc:98.41%, Test Acc:98.59%\n",
      "\n",
      "Class: 1 -> Train Acc 98.47967962029071 ; Test Acc 98.98678414096916 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.5215120911598206\n",
      "Train Acc:72.69%, Test Acc:76.99%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.34391874074935913\n",
      "Train Acc:84.52%, Test Acc:84.98%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.23404069244861603\n",
      "Train Acc:89.27%, Test Acc:83.43%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.5562332272529602\n",
      "Train Acc:91.50%, Test Acc:91.13%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.16792455315589905\n",
      "Train Acc:92.48%, Test Acc:90.21%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.10398342460393906\n",
      "Train Acc:93.86%, Test Acc:95.20%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.13363231718540192\n",
      "Train Acc:93.45%, Test Acc:92.93%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.3874112665653229\n",
      "Train Acc:94.12%, Test Acc:95.78%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.24875637888908386\n",
      "Train Acc:94.49%, Test Acc:94.72%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.2708955407142639\n",
      "Train Acc:94.58%, Test Acc:94.67%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.2984393239021301\n",
      "Train Acc:94.95%, Test Acc:94.96%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.25883767008781433\n",
      "Train Acc:95.48%, Test Acc:95.69%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.1871442198753357\n",
      "Train Acc:95.19%, Test Acc:95.78%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.22082757949829102\n",
      "Train Acc:95.64%, Test Acc:96.08%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.2539908289909363\n",
      "Train Acc:95.62%, Test Acc:94.48%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.20333337783813477\n",
      "Train Acc:95.76%, Test Acc:95.59%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.20425382256507874\n",
      "Train Acc:95.85%, Test Acc:95.74%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.1659824699163437\n",
      "Train Acc:96.07%, Test Acc:94.14%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.07975003123283386\n",
      "Train Acc:95.96%, Test Acc:97.14%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.1587374210357666\n",
      "Train Acc:96.02%, Test Acc:94.91%\n",
      "\n",
      "Class: 2 -> Train Acc 96.07250755287009 ; Test Acc 97.14147286821705 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.36400243639945984\n",
      "Train Acc:78.54%, Test Acc:87.72%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.4198724925518036\n",
      "Train Acc:90.86%, Test Acc:92.13%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.3824049234390259\n",
      "Train Acc:92.59%, Test Acc:90.10%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.09967142343521118\n",
      "Train Acc:93.24%, Test Acc:95.40%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.29864493012428284\n",
      "Train Acc:94.03%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.11428874731063843\n",
      "Train Acc:94.47%, Test Acc:91.34%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.19411815702915192\n",
      "Train Acc:94.49%, Test Acc:96.14%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.2013624906539917\n",
      "Train Acc:94.37%, Test Acc:91.93%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.208204448223114\n",
      "Train Acc:95.38%, Test Acc:92.18%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.16473735868930817\n",
      "Train Acc:95.22%, Test Acc:94.21%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.24540506303310394\n",
      "Train Acc:95.46%, Test Acc:95.50%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.42531049251556396\n",
      "Train Acc:95.34%, Test Acc:95.84%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.27410340309143066\n",
      "Train Acc:95.59%, Test Acc:92.33%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.07386313378810883\n",
      "Train Acc:95.59%, Test Acc:90.99%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.14284859597682953\n",
      "Train Acc:95.96%, Test Acc:95.15%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.41901978850364685\n",
      "Train Acc:95.78%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.1198115274310112\n",
      "Train Acc:95.76%, Test Acc:95.00%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.30823859572410583\n",
      "Train Acc:96.10%, Test Acc:93.42%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.13909952342510223\n",
      "Train Acc:96.09%, Test Acc:93.42%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.25714269280433655\n",
      "Train Acc:96.19%, Test Acc:97.33%\n",
      "\n",
      "Class: 3 -> Train Acc 96.19148589137171 ; Test Acc 97.32673267326733 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.38753607869148254\n",
      "Train Acc:75.93%, Test Acc:86.15%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.21488171815872192\n",
      "Train Acc:92.49%, Test Acc:93.69%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.18841128051280975\n",
      "Train Acc:93.58%, Test Acc:93.43%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.2030428647994995\n",
      "Train Acc:94.04%, Test Acc:94.45%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.19239889085292816\n",
      "Train Acc:94.66%, Test Acc:95.26%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.2936701774597168\n",
      "Train Acc:95.35%, Test Acc:94.96%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.26789140701293945\n",
      "Train Acc:95.29%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.17208963632583618\n",
      "Train Acc:95.53%, Test Acc:95.26%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.1543252170085907\n",
      "Train Acc:95.50%, Test Acc:93.99%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.2604433000087738\n",
      "Train Acc:95.81%, Test Acc:96.59%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.22520974278450012\n",
      "Train Acc:96.02%, Test Acc:96.03%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.21994753181934357\n",
      "Train Acc:95.86%, Test Acc:96.79%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.25202298164367676\n",
      "Train Acc:96.15%, Test Acc:93.13%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.17161603271961212\n",
      "Train Acc:96.22%, Test Acc:95.77%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.12717881798744202\n",
      "Train Acc:96.19%, Test Acc:96.95%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.12906219065189362\n",
      "Train Acc:96.47%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.20655637979507446\n",
      "Train Acc:96.61%, Test Acc:95.01%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.11096647381782532\n",
      "Train Acc:96.54%, Test Acc:96.44%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.1482575684785843\n",
      "Train Acc:96.78%, Test Acc:97.05%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.15220344066619873\n",
      "Train Acc:96.53%, Test Acc:97.51%\n",
      "\n",
      "Class: 4 -> Train Acc 96.7819239986306 ; Test Acc 97.50509164969449 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.5320016145706177\n",
      "Train Acc:76.56%, Test Acc:87.44%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.2767752707004547\n",
      "Train Acc:89.67%, Test Acc:85.26%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.2470032125711441\n",
      "Train Acc:92.68%, Test Acc:91.93%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.2119303047657013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.29%, Test Acc:93.83%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.24745318293571472\n",
      "Train Acc:94.83%, Test Acc:96.13%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.20287036895751953\n",
      "Train Acc:95.03%, Test Acc:95.80%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.1972137689590454\n",
      "Train Acc:95.42%, Test Acc:96.30%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.25880295038223267\n",
      "Train Acc:95.67%, Test Acc:95.63%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.2320770025253296\n",
      "Train Acc:95.99%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.246842160820961\n",
      "Train Acc:96.19%, Test Acc:93.05%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.14881765842437744\n",
      "Train Acc:96.37%, Test Acc:96.64%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.22326210141181946\n",
      "Train Acc:96.26%, Test Acc:96.86%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.1039741262793541\n",
      "Train Acc:96.19%, Test Acc:96.36%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.11739006638526917\n",
      "Train Acc:96.35%, Test Acc:96.75%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.22225986421108246\n",
      "Train Acc:96.55%, Test Acc:96.08%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.1546502411365509\n",
      "Train Acc:96.57%, Test Acc:95.18%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.19527067244052887\n",
      "Train Acc:97.12%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1869395524263382\n",
      "Train Acc:96.74%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.2033744752407074\n",
      "Train Acc:96.76%, Test Acc:95.35%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.22633236646652222\n",
      "Train Acc:96.80%, Test Acc:95.46%\n",
      "\n",
      "Class: 5 -> Train Acc 97.12230215827337 ; Test Acc 96.8609865470852 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.45146259665489197\n",
      "Train Acc:73.17%, Test Acc:83.77%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.29003527760505676\n",
      "Train Acc:88.08%, Test Acc:90.34%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.27394187450408936\n",
      "Train Acc:91.89%, Test Acc:91.70%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.2669994533061981\n",
      "Train Acc:93.33%, Test Acc:92.01%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.2322641760110855\n",
      "Train Acc:94.44%, Test Acc:94.73%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.20111268758773804\n",
      "Train Acc:94.90%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.24041244387626648\n",
      "Train Acc:95.53%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.22514605522155762\n",
      "Train Acc:95.71%, Test Acc:95.62%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.08743688464164734\n",
      "Train Acc:95.82%, Test Acc:94.10%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.16983644664287567\n",
      "Train Acc:95.96%, Test Acc:96.09%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.1806136518716812\n",
      "Train Acc:96.18%, Test Acc:96.09%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.1829453408718109\n",
      "Train Acc:96.49%, Test Acc:95.46%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.21392515301704407\n",
      "Train Acc:96.48%, Test Acc:92.38%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.1730395406484604\n",
      "Train Acc:96.73%, Test Acc:96.76%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.18922732770442963\n",
      "Train Acc:96.70%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.14906415343284607\n",
      "Train Acc:96.93%, Test Acc:95.82%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.15048113465309143\n",
      "Train Acc:97.09%, Test Acc:96.24%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.27472180128097534\n",
      "Train Acc:96.95%, Test Acc:96.50%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.16461987793445587\n",
      "Train Acc:97.22%, Test Acc:95.77%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.19615615904331207\n",
      "Train Acc:97.20%, Test Acc:97.55%\n",
      "\n",
      "Class: 6 -> Train Acc 97.22034471105103 ; Test Acc 97.54697286012527 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.38477838039398193\n",
      "Train Acc:74.76%, Test Acc:88.52%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.3609587550163269\n",
      "Train Acc:88.66%, Test Acc:88.72%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.2649296522140503\n",
      "Train Acc:90.02%, Test Acc:88.38%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.5421812534332275\n",
      "Train Acc:91.40%, Test Acc:92.90%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.15951567888259888\n",
      "Train Acc:92.27%, Test Acc:91.05%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.17919674515724182\n",
      "Train Acc:92.80%, Test Acc:90.27%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.23877331614494324\n",
      "Train Acc:93.17%, Test Acc:92.02%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.1905001699924469\n",
      "Train Acc:93.73%, Test Acc:93.58%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.12212669849395752\n",
      "Train Acc:94.96%, Test Acc:93.58%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.17683497071266174\n",
      "Train Acc:95.16%, Test Acc:91.44%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.19412606954574585\n",
      "Train Acc:95.20%, Test Acc:96.21%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.13292540609836578\n",
      "Train Acc:95.00%, Test Acc:95.09%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.1526222676038742\n",
      "Train Acc:95.36%, Test Acc:94.46%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.17924313247203827\n",
      "Train Acc:95.28%, Test Acc:92.90%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.1256081610918045\n",
      "Train Acc:95.79%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.21697737276554108\n",
      "Train Acc:95.77%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.1815153807401657\n",
      "Train Acc:95.86%, Test Acc:95.57%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.3039509654045105\n",
      "Train Acc:95.87%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.23387674987316132\n",
      "Train Acc:96.17%, Test Acc:95.57%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.21392202377319336\n",
      "Train Acc:96.19%, Test Acc:95.67%\n",
      "\n",
      "Class: 7 -> Train Acc 96.19313647246608 ; Test Acc 96.20622568093385 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.3553699851036072\n",
      "Train Acc:68.14%, Test Acc:78.44%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.46738600730895996\n",
      "Train Acc:84.46%, Test Acc:90.45%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.3319067060947418\n",
      "Train Acc:88.09%, Test Acc:90.91%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.06030808761715889\n",
      "Train Acc:89.62%, Test Acc:90.81%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.18988287448883057\n",
      "Train Acc:90.06%, Test Acc:88.04%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.032246723771095276\n",
      "Train Acc:89.96%, Test Acc:85.11%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.5488424897193909\n",
      "Train Acc:91.35%, Test Acc:90.14%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.37722599506378174\n",
      "Train Acc:91.15%, Test Acc:91.43%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.368284672498703\n",
      "Train Acc:92.31%, Test Acc:86.04%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.15314382314682007\n",
      "Train Acc:92.02%, Test Acc:86.24%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.06571659445762634\n",
      "Train Acc:92.58%, Test Acc:90.20%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.01851539872586727\n",
      "Train Acc:93.08%, Test Acc:95.17%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.10901562869548798\n",
      "Train Acc:93.28%, Test Acc:93.48%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.3322601020336151\n",
      "Train Acc:92.80%, Test Acc:69.92%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.057519230991601944\n",
      "Train Acc:92.89%, Test Acc:93.02%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.06542561948299408\n",
      "Train Acc:93.97%, Test Acc:87.32%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.062069252133369446\n",
      "Train Acc:93.86%, Test Acc:93.38%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.21713480353355408\n",
      "Train Acc:93.98%, Test Acc:96.15%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.0016676465747877955\n",
      "Train Acc:93.84%, Test Acc:85.93%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.6321905255317688\n",
      "Train Acc:93.86%, Test Acc:94.82%\n",
      "\n",
      "Class: 8 -> Train Acc 93.98393437019314 ; Test Acc 96.14989733059548 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.5557764172554016\n",
      "Train Acc:62.51%, Test Acc:77.80%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.44062796235084534\n",
      "Train Acc:81.38%, Test Acc:82.51%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.43716883659362793\n",
      "Train Acc:84.43%, Test Acc:83.94%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.5365292429924011\n",
      "Train Acc:85.98%, Test Acc:84.24%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.33263054490089417\n",
      "Train Acc:87.83%, Test Acc:85.38%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.2545408010482788\n",
      "Train Acc:88.63%, Test Acc:82.85%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.2639926075935364\n",
      "Train Acc:88.81%, Test Acc:87.36%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.23239368200302124\n",
      "Train Acc:89.82%, Test Acc:87.96%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.3330628573894501\n",
      "Train Acc:89.88%, Test Acc:90.39%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.2570061683654785\n",
      "Train Acc:90.59%, Test Acc:84.69%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.22767110168933868\n",
      "Train Acc:91.09%, Test Acc:88.06%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.28113552927970886\n",
      "Train Acc:90.91%, Test Acc:85.68%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.27548906207084656\n",
      "Train Acc:91.47%, Test Acc:89.74%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.2682812511920929\n",
      "Train Acc:91.96%, Test Acc:87.76%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.21408097445964813\n",
      "Train Acc:91.96%, Test Acc:86.27%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.2777880132198334\n",
      "Train Acc:91.63%, Test Acc:85.43%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.41210389137268066\n",
      "Train Acc:92.02%, Test Acc:82.71%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.3897702991962433\n",
      "Train Acc:92.15%, Test Acc:90.83%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.2757926881313324\n",
      "Train Acc:92.21%, Test Acc:90.54%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.2191687673330307\n",
      "Train Acc:92.49%, Test Acc:91.97%\n",
      "\n",
      "Class: 9 -> Train Acc 92.49453689695747 ; Test Acc 91.97224975222993 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = ConvexCNN([1, 16, 32], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "            with torch.no_grad():\n",
    "                yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 96.08306601384433 ; Test Acc 96.3265306122449\n",
      "Class: 1 -> Train Acc 98.47967962029071 ; Test Acc 98.98678414096916\n",
      "Class: 2 -> Train Acc 96.07250755287009 ; Test Acc 97.14147286821705\n",
      "Class: 3 -> Train Acc 96.19148589137171 ; Test Acc 97.32673267326733\n",
      "Class: 4 -> Train Acc 96.7819239986306 ; Test Acc 97.50509164969449\n",
      "Class: 5 -> Train Acc 97.12230215827337 ; Test Acc 96.8609865470852\n",
      "Class: 6 -> Train Acc 97.22034471105103 ; Test Acc 97.54697286012527\n",
      "Class: 7 -> Train Acc 96.19313647246608 ; Test Acc 96.20622568093385\n",
      "Class: 8 -> Train Acc 93.98393437019314 ; Test Acc 96.14989733059548\n",
      "Class: 9 -> Train Acc 92.49453689695747 ; Test Acc 91.97224975222993\n",
      "Total Accuracy (Argmax) is : 0.9412000179290771\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.1804620772600174\n",
      "Train Acc:86.23%, Test Acc:94.74%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.18958808481693268\n",
      "Train Acc:95.75%, Test Acc:97.04%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.198486790060997\n",
      "Train Acc:97.21%, Test Acc:97.24%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.17238833010196686\n",
      "Train Acc:97.78%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.13299264013767242\n",
      "Train Acc:98.27%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.17925728857517242\n",
      "Train Acc:98.51%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.14914283156394958\n",
      "Train Acc:98.73%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.13187280297279358\n",
      "Train Acc:98.97%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.12645836174488068\n",
      "Train Acc:99.09%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.18057182431221008\n",
      "Train Acc:99.17%, Test Acc:98.62%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.16148313879966736\n",
      "Train Acc:99.07%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.15103358030319214\n",
      "Train Acc:99.21%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.11444096267223358\n",
      "Train Acc:99.28%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.12282464653253555\n",
      "Train Acc:99.38%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.13376066088676453\n",
      "Train Acc:99.38%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1522301733493805\n",
      "Train Acc:99.51%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.1224607452750206\n",
      "Train Acc:99.47%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.17246827483177185\n",
      "Train Acc:99.60%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.1187882199883461\n",
      "Train Acc:99.62%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.11299744993448257\n",
      "Train Acc:99.59%, Test Acc:99.54%\n",
      "\n",
      "Class: 0 -> Train Acc 99.62012493668749 ; Test Acc 99.64285714285714 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.13804267346858978\n",
      "Train Acc:94.09%, Test Acc:98.85%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.1511746495962143\n",
      "Train Acc:98.37%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.11808193475008011\n",
      "Train Acc:98.61%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.15926505625247955\n",
      "Train Acc:98.80%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.14788022637367249\n",
      "Train Acc:98.80%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.12266390770673752\n",
      "Train Acc:98.80%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.09441517293453217\n",
      "Train Acc:99.03%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.11606942862272263\n",
      "Train Acc:99.01%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.10212311148643494\n",
      "Train Acc:99.22%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.1256958246231079\n",
      "Train Acc:99.25%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.12172568589448929\n",
      "Train Acc:99.33%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.19803737103939056\n",
      "Train Acc:99.39%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.0962444469332695\n",
      "Train Acc:99.40%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.14714877307415009\n",
      "Train Acc:99.50%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.13801109790802002\n",
      "Train Acc:99.53%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.12461511045694351\n",
      "Train Acc:99.47%, Test Acc:99.07%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.1490289270877838\n",
      "Train Acc:99.55%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.13564050197601318\n",
      "Train Acc:99.64%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.11279543489217758\n",
      "Train Acc:99.58%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.08764942735433578\n",
      "Train Acc:99.67%, Test Acc:99.07%\n",
      "\n",
      "Class: 1 -> Train Acc 99.67368733313556 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.37959763407707214\n",
      "Train Acc:83.21%, Test Acc:90.36%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.2376047819852829\n",
      "Train Acc:93.43%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.2014264464378357\n",
      "Train Acc:95.42%, Test Acc:96.17%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.20733661949634552\n",
      "Train Acc:96.37%, Test Acc:96.56%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.14069752395153046\n",
      "Train Acc:97.15%, Test Acc:96.03%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.12020328640937805\n",
      "Train Acc:97.61%, Test Acc:95.69%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.13407845795154572\n",
      "Train Acc:97.82%, Test Acc:97.63%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.2529689371585846\n",
      "Train Acc:97.85%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.1741374284029007\n",
      "Train Acc:97.98%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.10230457782745361\n",
      "Train Acc:98.25%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.1652321219444275\n",
      "Train Acc:98.36%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.20071864128112793\n",
      "Train Acc:98.52%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.17944419384002686\n",
      "Train Acc:98.54%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.19315506517887115\n",
      "Train Acc:98.70%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.07995714247226715\n",
      "Train Acc:98.69%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.09391672164201736\n",
      "Train Acc:98.81%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.15205185115337372\n",
      "Train Acc:98.98%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.07819971442222595\n",
      "Train Acc:98.98%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.1429133266210556\n",
      "Train Acc:98.98%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.11101866513490677\n",
      "Train Acc:99.12%, Test Acc:98.69%\n",
      "\n",
      "Class: 2 -> Train Acc 99.11883182275932 ; Test Acc 98.74031007751938 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.19830000400543213\n",
      "Train Acc:82.93%, Test Acc:95.59%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.3743743896484375\n",
      "Train Acc:96.37%, Test Acc:97.43%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.15018106997013092\n",
      "Train Acc:97.68%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.08567086607217789\n",
      "Train Acc:98.10%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.1337411254644394\n",
      "Train Acc:98.12%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.09745374321937561\n",
      "Train Acc:98.34%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.11519807577133179\n",
      "Train Acc:98.65%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.11190500110387802\n",
      "Train Acc:98.74%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.08024057000875473\n",
      "Train Acc:98.99%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.09675008803606033\n",
      "Train Acc:99.01%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.16840632259845734\n",
      "Train Acc:99.05%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.13490892946720123\n",
      "Train Acc:99.21%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.1324869841337204\n",
      "Train Acc:99.23%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.059841979295015335\n",
      "Train Acc:99.26%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.10483502596616745\n",
      "Train Acc:99.33%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.3118214011192322\n",
      "Train Acc:99.42%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.0969623327255249\n",
      "Train Acc:99.38%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.1702343374490738\n",
      "Train Acc:99.41%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.13994523882865906\n",
      "Train Acc:99.58%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.06405433267354965\n",
      "Train Acc:99.41%, Test Acc:99.01%\n",
      "\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.15841584158416 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.23982928693294525\n",
      "Train Acc:82.34%, Test Acc:97.40%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.14335325360298157\n",
      "Train Acc:97.85%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.15335391461849213\n",
      "Train Acc:98.50%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.12210483849048615\n",
      "Train Acc:98.76%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.21075105667114258\n",
      "Train Acc:98.68%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.11386895179748535\n",
      "Train Acc:99.02%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.1309921145439148\n",
      "Train Acc:99.12%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.1302165985107422\n",
      "Train Acc:99.14%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.14932456612586975\n",
      "Train Acc:99.20%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.08988761156797409\n",
      "Train Acc:99.33%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.1495891511440277\n",
      "Train Acc:99.38%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.16353864967823029\n",
      "Train Acc:99.32%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.1476287543773651\n",
      "Train Acc:99.44%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.12028200179338455\n",
      "Train Acc:99.41%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.11658769845962524\n",
      "Train Acc:99.48%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.13557186722755432\n",
      "Train Acc:99.53%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.18525664508342743\n",
      "Train Acc:99.52%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.12945471704006195\n",
      "Train Acc:99.53%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.1409398317337036\n",
      "Train Acc:99.58%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.14161859452724457\n",
      "Train Acc:99.61%, Test Acc:99.49%\n",
      "\n",
      "Class: 4 -> Train Acc 99.60629921259843 ; Test Acc 99.54175152749491 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.3016887903213501\n",
      "Train Acc:82.38%, Test Acc:91.82%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.20363691449165344\n",
      "Train Acc:93.02%, Test Acc:92.15%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.16057659685611725\n",
      "Train Acc:95.95%, Test Acc:95.57%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:868,  Loss:0.15785810351371765\n",
      "Train Acc:97.18%, Test Acc:96.97%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.18532609939575195\n",
      "Train Acc:97.84%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.1583007574081421\n",
      "Train Acc:98.17%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.14335201680660248\n",
      "Train Acc:98.20%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.21838518977165222\n",
      "Train Acc:98.45%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.16314858198165894\n",
      "Train Acc:98.59%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.21017208695411682\n",
      "Train Acc:98.77%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.14147599041461945\n",
      "Train Acc:98.74%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.15156495571136475\n",
      "Train Acc:98.83%, Test Acc:99.10%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.09501968324184418\n",
      "Train Acc:98.99%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.08736466616392136\n",
      "Train Acc:98.81%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.1709200143814087\n",
      "Train Acc:99.05%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.117319256067276\n",
      "Train Acc:99.04%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.1268780678510666\n",
      "Train Acc:99.16%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1466900259256363\n",
      "Train Acc:99.21%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.15686221420764923\n",
      "Train Acc:99.23%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.17042173445224762\n",
      "Train Acc:99.29%, Test Acc:98.99%\n",
      "\n",
      "Class: 5 -> Train Acc 99.2897989300867 ; Test Acc 99.10313901345292 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.2077164649963379\n",
      "Train Acc:84.82%, Test Acc:95.35%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.1803015172481537\n",
      "Train Acc:96.89%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.1403782218694687\n",
      "Train Acc:98.24%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.16347092390060425\n",
      "Train Acc:98.77%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.12698158621788025\n",
      "Train Acc:98.76%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.11239638924598694\n",
      "Train Acc:98.92%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.12295404821634293\n",
      "Train Acc:99.09%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.18133968114852905\n",
      "Train Acc:99.08%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.13413743674755096\n",
      "Train Acc:99.19%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.14196336269378662\n",
      "Train Acc:99.26%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.12594693899154663\n",
      "Train Acc:99.35%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.16191288828849792\n",
      "Train Acc:99.43%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.1240246593952179\n",
      "Train Acc:99.48%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.07806704938411713\n",
      "Train Acc:99.45%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.15184958279132843\n",
      "Train Acc:99.47%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1246243342757225\n",
      "Train Acc:99.56%, Test Acc:99.48%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.11428627371788025\n",
      "Train Acc:99.61%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.15936179459095\n",
      "Train Acc:99.61%, Test Acc:99.53%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11686903983354568\n",
      "Train Acc:99.64%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.09980972111225128\n",
      "Train Acc:99.64%, Test Acc:99.58%\n",
      "\n",
      "Class: 6 -> Train Acc 99.63670158837445 ; Test Acc 99.58246346555325 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.2671484053134918\n",
      "Train Acc:85.06%, Test Acc:92.41%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.18784119188785553\n",
      "Train Acc:95.55%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.16933974623680115\n",
      "Train Acc:97.23%, Test Acc:96.98%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.19241642951965332\n",
      "Train Acc:97.31%, Test Acc:97.71%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.09435970336198807\n",
      "Train Acc:97.89%, Test Acc:96.94%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.14230617880821228\n",
      "Train Acc:98.48%, Test Acc:96.16%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.14463546872138977\n",
      "Train Acc:98.56%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.1213400661945343\n",
      "Train Acc:98.47%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.15879616141319275\n",
      "Train Acc:98.85%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.12247806042432785\n",
      "Train Acc:98.83%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.09170859307050705\n",
      "Train Acc:99.03%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.17424611747264862\n",
      "Train Acc:98.95%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.1336062252521515\n",
      "Train Acc:98.99%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.1410990208387375\n",
      "Train Acc:99.05%, Test Acc:99.17%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.13184624910354614\n",
      "Train Acc:99.08%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.13963961601257324\n",
      "Train Acc:99.17%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.13108742237091064\n",
      "Train Acc:99.39%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.11897862702608109\n",
      "Train Acc:99.40%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.11873172968626022\n",
      "Train Acc:99.31%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.14647677540779114\n",
      "Train Acc:99.51%, Test Acc:98.64%\n",
      "\n",
      "Class: 7 -> Train Acc 99.50518754988029 ; Test Acc 99.17315175097276 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.0888645201921463\n",
      "Train Acc:80.95%, Test Acc:92.30%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.3702276349067688\n",
      "Train Acc:92.73%, Test Acc:92.56%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.023279989138245583\n",
      "Train Acc:94.74%, Test Acc:96.61%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.02956424653530121\n",
      "Train Acc:95.82%, Test Acc:96.77%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.015788279473781586\n",
      "Train Acc:96.52%, Test Acc:97.79%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.4062718451023102\n",
      "Train Acc:97.06%, Test Acc:96.97%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.21542233228683472\n",
      "Train Acc:97.52%, Test Acc:96.15%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.06078759580850601\n",
      "Train Acc:97.95%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.3028002381324768\n",
      "Train Acc:98.06%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.12469369173049927\n",
      "Train Acc:98.33%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.009352878667414188\n",
      "Train Acc:98.50%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.13798624277114868\n",
      "Train Acc:98.57%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.16518639028072357\n",
      "Train Acc:98.81%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.11803603172302246\n",
      "Train Acc:98.75%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.0042509776540100574\n",
      "Train Acc:98.93%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.0663013681769371\n",
      "Train Acc:98.81%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.010093149729073048\n",
      "Train Acc:99.03%, Test Acc:98.92%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.314830482006073\n",
      "Train Acc:99.16%, Test Acc:98.87%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.014579261653125286\n",
      "Train Acc:99.21%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.05483465641736984\n",
      "Train Acc:99.30%, Test Acc:98.72%\n",
      "\n",
      "Class: 8 -> Train Acc 99.29926508289182 ; Test Acc 98.92197125256673 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.22302323579788208\n",
      "Train Acc:79.57%, Test Acc:90.68%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.18452173471450806\n",
      "Train Acc:92.45%, Test Acc:93.16%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.23750662803649902\n",
      "Train Acc:94.28%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.1888790875673294\n",
      "Train Acc:95.88%, Test Acc:95.84%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.16795587539672852\n",
      "Train Acc:96.51%, Test Acc:95.79%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.13087183237075806\n",
      "Train Acc:96.91%, Test Acc:96.78%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.14902682602405548\n",
      "Train Acc:97.50%, Test Acc:96.93%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.11774980276823044\n",
      "Train Acc:98.03%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.14860795438289642\n",
      "Train Acc:98.21%, Test Acc:97.52%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.2118111103773117\n",
      "Train Acc:98.35%, Test Acc:97.57%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.12796105444431305\n",
      "Train Acc:98.67%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.09007184952497482\n",
      "Train Acc:98.59%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.1424645632505417\n",
      "Train Acc:98.71%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.15226441621780396\n",
      "Train Acc:98.89%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.11268064379692078\n",
      "Train Acc:98.99%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.14906056225299835\n",
      "Train Acc:98.92%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.210347518324852\n",
      "Train Acc:99.07%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.18221092224121094\n",
      "Train Acc:99.13%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.14765681326389313\n",
      "Train Acc:99.24%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.12328241020441055\n",
      "Train Acc:99.29%, Test Acc:98.17%\n",
      "\n",
      "Class: 9 -> Train Acc 99.28559421751555 ; Test Acc 98.26560951437067 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = UnivariateCNN([1, 16, 32], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "            with torch.no_grad():\n",
    "                yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 99.62012493668749 ; Test Acc 99.64285714285714\n",
      "Class: 1 -> Train Acc 99.67368733313556 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.11883182275932 ; Test Acc 98.74031007751938\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.15841584158416\n",
      "Class: 4 -> Train Acc 99.60629921259843 ; Test Acc 99.54175152749491\n",
      "Class: 5 -> Train Acc 99.2897989300867 ; Test Acc 99.10313901345292\n",
      "Class: 6 -> Train Acc 99.63670158837445 ; Test Acc 99.58246346555325\n",
      "Class: 7 -> Train Acc 99.50518754988029 ; Test Acc 99.17315175097276\n",
      "Class: 8 -> Train Acc 99.29926508289182 ; Test Acc 98.92197125256673\n",
      "Class: 9 -> Train Acc 99.28559421751555 ; Test Acc 98.26560951437067\n",
      "Total Accuracy (Argmax) is : 0.9793000221252441\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_mixup = True\n",
    "use_check = False\n",
    "check_every = 2\n",
    "check_size = 100\n",
    "\n",
    "m_,s_ = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.34373870491981506, MinVal:0.7171808481216431, gp: 3.952949960092135e-14\n",
      "Train Acc:60.05%, Test Acc:84.03%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.20422665774822235, MinVal:0.5945688486099243, gp: 3.4798385960960188e-12\n",
      "Train Acc:92.20%, Test Acc:95.92%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.19461770355701447, MinVal:0.6446799039840698, gp: 5.211763637845424e-13\n",
      "Train Acc:96.18%, Test Acc:97.14%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.13201749324798584, MinVal:0.9298467040061951, gp: 5.224568288245673e-18\n",
      "Train Acc:97.33%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.15460193157196045, MinVal:1.0137680768966675, gp: 2.2665687116960323e-19\n",
      "Train Acc:98.35%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.15231472253799438, MinVal:0.8079996109008789, gp: 6.825860533469694e-16\n",
      "Train Acc:98.78%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.11118222028017044, MinVal:0.7211374044418335, gp: 2.202409668484659e-14\n",
      "Train Acc:99.04%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.09308306872844696, MinVal:1.029153823852539, gp: 1.4369719562725255e-19\n",
      "Train Acc:99.22%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.1626431792974472, MinVal:0.7130423784255981, gp: 3.044274698321171e-14\n",
      "Train Acc:99.21%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.11628665030002594, MinVal:0.930463969707489, gp: 8.836883807647914e-18\n",
      "Train Acc:99.42%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.16589288413524628, MinVal:0.9246366620063782, gp: 6.4230599380160976e-18\n",
      "Train Acc:99.38%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.14703942835330963, MinVal:0.6534796953201294, gp: 3.2975293502712777e-13\n",
      "Train Acc:99.50%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.14687243103981018, MinVal:1.5218480825424194, gp: 5.218314406554507e-28\n",
      "Train Acc:99.58%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.11507023870944977, MinVal:1.5142886638641357, gp: 7.635476857382012e-28\n",
      "Train Acc:99.54%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.1150585263967514, MinVal:1.3675401210784912, gp: 1.2997619866257754e-25\n",
      "Train Acc:99.60%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.10138334333896637, MinVal:1.0843555927276611, gp: 1.5195265847333637e-20\n",
      "Train Acc:99.72%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.15338456630706787, MinVal:1.6469149589538574, gp: 1.9817399711360284e-30\n",
      "Train Acc:99.65%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.13297052681446075, MinVal:0.9513681530952454, gp: 2.318222677131154e-18\n",
      "Train Acc:99.73%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11557327210903168, MinVal:1.0098297595977783, gp: 2.1269952957656922e-19\n",
      "Train Acc:99.74%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.13792093098163605, MinVal:1.1521611213684082, gp: 1.2586846499443389e-21\n",
      "Train Acc:99.78%, Test Acc:99.39%\n",
      "\n",
      "Class: 0 -> Train Acc 99.7805166300861 ; Test Acc 99.54081632653062 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.1225963905453682, MinVal:0.5274885296821594, gp: 6.937234814374804e-11\n",
      "Train Acc:91.51%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.15727776288986206, MinVal:0.771781325340271, gp: 7.11105504450256e-15\n",
      "Train Acc:97.99%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.1424793303012848, MinVal:0.6243969798088074, gp: 1.682411805356554e-12\n",
      "Train Acc:98.35%, Test Acc:98.94%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.19898995757102966, MinVal:0.493887722492218, gp: 4.641076134515032e-10\n",
      "Train Acc:98.51%, Test Acc:98.85%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.14634497463703156, MinVal:0.5885432362556458, gp: 6.069342511211273e-12\n",
      "Train Acc:98.65%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.10400968044996262, MinVal:0.568385660648346, gp: 3.386195143728621e-11\n",
      "Train Acc:98.80%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.10056707262992859, MinVal:0.4833568036556244, gp: 4.712789603011913e-10\n",
      "Train Acc:99.05%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.10990927368402481, MinVal:0.44330063462257385, gp: 3.0427165231827757e-09\n",
      "Train Acc:99.04%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.10276519507169724, MinVal:0.5973445177078247, gp: 1.2453861726602344e-11\n",
      "Train Acc:99.21%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.13544893264770508, MinVal:0.26300910115242004, gp: 2.608818022054038e-06\n",
      "Train Acc:99.17%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.12801781296730042, MinVal:0.507764995098114, gp: 1.6159809601568043e-10\n",
      "Train Acc:99.35%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.08807363361120224, MinVal:0.38998228311538696, gp: 1.681275030307461e-08\n",
      "Train Acc:99.35%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.12248890846967697, MinVal:0.435306578874588, gp: 2.8282547415159343e-09\n",
      "Train Acc:99.45%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.10690835863351822, MinVal:0.8530929088592529, gp: 2.453725010973456e-16\n",
      "Train Acc:99.46%, Test Acc:99.56%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.1269526481628418, MinVal:0.5232714414596558, gp: 8.166493870032099e-11\n",
      "Train Acc:99.58%, Test Acc:99.56%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.06027337908744812, MinVal:1.1178104877471924, gp: 4.972127732093697e-21\n",
      "Train Acc:99.51%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.15389129519462585, MinVal:0.3873846232891083, gp: 1.8648123045750253e-08\n",
      "Train Acc:99.67%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.12144265323877335, MinVal:0.7200343012809753, gp: 3.113876750849773e-14\n",
      "Train Acc:99.63%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.10818439722061157, MinVal:0.8711309432983398, gp: 7.387379982377149e-17\n",
      "Train Acc:99.65%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.08636800199747086, MinVal:0.8935328722000122, gp: 3.027506849979193e-17\n",
      "Train Acc:99.66%, Test Acc:99.34%\n",
      "\n",
      "Class: 1 -> Train Acc 99.66627113616138 ; Test Acc 99.55947136563876 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.28766268491744995, MinVal:0.5403376817703247, gp: 8.755453306807937e-11\n",
      "Train Acc:70.59%, Test Acc:89.78%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.1703946888446808, MinVal:0.6517648696899414, gp: 1.0154966060757498e-12\n",
      "Train Acc:93.52%, Test Acc:96.71%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.16667456924915314, MinVal:0.7538397908210754, gp: 1.7366804608981434e-14\n",
      "Train Acc:96.27%, Test Acc:97.24%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.16937735676765442, MinVal:0.9840284585952759, gp: 3.539476889792966e-18\n",
      "Train Acc:97.23%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.08161500841379166, MinVal:0.6762237548828125, gp: 3.823326475294736e-13\n",
      "Train Acc:97.78%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.16501963138580322, MinVal:0.8902694582939148, gp: 1.204150375797288e-16\n",
      "Train Acc:98.13%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.18985968828201294, MinVal:0.832935094833374, gp: 7.396923793761439e-16\n",
      "Train Acc:98.36%, Test Acc:98.01%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.07767181098461151, MinVal:0.5037047266960144, gp: 4.437447909122483e-10\n",
      "Train Acc:98.47%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.13201917707920074, MinVal:0.5718501806259155, gp: 2.4881145754829248e-11\n",
      "Train Acc:98.68%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.17178422212600708, MinVal:0.5347869992256165, gp: 1.0931106714240357e-10\n",
      "Train Acc:98.80%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.1386842131614685, MinVal:0.7160578370094299, gp: 7.763228401054187e-14\n",
      "Train Acc:99.07%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.18963466584682465, MinVal:0.8522940278053284, gp: 7.222760055520562e-16\n",
      "Train Acc:99.14%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.10113508254289627, MinVal:0.9229588508605957, gp: 2.0144038289928264e-17\n",
      "Train Acc:99.14%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.16311809420585632, MinVal:0.7226628065109253, gp: 5.957186106171283e-14\n",
      "Train Acc:99.29%, Test Acc:98.45%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.2002752423286438, MinVal:0.9446874260902405, gp: 8.366050121440893e-18\n",
      "Train Acc:99.24%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.1487918347120285, MinVal:0.4825400412082672, gp: 8.833899167726145e-10\n",
      "Train Acc:99.35%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.14906303584575653, MinVal:0.377984881401062, gp: 5.767647337506787e-08\n",
      "Train Acc:99.36%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.11746475100517273, MinVal:0.8239850401878357, gp: 1.0350387920400887e-15\n",
      "Train Acc:99.41%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.09363135695457458, MinVal:0.7574102282524109, gp: 1.5917139907007695e-14\n",
      "Train Acc:99.44%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.18673506379127502, MinVal:0.714322030544281, gp: 9.524982392443773e-14\n",
      "Train Acc:99.42%, Test Acc:98.98%\n",
      "\n",
      "Class: 2 -> Train Acc 99.43773078214166 ; Test Acc 99.03100775193798 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.36151304841041565, MinVal:0.4562162160873413, gp: 3.814264903923004e-09\n",
      "Train Acc:81.84%, Test Acc:93.42%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.1389627754688263, MinVal:0.6857538819313049, gp: 4.084470663166112e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.86%, Test Acc:96.29%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.12578575313091278, MinVal:0.4853037893772125, gp: 3.212973886945747e-09\n",
      "Train Acc:97.33%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.1781097799539566, MinVal:0.6099213361740112, gp: 7.82265831972273e-12\n",
      "Train Acc:97.98%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.23081518709659576, MinVal:0.4118262529373169, gp: 1.9914272897381124e-08\n",
      "Train Acc:98.39%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.2470516711473465, MinVal:0.6352403163909912, gp: 3.7109334702356556e-12\n",
      "Train Acc:98.56%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.12452089786529541, MinVal:0.7442803382873535, gp: 3.402670262523874e-14\n",
      "Train Acc:98.77%, Test Acc:98.76%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.12417756766080856, MinVal:0.811779260635376, gp: 2.6950343744321613e-15\n",
      "Train Acc:98.97%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.17334647476673126, MinVal:0.43081191182136536, gp: 9.31895804967553e-09\n",
      "Train Acc:99.14%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.11646396666765213, MinVal:0.5505597591400146, gp: 7.755701636469325e-11\n",
      "Train Acc:99.23%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.1341216117143631, MinVal:0.6454128623008728, gp: 1.7454324660950982e-12\n",
      "Train Acc:99.24%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.08085131645202637, MinVal:0.6836949586868286, gp: 6.494796562540872e-13\n",
      "Train Acc:99.18%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.1932000368833542, MinVal:0.5381093621253967, gp: 2.5958812877036053e-10\n",
      "Train Acc:99.45%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.16855363547801971, MinVal:0.8875762820243835, gp: 1.51245197210103e-16\n",
      "Train Acc:99.45%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.18523108959197998, MinVal:0.8968196511268616, gp: 7.491250044512168e-17\n",
      "Train Acc:99.55%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.1277196854352951, MinVal:0.7976325154304504, gp: 3.95932972754756e-15\n",
      "Train Acc:99.46%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.13055768609046936, MinVal:0.9615045785903931, gp: 5.6991813626714485e-18\n",
      "Train Acc:99.55%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.040307458490133286, MinVal:0.6571280360221863, gp: 1.092442000576177e-12\n",
      "Train Acc:99.66%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.08405885100364685, MinVal:0.6169285178184509, gp: 5.4540517067935834e-12\n",
      "Train Acc:99.67%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.08866095542907715, MinVal:0.9085426330566406, gp: 4.686805350725455e-17\n",
      "Train Acc:99.71%, Test Acc:99.26%\n",
      "\n",
      "Class: 3 -> Train Acc 99.70641004730061 ; Test Acc 99.25742574257426 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.19509734213352203, MinVal:0.20558790862560272, gp: 2.948433393612504e-05\n",
      "Train Acc:80.35%, Test Acc:94.96%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.14670948684215546, MinVal:0.29839369654655457, gp: 6.454135927924654e-07\n",
      "Train Acc:97.44%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.13614870607852936, MinVal:0.43912529945373535, gp: 2.3664099568776464e-09\n",
      "Train Acc:98.29%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.1754414588212967, MinVal:0.5881932973861694, gp: 6.224109769248365e-12\n",
      "Train Acc:98.72%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.1468903124332428, MinVal:0.633901059627533, gp: 2.3604636040924776e-12\n",
      "Train Acc:98.72%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.14837028086185455, MinVal:0.3372758626937866, gp: 1.3814371868647868e-07\n",
      "Train Acc:98.84%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.1485530138015747, MinVal:0.4211697578430176, gp: 4.835191802499139e-09\n",
      "Train Acc:99.03%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.15107572078704834, MinVal:0.6737690567970276, gp: 2.350966914633351e-13\n",
      "Train Acc:99.14%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.16697412729263306, MinVal:0.6434603929519653, gp: 9.40107366953491e-13\n",
      "Train Acc:99.16%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.14134621620178223, MinVal:0.6624755859375, gp: 3.8274057859687127e-13\n",
      "Train Acc:99.29%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.12872314453125, MinVal:0.5218530297279358, gp: 8.690908409603182e-11\n",
      "Train Acc:99.21%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.13975580036640167, MinVal:0.6098055839538574, gp: 2.63009926337876e-12\n",
      "Train Acc:99.38%, Test Acc:99.59%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.14410589635372162, MinVal:0.22313569486141205, gp: 1.2290440281503834e-05\n",
      "Train Acc:99.39%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.1860109269618988, MinVal:0.5443417429924011, gp: 3.6776696271667575e-11\n",
      "Train Acc:99.38%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.13786934316158295, MinVal:0.5895126461982727, gp: 5.787393134171204e-12\n",
      "Train Acc:99.47%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.13004213571548462, MinVal:0.4514027535915375, gp: 3.101499723712209e-09\n",
      "Train Acc:99.48%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.13230231404304504, MinVal:0.420820951461792, gp: 4.903003780754034e-09\n",
      "Train Acc:99.49%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.1521839201450348, MinVal:0.48380061984062195, gp: 3.954164495834078e-10\n",
      "Train Acc:99.60%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.15409547090530396, MinVal:0.6027190089225769, gp: 3.6541637771225766e-12\n",
      "Train Acc:99.51%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.1123969554901123, MinVal:0.5435447692871094, gp: 3.651511037983113e-11\n",
      "Train Acc:99.60%, Test Acc:99.29%\n",
      "\n",
      "Class: 4 -> Train Acc 99.59774049982883 ; Test Acc 99.64358452138494 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.28749001026153564, MinVal:0.5771834254264832, gp: 1.8315623323550412e-11\n",
      "Train Acc:80.21%, Test Acc:91.42%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.3112858235836029, MinVal:0.43220317363739014, gp: 2.518800501505325e-09\n",
      "Train Acc:93.35%, Test Acc:95.29%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.20553675293922424, MinVal:0.5053163766860962, gp: 2.402010257362974e-10\n",
      "Train Acc:95.92%, Test Acc:96.52%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.27322670817375183, MinVal:0.6934177875518799, gp: 1.4721984211134992e-13\n",
      "Train Acc:96.65%, Test Acc:97.42%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.18013371527194977, MinVal:0.4176395535469055, gp: 5.070912578730713e-09\n",
      "Train Acc:97.54%, Test Acc:96.41%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.1421475112438202, MinVal:0.6353595852851868, gp: 7.748915441599391e-13\n",
      "Train Acc:97.57%, Test Acc:97.31%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.11922257393598557, MinVal:0.5838198661804199, gp: 1.2520345871180893e-11\n",
      "Train Acc:97.99%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.17204120755195618, MinVal:0.6524481177330017, gp: 6.668632659967422e-13\n",
      "Train Acc:97.98%, Test Acc:97.70%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.14902856945991516, MinVal:0.6783343553543091, gp: 3.1845075079521556e-13\n",
      "Train Acc:98.51%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.16635668277740479, MinVal:0.6113526821136475, gp: 2.0247985146187863e-12\n",
      "Train Acc:98.66%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.15255381166934967, MinVal:0.7046576738357544, gp: 1.0114915768031155e-13\n",
      "Train Acc:98.76%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.13844603300094604, MinVal:0.8814372420310974, gp: 4.0562081812125944e-17\n",
      "Train Acc:98.79%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.18883202970027924, MinVal:0.5598782300949097, gp: 1.528033082009994e-11\n",
      "Train Acc:98.91%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.12638269364833832, MinVal:0.34434932470321655, gp: 8.405858409332723e-08\n",
      "Train Acc:99.07%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.10679013282060623, MinVal:0.8289910554885864, gp: 3.422521856071318e-16\n",
      "Train Acc:99.02%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.15946464240550995, MinVal:0.8172910213470459, gp: 7.191408189769128e-16\n",
      "Train Acc:99.02%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.12284278124570847, MinVal:0.28633883595466614, gp: 8.418758739026089e-07\n",
      "Train Acc:99.25%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1719025820493698, MinVal:1.15854012966156, gp: 6.504606741412387e-22\n",
      "Train Acc:99.32%, Test Acc:99.05%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.17343905568122864, MinVal:0.746397852897644, gp: 8.786083026488672e-15\n",
      "Train Acc:99.35%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.12510159611701965, MinVal:0.9738379716873169, gp: 1.1152431589473225e-18\n",
      "Train Acc:99.13%, Test Acc:99.05%\n",
      "\n",
      "Class: 5 -> Train Acc 99.35436266371518 ; Test Acc 99.04708520179372 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.24649003148078918, MinVal:0.649649441242218, gp: 5.173111288295229e-13\n",
      "Train Acc:73.63%, Test Acc:94.68%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.24425369501113892, MinVal:0.6232988834381104, gp: 1.410568276766222e-12\n",
      "Train Acc:96.78%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.1415145993232727, MinVal:0.7378548979759216, gp: 1.687062626100702e-14\n",
      "Train Acc:98.24%, Test Acc:98.38%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:948,  Loss:0.164567232131958, MinVal:0.5358307957649231, gp: 8.198663276060003e-11\n",
      "Train Acc:98.56%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.17301779985427856, MinVal:0.691493034362793, gp: 9.272929104263417e-14\n",
      "Train Acc:98.57%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.13230571150779724, MinVal:0.7044814825057983, gp: 8.858839768526028e-14\n",
      "Train Acc:98.74%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.19545435905456543, MinVal:0.6322676539421082, gp: 1.4664416599433072e-12\n",
      "Train Acc:98.93%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.10732046514749527, MinVal:1.213536024093628, gp: 1.228775689231368e-22\n",
      "Train Acc:99.05%, Test Acc:98.75%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.09836412966251373, MinVal:0.9989995956420898, gp: 4.1913603529579904e-19\n",
      "Train Acc:99.10%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.18361829221248627, MinVal:1.3352131843566895, gp: 6.051484138152006e-25\n",
      "Train Acc:99.24%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.1430024802684784, MinVal:1.3515793085098267, gp: 3.143536012038769e-25\n",
      "Train Acc:99.31%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.11606170237064362, MinVal:0.8171096444129944, gp: 6.054960495701386e-16\n",
      "Train Acc:99.31%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.13054567575454712, MinVal:1.4056745767593384, gp: 3.6117084425122364e-26\n",
      "Train Acc:99.32%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.14118832349777222, MinVal:1.5373140573501587, gp: 1.8658554949675585e-28\n",
      "Train Acc:99.38%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.13489773869514465, MinVal:1.6061415672302246, gp: 1.1891005944895526e-29\n",
      "Train Acc:99.51%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.13281665742397308, MinVal:0.9180377125740051, gp: 1.0688132216515067e-17\n",
      "Train Acc:99.49%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.12833747267723083, MinVal:1.8925994634628296, gp: 1.2558491472224576e-34\n",
      "Train Acc:99.59%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.10106432437896729, MinVal:1.368253231048584, gp: 1.6134756983760016e-25\n",
      "Train Acc:99.70%, Test Acc:99.48%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.118539959192276, MinVal:1.9403185844421387, gp: 1.8619777424628818e-35\n",
      "Train Acc:99.65%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.10053893178701401, MinVal:1.7486491203308105, gp: 4.1796614760542396e-32\n",
      "Train Acc:99.66%, Test Acc:99.32%\n",
      "\n",
      "Class: 6 -> Train Acc 99.69584319026698 ; Test Acc 99.47807933194154 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.3056042492389679, MinVal:0.5646619200706482, gp: 2.9596811113030697e-11\n",
      "Train Acc:81.93%, Test Acc:92.32%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.17722055315971375, MinVal:0.39516451954841614, gp: 2.7027661886336318e-08\n",
      "Train Acc:95.02%, Test Acc:96.06%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.18204879760742188, MinVal:0.7618483304977417, gp: 6.734706871092686e-15\n",
      "Train Acc:97.12%, Test Acc:96.60%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.11275327205657959, MinVal:0.26012444496154785, gp: 4.281308520148741e-06\n",
      "Train Acc:97.78%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.1493588387966156, MinVal:0.8640530109405518, gp: 2.2576866468697364e-16\n",
      "Train Acc:98.34%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.25101080536842346, MinVal:0.6724230051040649, gp: 2.3787433611408004e-13\n",
      "Train Acc:98.49%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.14218218624591827, MinVal:0.8138032555580139, gp: 8.293732102765546e-16\n",
      "Train Acc:98.64%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.09488199651241302, MinVal:0.8863080739974976, gp: 8.277569920038546e-17\n",
      "Train Acc:98.63%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.15479707717895508, MinVal:0.9249361157417297, gp: 1.6620928822915885e-17\n",
      "Train Acc:98.89%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.12254814803600311, MinVal:0.758187472820282, gp: 7.672044118436135e-15\n",
      "Train Acc:99.01%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.12491961568593979, MinVal:0.8408754467964172, gp: 2.859599641193871e-16\n",
      "Train Acc:99.13%, Test Acc:99.17%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.19895236194133759, MinVal:0.983995795249939, gp: 9.168293099681826e-19\n",
      "Train Acc:99.14%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.09878451377153397, MinVal:1.1419564485549927, gp: 1.7312385349755528e-21\n",
      "Train Acc:99.21%, Test Acc:97.91%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.1951083391904831, MinVal:0.9092066884040833, gp: 3.8902641698058813e-17\n",
      "Train Acc:99.26%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.10024824738502502, MinVal:0.7020175457000732, gp: 7.255194979950003e-14\n",
      "Train Acc:99.36%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.17619700729846954, MinVal:0.9344347715377808, gp: 6.658605821295166e-18\n",
      "Train Acc:99.32%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.12562979757785797, MinVal:1.4641491174697876, gp: 6.422096984918824e-27\n",
      "Train Acc:99.43%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.11986812949180603, MinVal:0.9738895297050476, gp: 2.3893320856698874e-18\n",
      "Train Acc:99.33%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.1933605670928955, MinVal:1.068557858467102, gp: 3.1161085978177365e-20\n",
      "Train Acc:99.56%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.10488053411245346, MinVal:1.0552425384521484, gp: 1.0565972167400492e-19\n",
      "Train Acc:99.47%, Test Acc:99.17%\n",
      "\n",
      "Class: 7 -> Train Acc 99.56105347166799 ; Test Acc 99.17315175097276 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:2.0921671390533447, MinVal:0.776365339756012, gp: 5.5614546849063265e-14\n",
      "Train Acc:71.61%, Test Acc:70.94%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.0852203518152237, MinVal:1.478290319442749, gp: 3.5603742435513523e-26\n",
      "Train Acc:91.43%, Test Acc:93.33%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.5696923732757568, MinVal:1.6044425964355469, gp: 2.2908955947785614e-28\n",
      "Train Acc:93.57%, Test Acc:96.51%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.6600929498672485, MinVal:1.8433045148849487, gp: 1.6238653651083404e-32\n",
      "Train Acc:94.96%, Test Acc:87.63%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.025480857118964195, MinVal:2.2561047077178955, gp: 1.0951483810329883e-39\n",
      "Train Acc:94.90%, Test Acc:96.46%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.008476289920508862, MinVal:2.391082286834717, gp: 4.9521887729239035e-42\n",
      "Train Acc:96.39%, Test Acc:97.64%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.15315057337284088, MinVal:0.9472134709358215, gp: 6.01201883695135e-17\n",
      "Train Acc:96.56%, Test Acc:97.74%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.14994393289089203, MinVal:1.4166302680969238, gp: 4.194108178580739e-25\n",
      "Train Acc:97.27%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.05812009423971176, MinVal:1.625411868095398, gp: 9.902230799937058e-29\n",
      "Train Acc:97.63%, Test Acc:97.28%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.1476689875125885, MinVal:1.6239012479782104, gp: 1.0850193379717007e-28\n",
      "Train Acc:97.89%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.04611479490995407, MinVal:0.7934360504150391, gp: 2.8111981668845105e-14\n",
      "Train Acc:98.05%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.4021729826927185, MinVal:1.9324160814285278, gp: 7.2252320469818465e-34\n",
      "Train Acc:98.41%, Test Acc:97.13%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.0635504424571991, MinVal:1.5893006324768066, gp: 4.328610364997921e-28\n",
      "Train Acc:98.21%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.06344128400087357, MinVal:1.171511173248291, gp: 7.599665332281256e-21\n",
      "Train Acc:98.68%, Test Acc:98.97%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.4124477803707123, MinVal:1.2572410106658936, gp: 2.481681434484871e-22\n",
      "Train Acc:98.43%, Test Acc:95.43%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.1260252594947815, MinVal:0.9579514265060425, gp: 3.8968028671119905e-17\n",
      "Train Acc:98.22%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.3659534454345703, MinVal:1.4569461345672607, gp: 8.361459674370579e-26\n",
      "Train Acc:98.87%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.05868047475814819, MinVal:1.193418264389038, gp: 3.1639537261118267e-21\n",
      "Train Acc:99.05%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.13069969415664673, MinVal:1.3058701753616333, gp: 3.5215987742965354e-23\n",
      "Train Acc:99.15%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.013164186850190163, MinVal:1.1583900451660156, gp: 1.3679009857194126e-20\n",
      "Train Acc:99.29%, Test Acc:98.82%\n",
      "\n",
      "Class: 8 -> Train Acc 99.2907195351222 ; Test Acc 99.07597535934292 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.33140671253204346, MinVal:0.354828417301178, gp: 1.0266119687685205e-07\n",
      "Train Acc:77.42%, Test Acc:89.15%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.21978993713855743, MinVal:0.5491387248039246, gp: 6.660030166250053e-11\n",
      "Train Acc:91.92%, Test Acc:92.96%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.3322354853153229, MinVal:0.3244022727012634, gp: 1.656146508821621e-07\n",
      "Train Acc:93.81%, Test Acc:94.10%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.23748548328876495, MinVal:0.5595757365226746, gp: 1.77621823499452e-11\n",
      "Train Acc:94.61%, Test Acc:94.85%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.14569200575351715, MinVal:0.5093867182731628, gp: 1.0120149163128644e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.92%, Test Acc:93.11%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.27664485573768616, MinVal:0.5832842588424683, gp: 7.81894601148414e-12\n",
      "Train Acc:95.80%, Test Acc:95.54%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.1474100947380066, MinVal:0.7431163191795349, gp: 8.795740049120319e-15\n",
      "Train Acc:96.29%, Test Acc:96.13%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.14480799436569214, MinVal:0.6121073961257935, gp: 1.6535127217096046e-12\n",
      "Train Acc:96.82%, Test Acc:95.99%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.15610824525356293, MinVal:0.9322028160095215, gp: 6.455074309263737e-18\n",
      "Train Acc:97.01%, Test Acc:96.63%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.19983462989330292, MinVal:0.802293062210083, gp: 8.579600957903544e-16\n",
      "Train Acc:97.37%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.248808816075325, MinVal:0.9738993048667908, gp: 8.588674719768848e-19\n",
      "Train Acc:97.68%, Test Acc:97.32%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.1553627848625183, MinVal:1.1760530471801758, gp: 3.0079685358990034e-22\n",
      "Train Acc:97.86%, Test Acc:97.22%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.28854334354400635, MinVal:1.2942801713943481, gp: 3.7887301115428024e-24\n",
      "Train Acc:97.96%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.1930835247039795, MinVal:1.039145588874817, gp: 1.0378902040697357e-19\n",
      "Train Acc:98.15%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.15112562477588654, MinVal:1.1054799556732178, gp: 4.618950691101964e-21\n",
      "Train Acc:98.34%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.15697890520095825, MinVal:1.6241775751113892, gp: 2.114674088202723e-29\n",
      "Train Acc:98.50%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.18802358210086823, MinVal:1.2028627395629883, gp: 9.04504569156174e-23\n",
      "Train Acc:98.68%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.1475401073694229, MinVal:1.5773977041244507, gp: 2.816586177745389e-29\n",
      "Train Acc:98.85%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.2044462412595749, MinVal:1.3764697313308716, gp: 9.030008814486489e-26\n",
      "Train Acc:98.66%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.10728791356086731, MinVal:1.417213797569275, gp: 1.952041394424447e-26\n",
      "Train Acc:98.81%, Test Acc:98.41%\n",
      "\n",
      "Class: 9 -> Train Acc 98.8485459741133 ; Test Acc 98.46382556987116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    lips_net = UnivariateCNN([1, 16, 32], actf)\n",
    "    Net = BasicInvexNet(784, lips_net, lambda_)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if use_check and epoch%check_every == 0:\n",
    "                rand_inp = torch.rand(check_size, 784)*m_+s_\n",
    "                Net(rand_inp)\n",
    "                Net.compute_penalty_and_clipper()\n",
    "                Net.gp.backward(retain_graph=True)\n",
    "            \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))   \n",
    "            Net.compute_penalty_and_clipper()\n",
    "            loss = criterion(yout, y_mix) + Net.gp\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        min_val, gp = float(Net.cond.min()) , float(Net.gp)\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}, MinVal:{min_val}, gp: {gp}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "#                     with torch.no_grad():\n",
    "            yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 99.7805166300861 ; Test Acc 99.54081632653062\n",
      "Class: 1 -> Train Acc 99.66627113616138 ; Test Acc 99.55947136563876\n",
      "Class: 2 -> Train Acc 99.43773078214166 ; Test Acc 99.03100775193798\n",
      "Class: 3 -> Train Acc 99.70641004730061 ; Test Acc 99.25742574257426\n",
      "Class: 4 -> Train Acc 99.59774049982883 ; Test Acc 99.64358452138494\n",
      "Class: 5 -> Train Acc 99.35436266371518 ; Test Acc 99.04708520179372\n",
      "Class: 6 -> Train Acc 99.69584319026698 ; Test Acc 99.47807933194154\n",
      "Class: 7 -> Train Acc 99.56105347166799 ; Test Acc 99.17315175097276\n",
      "Class: 8 -> Train Acc 99.2907195351222 ; Test Acc 99.07597535934292\n",
      "Class: 9 -> Train Acc 98.8485459741133 ; Test Acc 98.46382556987116\n",
      "Total Accuracy (Argmax) is : 0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 70000 input points\n",
      "Class: 1 -> Correct 100.0000% on 70000 input points\n",
      "Class: 2 -> Correct 100.0000% on 70000 input points\n",
      "Class: 3 -> Correct 100.0000% on 70000 input points\n",
      "Class: 4 -> Correct 100.0000% on 70000 input points\n",
      "Class: 5 -> Correct 100.0000% on 70000 input points\n",
      "Class: 6 -> Correct 100.0000% on 70000 input points\n",
      "Class: 7 -> Correct 100.0000% on 70000 input points\n",
      "Class: 8 -> Correct 100.0000% on 70000 input points\n",
      "Class: 9 -> Correct 100.0000% on 70000 input points\n"
     ]
    }
   ],
   "source": [
    "## only on training and testing data\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14065"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:45<00:00, 443.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 99.2065% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:49<00:00, 406.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1 -> Correct 37.4307% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:47<00:00, 420.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 2 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:48<00:00, 413.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 3 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:46<00:00, 434.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 4 -> Correct 85.9228% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:46<00:00, 434.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 5 -> Correct 94.9125% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:46<00:00, 433.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 6 -> Correct 20.6208% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:46<00:00, 432.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 7 -> Correct 94.8357% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:46<00:00, 431.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 8 -> Correct 7.7850% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [00:45<00:00, 434.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 9 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Check the constraint on large number of points, including training and test data.\n",
    "from tqdm import tqdm\n",
    "\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    for i in tqdm(range(20000)):\n",
    "        xx = torch.rand(batch_size, 784)\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAFXCAYAAADK21P3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACf90lEQVR4nO29ZXRbV9r2vyVZsswys2M7TuIwJw0zN0mbptxpUmamaaedMk1p0nbK3CalpG2oYWZmsuPYTswos2VZ0v/Du55Z69a1/2v8zvPKnmmu31r9sK/ePtraZ8M50b72bfB4PB5FCCGEEEIIIf+PMXZ0BQghhBBCCCF/TPiyQQghhBBCCPEJfNkghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn8CXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE/iyQQghhBBCCPEJfNloIw6HQz3xxBMqISFBBQQEqKFDh6p169Z1dLXIRUJ9fb169tln1dSpU1VERIQyGAzqq6++6uhqkYuAffv2qXvvvVf17NlTBQUFqZSUFHXVVVeprKysjq4auUg4ceKEuvLKK1V6eroKDAxUUVFRavTo0Wr58uUdXTVykfLyyy8rg8GgevXq1dFV+a+ALxttZP78+ertt99W119/vVqwYIEymUxq+vTpavv27R1dNXIRUFFRoV544QV16tQp1bdv346uDrmIeP3119WSJUvUhAkT1IIFC9Ttt9+utm7dqgYMGKCOHz/e0dUjFwH5+fmqrq5OzZs3Ty1YsEA988wzSimlZs2apT755JMOrh252CgoKFCvvPKKCgoK6uiq/Ndg8Hg8no6uxH86e/fuVUOHDlVvvPGGevTRR5VSSjU3N6tevXqpmJgYtXPnzg6uIfmj43A4VHV1tYqLi1P79+9XgwcPVl9++aWaP39+R1eN/MHZuXOnGjRokLJYLP/UsrOzVe/evdXcuXPVd99914G1IxcrLpdLDRw4UDU3N6vTp093dHXIRcQ111yjysvLlcvlUhUVFfxHlzbAXzbawOLFi5XJZFK33377PzWr1apuueUWtWvXLnXhwoUOrB25GPD391dxcXEdXQ1yETJ8+HDxoqGUUl26dFE9e/ZUp06d6qBakYsdk8mkkpOTld1u7+iqkIuIrVu3qsWLF6u///3vHV2V/yr4stEGDh06pLp27apCQ0OFPmTIEKWUUocPH+6AWhFCSMfg8XhUaWmpioqK6uiqkIuIhoYGVVFRoXJyctQ777yjVq1apSZMmNDR1SIXCS6XS913333q1ltvVb179+7o6vxX4dfRFfhvoLi4WMXHx4P+P1pRUVF7V4kQQjqMhQsXqsLCQvXCCy90dFXIRcQjjzyiPv74Y6WUUkajUc2ZM0e9//77HVwrcrHw0Ucfqfz8fLV+/fqOrsp/HXzZaANNTU3K398fdKvV+s//TwghFwOnT59W99xzjxo2bJiaN29eR1eHXEQ8+OCDau7cuaqoqEj99NNPyuVyqZaWlo6uFrkIqKysVH/961/VM888o6Kjozu6Ov91cBtVGwgICFAOhwP05ubmf/5/Qgj5o1NSUqJmzJihwsLC/ullI6S9yMzMVBMnTlQ33nijWrFihaqvr1czZ85UPOeG+Jqnn35aRUREqPvuu6+jq/JfCV822kB8fLwqLi4G/X+0hISE9q4SIYS0KzU1NWratGnKbrer1atXc94jHc7cuXPVvn37mPOF+JTs7Gz1ySefqPvvv18VFRWpvLw8lZeXp5qbm5XT6VR5eXmqqqqqo6v5Hw1fNtpAv379VFZWlqqtrRX6nj17/vn/CSHkj0pzc7OaOXOmysrKUitWrFA9evTo6CoR8s8tzDU1NR1cE/JHprCwULndbnX//fertLS0f/63Z88elZWVpdLS0uhf+xfQs9EG5s6dq9588031ySef/DPPhsPhUF9++aUaOnSoSk5O7uAaEkKIb3C5XOrqq69Wu3btUkuXLlXDhg3r6CqRi4yysjIVExMjNKfTqb755hsVEBDAl1/iU3r16qV+/fVX0J9++mlVV1enFixYoDp37twBNfvvgS8bbWDo0KHqyiuvVE8++aQqKytTGRkZ6uuvv1Z5eXnq888/7+jqkYuE999/X9nt9n+efrZ8+XJVUFCglFLqvvvuU2FhYR1ZPfIH5ZFHHlHLli1TM2fOVFVVVZDE74YbbuigmpGLhTvuuEPV1taq0aNHq8TERFVSUqIWLlyoTp8+rd566y0VHBzc0VUkf2CioqLUZZddBvr/5NrQ/T8iYQbxNtLc3KyeeeYZ9d1336nq6mrVp08f9eKLL6opU6Z0dNXIRUJqaqrKz8/X/r/c3FyVmpravhUiFwVjx45VW7Zs+f/9/1xCiK/54Ycf1Oeff66OHTumKisrVUhIiBo4cKC677771KxZszq6euQiZezYscwg3kb4skEIIYQQQgjxCTSIE0IIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT2pzU76pdd4BW9RhmzvZ7uVyU697DmFkvrAdt+dMTQEt5PEuUz36QiZ93Qxlojh9jsa698YRfj8VLc0OIMjoN+HcoKY8/Xt/Q4hXYxkOG23Itj+Y10ehEzRXeCpqlyIzX71Yvyub9IXixYXaQTsx+HuN8wAvHZ4K28JfxoBl714iyIw+/R0iGHbSgbzEhXtEs2aDBR6wQY6nFexV+uhm0nLn+oMXvkGVHCHasiJONoNm7BoIWloefqVyybqYG7CDOCPxOpkbsM8ZWOTg8JqyrXz6OxdbSctDK7hwKWlCpS5Rd/nj9oKIW0DZufBI0X9HtuXdA86/GuMYRcixFLsP7VX4p3q/4xdhHmm+WH+BeFgkx9lF4rdgVeK2SUdhXrSUmUW5KwnsfegaXidqeeC+sFyygNcfL69mO4rXsvfAzrSUY5+oh2zVgFyZyq+vvAC3oJLaFbi5rOSnngNZO2K6m8zhezv75Yby+Dxi+9gnQik/GgNZ9gMzFk7UzFWIGjTkN2r7tuL72HyHX4AN7u0DMw1NXgvbmnsmgvTPyR9CeP3mpKG8e+CXEjDs4H7S/98Jr/b1gEmgDbBdE+fOdoyFm5qBDoK043ge0QRl5orz/ALbFgAFnQTt4GDNLzxu9DbSFJweL8vyeuyHmy+PDQMu55i+g+YJj55NAe3z8taDdt3aVKC+47HKIeXX516A91Rfv31V7ZT/99m58Dvjb5x+C9swUrFfityWg7fytryjf/aflELP4IcyllncFrk/WQnyueuLaxaL8xROXQUz1/HrQ1A4bSPfcvFSUP/7HbIipG4HPC4EHcP1JmIH5us5v7CTKLTZ8IDa24vc++3jb5j/+skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+oc0GcbsjALTGBDTLPZ+yRpRfargJYsYHnQJtde1Y0B5PWC3KD5RnQMwDndeC9k75daB1uyQLtGM/9RDlmJkXIKZiCRrcg2ah0ahhRRxo1hmloty8Ao3rUXPwM0tX4mcmzcwT5YLlqRCTOvscaDmr00HrPBXjTu6T17ONRbNveZXGNN5OdLcWgeaIdoFm9XLvv3QpGglfPTUVtKKx+JlvD/tJlLMH4P37YO840GoycFzcO2ENaMeGJory0fJ4iDnXPQK0zv2xz+SWY9yI1FxRPlWF9S8tQPOYuRK14J5VouxnQvNYahga0PcdHwjanMFofLzQFC7K9U409U6MRlOrUu1nEA8qRIN1SCGam5tig0Q5LKsOYmqPheL1c2tAKz4j72vaySaIqUvHuTmoEOP8KzQHC5yT99FtxiUhNA/HmTMIzeDhZzCu2i2vF3oe20v3mcFFeK1yq1e75uO1mqOwXmHn8FrFCdj+EV7e3upUCFEm70M/2pHSIzh+/bAJ1JkiGWfEr6/y68JBM2jiYvyledUdiON+lx0N0KrZhJIbDbT2ErmmLK5Lg5jqclx33i2cCNrJzfh8cChBml6Dz2Jf2xDdFTSjBRvjdIU045trsS9kVUaDpjsYZm0xmvFdxXIc12fiHNhag/27vbj/7NWg1UzANev+fdeIsnVKEMRsa8Q2r7i8J2g7auR9yJ+Ofehwcwpo9T3wII0EK64fBq97s+AorudR4dhnjOjDVh4T3uhXDk0TZUsmXiszCp+1DvbCOf1QvfyejfH4eYM6nQftgML2qWzEe+J96JA7Ctdzo79mwmkj/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfEKbDeLXJewB7Yf1mPlwa700Ppnr0VDSzaxJ1a3x3SWbvM2L+G60saY7aLrsw3m1aKBt9fJLVjaggdKBPjplaEGTUjP6kVRLozQKe2wYMzn2JGhf+WuyrsceEeV/mFIh5ob4XaC94EGD+IiIHNBOuaQxr+yc5guFaFKUtxNWI2YstkSjS6vVKY2JT++/rG3XL0ZDY1mrNJGerE+AGEMj/p3x3/RQTUvGgxMWXsCMsTUONKCHBGG2472F0hjWVIQZl62VWP/WADSeNTRJs6J3OyulVHkpZmE3WNFo2SMQzf4BJtm3mlw4xvJ0g6wdsY/HNg7/COOmTZMZiU8v6QYxPWecwetvxXE/YZQc9/k/oAnWvxsayx2a7NqqJxrVDaekUdARi523PgGXiaZOOBeE5WCfcFlkX2qKwpi6zthHwrNwjTB1kePdsBNNlBGD0Gxp2WIDbcTQbNDOHJAG1T7JBRBzKguzRrcXA0dinzm0GfvWXX22ivKH5zED8p9ScD1/68gs0EaHSVPt765+ENM7pBC0PZp1Ob8lCjRTnewPbxzDLNKmKo0p+AJmsw7QGLZbg2TfbdUNi5hS0I4W4lwfHyLHzzl/G8T0iSkGbVcuzosjY/GQll+OSmN/uLkBYgyujjugIMyCh044qnCcZnaS2alzf8E+ajbgPBNcjHNK1yB5GM/hk5jZ/eQ4vFfmWpxTvt08CrTIMjk/NZbiM6BB87hqqcJnUV1coNe67GpBY/b5WnzINJbjQQClTV6HWmi6wv5daLxX8Q6Q6g7iWmrw+kopP+N3PD8Z59y2wl82CCGEEEIIIT6BLxuEEEIIIYQQn8CXDUIIIYQQQohPaLNn47m1V4CWacJ9r8vze4lyTDPuw1vTGAOapRT3J+50SJ+FfzXu269w4CZMSw3uB8wtQM+GzWurc30jJtEJQFuKqqnRJMcqw33utQ651zS0CmOO1SWC5odbI1VFq0xsZMJteGpnHe4nNuM2bVXosIFmrZQbAOMG4b76c0exru3Fyup+oAWvxXtf1U9unPT4aTIqGVELzcMNl6/tkQl5gsLwxngsmr3lTbgvfeG7uG+6qr/cVxpQhMPRXzNCo3rgWDl5HBP3eCeT8q/AegUWY1u4/XAzqLNatjXuolYqaX0taEVjMHna1/HoQymrkdd3tWJdPR7NJtUBmor4iMCDuF/V1ITfedkumcgws7ESYo5uxL21aQ3ovVh7XPoIurViH6wvwXEQ2YL31dmCncnglnGGAJw7Ayrw36RqrRhndOE9c6bIicp0Cvci+zXi9d0WTf3z5X5njyaxZO1WTHwX1Ipemx27e4CWWCfH4+E89NCEa8ZLe6FLGNcaqFlT6uU87fbHmEAjLiAuK8adapLXMjhxDMaasd/6NWHcp8dGgGapkfe+9Rz2Zf8avFaLC8diSxjW3+iVhFHXXjUteC1nPfbTepvUdNPR4RLNet6AgT/tGQKav1eb/XKhH8SYqzvu34dPbcDni8QqHFtZn0i/TlgZxvxYOAi01mCcPz7cKJM3JtTgmN9TngoaPskppTRJZ01e/tuwVDvEOI6hpyJwcAVorrXoSfI3y3myWfPcpiOoEPtMQqAcZ9n1GJM2DJP65W/pBFrSaEwMXLBFznfnp2Nf82jWh7bCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ7TZIP6XSUtBW/wXNAxlREjjTF0WmrqXVvYDzdCC5p1Krww8BicmaqlyoFlbGdE4Y4tGp3dLqDSNm0xoHmuMRy01Hg2ftc1oDEuOrhblvMHY3FUOTPLSmICfGWaSxtAWzBOkOlvLQduAl1e9gjAJ07qAwaKcU4hmRI+/JmtNO3Fn9GbQ1mf0B81gk/1N0xWUKQ+T4jUkYuA1ffeJ8p7KVIjRmZYd1WiKHjHzKGjZNbKNi2x4UyPC0AzuneBRKaWcGnPu+SppbDMm4P1r6o31byrHMTW4t0wEeeg8mmcvu3ETaO+eHAfal5nfgvZaiTTQj7WdhpiP80aD1p4ETsCEcY1n8eCJP43aLso7fxgMMVNn7APt0D50uz8wdK0o/7YYk56N6JsF2rHTaIAeknoWtP0DZBLWCZmYOG5bACYGnZaGn/m7qxdo47rJuL2heJBBkBH7ZaUmCWunfjLJXlkJJnYLGolzYHM2XmvKyMOg7c6S88mEbicw5nhf0NqL9HBcd4414nfzxtuErZRSuQ48pEWXlGxaqJxrvjZiYrS9ddg/HFG4Vn80ZCFodzTMF+WhPTDh7IEdmBRu2Ci8NzvOdgbtiUFrRHl1eU+IuSVhG2iP2/FAHJdbtqPuEIOoYJyvi/xwPejaBQ9gOV8ix4Yu8d+vgbgutxfNqehuLnLhWup9MInbD2Maa0JAC4jSJcqTF2u24XoVrJk/ajuhwT/kMP5tvdcU0nge1+CAGPw74xY0gzujNc+PNfIBzJCIMYYGbB/nIDwIpNYp4xy9Malx7i6cX/364AEO+Xtx7nQmSPN316/Q2F/1NGpthb9sEEIIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE9os0H8jZ8vBy21CU2OB3IzRDmj7hDE7M7vA1rn4lzQXjo0Q8acQINjRSMas20ONKcZDGjMidsrDU+F6DdW8bvwWvaeaOiJzEJDzwW7NIZ1/QTN8s6XdVmd0ZDkb5QGerMms7l3jFJK+Wni9tWmgeZ9PUcd5oi22Dvu3XRVXW/QdLl8PW7ZdpYAbJPWNLxX5m2YRfZ8kzRf5pehGTM8FE1aLk32XG8zuFJKnT8jsx3HZmBW0tJSG2g1KVjXrHPxWLdYmd3aXoXZeReN/gS0Ww7dCNqbKfKAiEsrboOYO2148MCKKDS1FrqwHtvPS5NpkrUaYmpX4ndU6Jf2GZ7v8R76azLo/vzzGFHuVFsFMet/xgzCCZVoLv3HkbGinNqAGVyPlWnufRb2+x4hxaBlnZUG8aYxOO7DluP9sj2C/T5qE5oym7rI6wX8hgZM5xy81xGncN49lxInyslnsS2q/PAeBdVjW6zZ0Q+0xGL5mftL8BAE/6qOyyB+Zhlmnded2bFzvTTqGzVVXngKMzgbNdnBv6qQhnD/Klyv1udo6lWBcT9WDMWKuORnDgzLh5A9IRmg+Ruxf3hcuD7VeGUaP5KPxtjsyDjQGss1B7cY5cEZuszmFRsTQPPDIaWyzmBcgNdXym2IhBhDq+bEk3bCmo95uXWHCng/S7SEYp11B6s0R6JmqZZaM/qyVZI/ruflcXgt3eERTVvkfNGjN2bgzqnA5yXPgFrQgtah6b0mQ/bJkCKsV0smNqL5KK7xZyPklw/ZgQe51HTVXGufZs5Nxzkx+KzsqGfvwTHspzGztxX+skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+oc0G8b9d+zVoHyzHLJszexwT5exOaLKb3fUYaMcyMOPtnb1lZs/1JjR3dYvArL5nkzJBiwspBa0sXRp+42xoZq2+CU2IA6LRaLl9NmbPTY2QGW8bnkOnWILG3FQxHo3CR+tlO9Z1RoPc1CDM6rtAk2l8Uvhx0LZGSNP+gD6YyfXgUczQ2l7Em9FEqjOnzeu7W5RXFmDG2Lp9aCI1tqCLcuchmbk2oAANU611aNKKy8aDAJrOogkxzsujVVMUCzEJ2Xift6V1AS0gHPtR3WnZv5O34bXu3XEvaGF12BaTjz8uyoElGNNr192gWTWG2vkjbwYtdo00F/8WPhZj/rETNPX3h1DzEZ3uwPFlfwznpBdv/E6UP1s+A2IW3PYxaK/tQmP+yhHvi/KdXz0AMc/3XA7aKzF/Aq1PAJofPx8s+8RIWzbE7O6H82mUuQ606inYB3uFyEzJu0bhHDI/9ShoP/Yai3HDNovy0sNjIObeG5eC9sOR6aC9M+Mb0F7fKdv/0cx1EPPGhqtBay/GXY0HsqxZg0bvuy5bJcr/WDkNYr4d8iVo1zXfDtpzcRtEeVUcHu7yfL/fQXu2Bg+U+VM0jt+cdGl6nRR0EmL29EKD7oyII6AF9cYM1063fMSJjsR+W6/Jgm0KxTl8QMoFUT5Qj/Nw3CX4bFCyGw9wGD8Av+f2DfIQlFnRhyHmYGwn0NqL1F9xDT7zCBqZ47+Q5Zxr8DEzegUeOlExCNenLgvlnHJuDhr3j+bhIUEmG647zmPoLm9Nkp9Z3YzfpzUQrxW8EbPCt6Ck3NXSVO8Ix5ggfzRrV3TF/hfsdchRM54foGL3oFYyHq8VdBYP83B5SV0WYL2Kn8Z71Fb4ywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Qlt9mw8sOEG0Lp5MLHTsl0DZUxYDcQsPoD7THtUlYD26akRopxmKoAYewvut/QYMXHKPckbQXujUO5rdrhwT757J26yM865AFqnVbhftK6X3K9XvzUGYh66eT1of9G09bTrl4nyhoqBELO5MRU0P7xFqtGNyXn86mWbJQXaIeZIXce9m7o178WmZrzP366V+7hdNvTcaPL8aV+7TQ1SNOKllKkZ93P6NeK+Rrcms1NgmaxIrRv3UTpCsWLxATimjpfiXl4/r/r6V2IfbQ5Hz4m1Ahso5pAcG7oxFoRDWHk07epXiP2vxSsfkm7/qylKs0m1HTm1tBtoyeW4R/upH68X5Qw7zlt3f4/74zsXo//s0l13iXK6JongV0UjQAvLw7jPikaDlrRG3sf1PbtjzEbszweHp4CWsAj7b+Xzco918nLsEGs1HrvEzej/+KabTAqXfB4H5Du/zAItqQX3LD+w8XrQ0itlv3/2wEy81lnd5NE+HKxA/6PLH+efzRWyn3pMGGM2aBLfVuMc9VLpWFEOzMdHhl9KcS2ylGFcnhP3zJdtkcnt9iajP+PIDvRGhI/D/rFpK/pJkvtJz1BZLs4hh0PQd6UKce9+dpD0+hlbcA4sOoj+DJML47ZswyS1fl4J+9ZXo49V1WgyBLYTp+9Fn4V/LtYnZ55cZ0yaBI8PP/UDaM/+fA1o5x+Rfdd/P7blgFGY7PnwEfTQWif866R+/YdhYtotlei3dE7ENTh4CSb1cw6WD2DmsxjTORw9unUHsZ9OHnxalJc40OOZds8Z0Mr24bql87a9/ZucOwv/gqZYj/vffwbkLxuEEEIIIYQQn8CXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE9psEH9p3BLQ3t9yJWiLpv9DlJ9adgfETO6LSeVODkBz16S0g6K8byoa0foEYnKfLPQ4KpNCk1zZzdJkNjEak14VzUQj0CgbJvfaOQrrH22SSXCixhdBTEkrZt1LH50HmtUgjYmWfphgJ84P69oYj987wQ//tjlGmoFiNEm7WsM1Dul24pfSAaAFX8Dv1jBD1tvjQUOZIxO/R9ImNENV95QmQSd6u5TSXN8ZisOqbkY9aMEfS0OtaRjeF9PP2D/cGtd16Gk04VmnScNxngGTGdr6oDmt8CAaOVviZJv5F+F3HDUVx+ImnREyBduitVzXuN6V6DhzrlJK+Y2sAq11BzrZB46XRr7qxWgwnDTlIGhnVuPE9beBi0X57zHXQsw1sYdAe2cAJs+7Keo0aAumSKP3tDA8/OK7m7D+V4Tmg3b4Vkyu1TtImuMP34dm3DnxmNRvwbWTQXt6oDwk49ViTBz315k/g/bBqbmgXT90B2jbl10iylE2nE8Nbk1WrnZiagImgvvmMJpEu4XKBLYnnOkQ4/TgfKFZIlXfINkfNqjBEDM2Ck2ppwz4mdvsXUEzN8jyW0cnQoxRM+wrHXiwhS4uOkDONUE9cY3vGowHMxz0x/EzJF72+bUVaJhOTUETcsHBBNDiemOS4Yq98l5OiTgBMdusaPZtL/yLcc5vDcJ1M2mZjCscix3ruR/RDO4Mw7jO78prFUzAeu1di2Zws+bJ1rkS1z+X13BeswGfM0yYR1BZN+G67LBhnPGoXNcaErG99uak4h9GYtw3O+VBIIYEjDmsWUMsffBZ7qOPZoPWmiEPjUh7HRux9tkG0NoKf9kghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn9Bmg/jrH18NWkIWGujue/FeUQ5zYtbitcd7gtbJgWaXGIs0trgsaMb9S9w60HbU9AdtqD+abw0HpbmzIMYGMXnfZ4AW/ch20DqtQhPOhKuk8XHhJ1MgZs6j34H2wbeYubZkvqxb00kbxJh6Yxtaq7DNjjdjJlr/CvneWd2KBjxTbZu7y/9zjp3EjMU9NqPhvsohM7iW45kCyh2I7dQYj+1krpWaQZMJtqETZuJVBsyq2lyJf2vvIk2atSVo2mzqqck+ew77ZKgmk7lrsTTEuXpjTEUFGrP9NN5R5ZXd1hGLJvsDpWj+dQdo6tWKH1DnZU5LWot/l38PGgHbk4gF6BQ052LG2eo7pNHT4MA58PizeKBEYKUdtOf/fqMoR1ejQe+FDWiUztiNcf+ImwZa2gbpqv2sdSzEpKzE8bLmCcxuHP0ezhkfPzpKlINfxv72j5lYr4zlmCH6zdI5sl67MDP4RwfQDB5cgnFLF44CLa5GZvst2RcDMf5+HXdIxvc/jActyI5xaz8dLsr+mrMXbvn0PtCCMem8+vBN2bdM6ItVH53AtvTXrDsHv8U+b3LLcR66GseYyx8/89R6zCpuMOOccbxErgfNxXj9MePwwBfdP8N6P7cYNeth/ik8TEGTwF0V5uEhHH5e3/NsM5r/lWYNai8C++EBGfY8G2gFs+QY8Su3QMzsmbtA+3n7UNAKH/By/R/HzO7JI/FQi+K1+IxTl47zWOhZ2Z5NGThXhO7C+jtD8D4EF+D161NkXEAJdqzgnvgcXXcC7717cK0o++3Ew0nq++BaY8rBgwzUKHxe9T8mJ4rcB/A7Wh3YFm2Fv2wQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT2iz4zfjsmzQCsvRqHrb40tF+aMFmKnw49GfgfaX7beCNjJIGre+7jkOYrKd6FgzD0cj0++NaBgyDZGm8TALOuRc/miSeTsPs9uqEDTOZDVIs1hTLDrF/lqMpnFdJs3lFX1FObI/Zj21GdFUWd8VDU8RfpjBuSlRmroCTfh3rvCOy+B8y4itoC2eiYbJulRp0vJE4fcIyLKC5teI323QRJkZt/AFNCXaM9AMbq1Co1japZi5tmx7qij7l6Fx2hGDBnRjK/4bQasV+2m9V1u4g/Fao7qeBW1/FhqxTV1k32rNRdNZZJdG0OzKBlpSNB7WUOwnzW6TX9wHMd9na9z+7Uj1gzhuIt7B7MDT39ssyqvvGA0xL7//MWh/ve020H58/A1Rvu2ehyDmgylf4fXXzwft07n4mY+fvEOUX5u8CGJeuHA9aK+lrADt2ivuAu3pVJmp+83xcyDm5csXgvZEGB5I8tK4H2VZYcyrN3wD2vPv3Aja1X/aCNqanDGibOqFxk27XeOQbieenY/t9NTS60B7dIbMtL7gJ1yDH7hqKWi6uA/u+4co37j0bohZNfQj0KZUPwjatUP2gLbym5GiHH5FAcScO4um69mDD4J2sALX+HFx8hniF1NfiCl0YFb4Xr3zQYsPkP1h41nM5v2PIXiP7tg6D7RXRywB7ckNV4ryVWH7IWZJAta/vbDnYjv5V+FalPirXEuLRuDatPHdYaCZMvEzQ3+T60xtJ4w5dywRNAsu8codhWt8c42XK78J12CdGdyj8elX9vrX5v1GTQbx5mo8wcGlyQ7uqZVfyqo5+MFcgM+hLZrDXCJ/w4MSatNkOfZnbMTYh/BAlLbCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ7TZIH6sAE04YZpkgosuDBFlM3pG1ea67qC50WerGjzyAyzVaMBJ9UMTX+MxNDJ16VMCmt8amyjnXIYG8cQVxaCdH43OnOQyzNg7MCRPlLN2Y+b0c0Mj8Vpr0dQcM1FmfDx4GM1prkxsn8AcvEm2MXhTrCWyK+Q0REOMqVpzk9qJEgcaM53ocVKmFtkGTofGdB2J5iujC035O/fLNu7cgPfFWoXXt1aiIevCz+mgBTdIw3ZQId4/h+ZQgehIzP7pbEEzl6lJXs+vHu/f6e3YJ5OysC/nBUujnrke69ry93jQ0uvRlFd0D46fllKZffpbzxCIcedqbng70rQfx6q5Cs3un/wiD31Iq8OYG1bfCVr3YjtoU1c8LMqZuRhz9/YbQOuWg/Pi7fswrvMBWbcF5yZATPJKPHDj/dkYl/lBLWhfpsts1unfFUHMswY0oGcuwc98ximzg6dvxfn6mQY0g8cfwfnui61jQMsokddrKsRDEGLKce5oL149hZnWg4pwHL6+dYYoB+NwVh9m4aEFbk2q68/KZDv5NeLnfVCBbelnx0eLgmYbaM2R8jMLKjHG2Iz/JtrZWg7asmI0T+eEyHWsKQezLm81dQZNZ4Y+ZpXztV8NfsdXo6eDpss0/kv5ANAMXtnBV9XjQR11ZZps0O1Epx74LFSxBp8Lc66U3zc4D681+l48LGDpRswgPuTBA6K8Zs0gvNYlJ0DbsQnbrmsKPgPmFqSI8tC+eGDKiVx0rrcMwsNCLAfw3viNkPNYXRb2K+2BKdnYrsm9SkX5QkESxAydgG2xfT8+b1/z1GrQ3ls3VZQNd+AhRAV1NtDaCn/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+oc2ejfTYCtCaKjGh1RWJh0R52TkbxKwrxD1wkUdxX+175+W+4KAi3FP6UN5c0Dy4jV49nn0laGG5cm99vVPjSehpAyk2FPf+lY3Q7LGzVIpy8TCs2FNJu0F7/vpZ+JkOuR9w0OjTEFPUivsBG9Nxz3yIJvmft4/B34i+A7e14/Yrr1+Fe1zD87E+TVHy/dn/JHbxumTcd+w2o2Z0Sq2ukz/EeIy6a+E7/Kj5mKRuc4FMinl52lGI+fbQJaBl2HAsnjDFgDZ84jH5eYdx76Z5KF6r8pdY0JIHy2Q+uSdw7Fd3wbYOLMO2iNfU/3yL/NvQINyPXxkYAFp74u6J+3Rd69ET1WnEBVFuXRsFMdMG473OCe0K2h2jZfK5DQuHQ8zUnpo9y+NxvNzd+3fQPrpK+gDu0yTr++B53N9/axQmVfvzU5iw77m0daL8xScjIObZ5O9Be7X/VNDe6/W1KD8QeQ3E/KnnZtBWVKKnYORAbLOCZbL9Q1LQg9Kk2cvfXszohHVe6RwF2tDect/5Uc16+1jmOtCe16ylj8atFeXLjbgX/pLgHNCW2vqD9kT8GtBmp0m/xPsDf4SYPQ3oqUj3LwWtVxomHAvyc4jygEswOXG4BZ891lWjP8zglcmtNRSTpA6KxOSt5xV62ZIDcJ/+Pn+5njl1DzLuf504zlfkXUAfpw2naRV+TNbbo/kn7eVr0Z9hacDvtunHwaJs0FhWtuxB36FJ85nnSnEedkbKe7gvF7MGBmkeewynsSKNcZpEfF79qM+QcxCTXYH18mTiWnO+Qs49LfH4jLbtBK4hRht6Tb95D/1fnl6y/sZ3sV4td+Cc2Fb4ywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4hDYbxLNy40CLDkMD00enR4pycDqaOivz0GgbEoJmq887S7PYZeGPQ8xTyStBe+Tg3aCVZmAisfQsmRgoT2Mg6lLmAO1sIcZlbsIEKM/MmC3KsfvQQJR8dSVoYYfRdPrIeGmuu27RAxBz57WbQAs8h6b3Y8OTQbNWyPdOt0Kzlqmh495N43eiGUp58MAAf7tXUr9g7KMh6OFTxZfgUAg7I8tBxWi0aozF9i0djNdafqwPaAavJt5QjIkajWbsM2YjjpW6kWhyPFgik/741WJbFGej6c8P8w+qqnwvA7oV6xA/owA03bwxORQTcp3zun5aCo4LexMm1WtPwlahadSvHI2qLS/K72KuwwMZTj7XG7SARkzWuPz58aIcakdj6YnnsW8lnkMT/tdOTDiWfFTW7e+WSyEmdSW6QF9+DA2GqR/jnPHihKtEOWUNtsX78VeBFt6I/f6prjeLckIezglr/NHMHlKNh2Ts2oKm0k4tcq6vO48J4GLKOvCQjDfRXB9Wid/twgJpEg0OxHnyjS+wzUM0Zt85C2VSycBSvMcf5aMB378U58C3SybhBxTLZ4FPivD+HTqdClrfcTiJHzuLSc7qUuT1887i4RfmcM0Xr9UcFhOGbe3N5qIu/zJGKaVW5mhMzV7z86ZyjdlXk+CwvTAYsR/VpeJ4cAfIOLMd6+x94IhSSp0/iIfsDB19XJS37sJ2Gzf0OGibd+FBBjO7ag5Y2CAN6N17YL/KzsYF0TYYn/dqd+IhLbG95Tx8fH8axFw1fidoP63HsR6QIRO1mvLRpN6Ujs8oxiJM+FszEvu8OU/GVdyCJnWz598/oIC/bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn8CXDUIIIYQQQohPaLNB3NCE5lJnMJpF7uu+WZQ/X4HZsG0pdtDcJjTjvVYqDWWNcWhQKtRkza5Jx7p2jkbDZPGkVFF+fdQiiPnbrutAe2gQZuJdZcZMz+nh0uR6uisaXJ0evAW1g9C8Y3dLo71/TzvERGoygzcloZG3wolmeWewbFunG9tQlzG1vSgaoemqGq9Sa5D8HgZNld3RaPo3VKIpv7qXvFZ4Nva/VitWolWTcrR3OhriThxKFeUELwOYUkoVFkWAVulAo7L/sUDQmkJln3Fbsf6BiWgCc57EsWjw88ouWoWHPDhceI8C8rBd1xrQ5Ocdd6gSzZG6Axbak+bL7KgV4Pwz/u0dorzxYTT7XfcmHmzx3Z/RnP3bO2+L8tQXHoWYvz7+NWjPvjMftA8feQ/rsVIepvHetC8h5t7Y60F7PXM1aItfHgTabTH7ZV0zcT14awDW/6njl4P2iFfW61d+uhJirp69FbSV76Lp+IZpW0DbtE3eJ48Zx4sjXJPVuZ2IujUftIJf0HD64N2LRfmtLzAz+NzrN4P2w5KxoL1y5UJR/utXN0DM8GjMirzYglmzkzRZs102afLvHVYEMVlRaLytbEVz7Ox+h0HLDCgW5d8teDDDpTFHQVtW2he0MVFZovzRYexXkxJPg/bTmeGg9UvE9WBvuTSXv5z2K8TcVDsPtPbCWIGmeWs5/nt1aL6cp1vwcUPVnkUzeAguKepwnrxfxhQck5v24XriX4P1WnqkH2gmr+X7XKXmEBLNc0bpeVyXVRqas8+XesVprvX9Hnx2NPrh96wvl+u+VfNTgaUI75EzGZ93Iragabze69ygpBfx+vWv4ndsK/xlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4BL5sEEIIIYQQQnxCmw3iIefQGGetQsPmx9mjRDmoDmN6xmGWxsPR/UAzGaRJJqgQ3TV7GzC7Y2Apmmsi/BtAq6zzMkVrzNrmRrxWiAmN2G4L/u2ZCmlsizqKGUgjTGjQDduH5p2Q0dI03noAjanHuifg32XjfYsai5mKLTWybVs9+B7qV9dx5khv47dSSmX8gPfUnimNg01R2GcaNAcNmJoxLiT/X2fL9GiaxNiCf3fiQCpoAWWyjfcd7ay5GEotLvxQfzt+J283WsJ2zLhsTw8DLeYMmsAaYqV7r0aTKLdsC/Y/nSHOegFN4/5VsuzSmAWdgR37byPuXTjmLDU4ln78Rmb9Tiqpgpi3lswGrXMWHmJxybZ7ZMwRnC9eypoBWuzeWtDeL5kAWsYiOa983ncUxHT7APvDonQ0NTY9hkbeBS/Iz0xZgH33vmvR9Nr5R/zMl+6W3zNlExoff6nHbNYJJ7DNvt6K3zOjWraFXx0eumCp1Y2z9iFnI5rBbRW4vj6/U5rwbThNqq/24qEFoXg+hXr73ERRtmC3UkvPoek6QJNpfH1xN9CCsuVcsK9zJ4hxZOOBFbsTca7ctA3rUTJMmrp183DsCBzDJ4+ngFaWJtcWjx3nsZO1aIx3a56yShs1rmmvrrWzESfZuko8HKS9CNIcYGLM1RzQc6VsT8smXGOefuw70J75Fg8fuOsaeZDGu8unY8y49aB9+cMU0Mb2OAPa7t9ln+kTiwcUHHZi/VM7l4JWcADXv6Gjz4ry3gvdISa+B8775fsx0/2V43aL8k8VIyHmknGYJX37QfzMmx5aAdo7q+T8euFpCFGqIUAjtg3+skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+oc0G8fBpaJypXIeGmNszdonyZ4loXpxgOwnahj6YsbNnkMyyeXBaEsQ0uTBjYuscNGSG+qGZsMUrA3qQEWMa4vB9zKjQlGesR9N4gEWaIau7Yl3tLjQh2nuhkbfcJQ1lzu6NENOicSs3R6OhMcGMmVwd4TIuwoLX78gM4hHH0XCYNxOzyHq/Phtc+P0DAjUG6EgcCrNmyEzQ2x5AU6wzGOsVeg4/s2okHg6QsES254VJ2BecGmP82YPJoCUW4L1pjpDfqeA67FfX99oJ2rdb0HjmFy37g+eCpq5pOAYsZ9FQ1hyD9fCeinRZT2udeHBCe9KQgfew7hy2Q+jEEvl32VEQM2XqftAOHh4A2tLhfxflK08+AjGLenwG2vVP3gza/MgjoL39dLQoT4rAbNAXPrSD1iMQ14Ot72DW92m2XFE+tyAaYmYGlIH2WyauB/NjpMHz85sxM3PfTtmgnWtCo22nTMzg3JgQJ8ruhGaIqbf/+wbJ/y2Bg9FI6izEjMe9OxeIck42HqJy4xAc90ty0Fx/R6rMyP6O5yqIGZKIB77siOkF2j2ddoP2t2hpZh8ZmQMxjf3RiN09qBi0za4+oHmvYwGpaAZPC8B29VhxPo0IkNcq99OYo1twjjLX4hpRVIWmY6NDxhkN+JyhXP/60BJfUVeLfT+qAdcne61sg4hCbMsnl1wPWuwJjPviA/n8GKA5OOSjdZNAC9EcZLBjM/ZJP68m3nUU54ogzWNP/uk40AyJOF/sOicPdfDE47NHYQFmIzdpvudCr0zjJn9s+x05mkNmQnDdemsdPpebnLJvhS7GQwxKpzGDOCGEEEIIIeQ/DL5sEEIIIYQQQnwCXzYIIYQQQgghPqHNng1dwq7QYtxT+MXZYaJs1uzpa3ajdyGgFN977rFdEOV3D10KMQ/d8BVoG5YMBq3PjdtA29ck90gfb0JPSHg27i9/7fhU0NKa0AfhcssEPAmb0EvyyVzcJ5vxPe6xs02W+0VN2Zq94oNxz6C5rm17PM0NMi7JH7+PqaHj3k1duG1XtUThZkpDoNf9qsO+ZjFivzU0o9/lm6NDRTkhAq/lsGG93GZscz8r3tPCMdJz0pKhSRZZi585f8R20L6ORj+Jn7/sDy477ifeWpYBmo6YcLnXuSwP+5/ZH8eKK0CTFDMB9003OOQeZv9AbC+3WbORtR1JWYr3NfA8Jrpqek/uo/evxHG54RecozqdxL3jl3//sIzZgn1kbtiDoCWvx/Z76rrLQYtfKQfWZ1dgsrewVZhI7MA1mNRKfYFJ/XZNkv0r/CAuOaswV50Kx9xU6vOJsl1jVmF/OBuHe65tF7Bf5mVj0qxkp+yrurEXWNJxSf1MS9CfoUs6W7hINqifxmby0xJcd6yY+1C99bGXR0MzD2/Z0xO0wBocK6+tnQWatUauKZ9u19SrFPvMRwGYPM9Pk5h1fY70EbWWYWNYu+JY0a0HOSXSb2Rw4ufZG/H6rcF4j4wuXEu9k/9tq8a+bHB03BqcFIvPBEWTbKCZvdbXwrE4jrr2Rp/PWQt6EU1JslO6NF7B9D7ov8rXPMtF98M5q+KAnAdC4nFtcpagNyepK/rMCk/hnDJ0sPSZ7TqFnoqxvTDZ4OYjmaB17yq/56nsRIgZkZ4L2t58TJTZZ8BZ0A6ckvNGy3W4tnUJRC9vW+EvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT2mwQz5iMyZ7KP0oFbV6GTNzzZdB0iInxQxNOiw1NVFu9fJXWnnaIqXKjY625B5oo+1nzQWuMlQavvdWpEFPeD5uoa3Q5aMXjMXFSdJA0QRVOQqPOpcGY4PCX8Zgcy+mR9QjQ+DN7W0pAs9Rgu1oNaIhrsUlTV6AJk6q5bLpkbO2DvbvGZKczy4V4mTyN+Hd11WgyM2oS9wxOl32mwICGPbcmsY5lQCVo92WgqfvD7ZeJcqPGlGgtwf5X3Yr199OYsw050thr0Xhb7fFoaEzchHHFTmn+jT2IJvsyAyZZjNuDcSUpaOw1epktzbsxoVDUEeyT6imUfEXtbZgpyvQP/M7z31oqyh8/PwdiTtz7AWgjzt4J2vrr3xDlGdWPQ8wrsxeC9kzzdaD9echS0L6Lk4cg3JxwHGJ2xeHcNkyT/G/xjf1Buy1FJhLc2hkPJHguGTvcM11ng3Znxl5R/rAKk3k9Mmk5aO/+igeLzB66D7TNp4ZIwYoJrJzBbV4y/58z7aGtoP3yLRqqX77jK1F+aMWNEPP9Ze+BdsuHD4D2xu2fi/KDC2+BmL9P/wa0h1biZ3418yPQbvv+LlGeOeQQxCw/jAkerxqISTF/2ouHLjzf73dRXl/dA2IGBWJfjs/ANX5cnEwYuXDnMIiZlXoMtIVnR4E2p/th0H6qlf3vwfh1EHNTHJqC24sLuZiQMygXx0PyGrsolwzHAyYaNqOB2xaFhnvzAbnW1SXjmn/uKLZJJHquVVULJuIzeZ8nU4rzeXQeLpzFQXgtdyQ+Vx0ulnUzOHCN33yoO2jBcXhaw+kTXgb6QHxoOfU1XivyMjSz53yPz5iqn6x/yAeYeDLlOTTjtxX+skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+oc1ut8LaUNA8NjT07LZLM6Euw6lL4d/5V6GWbJImGccRzORo648mPv8sNL1aRqJR1b9a1m16NJq7Pi3F9LZ1TjS4RhzE7Jr2a2XG5uACrENtK9Y1fid+p+h5DaJsy8GYHCe2jzMY29ViQGORf6V873R78D3UVNNx5sgY9HOqVn/8bjXdZJubsMmVqwW/m18jXivvA2miCqxBA5hfA/aFqgo0N79aigcleHnyVegJPOzATzN+lh7qB1pwFv6tw+vQhTBMGqpayiNAc5s1GdZbZftYatGQHpata1fsa621WFerVwb7xgSsQ5Vm3LUnrq3YVgFnLoD25ldzRTn5lB1ium5FA21aXgNolx+5WZQTN+HhGk/2RgN659V4SMaioUNAM74bJconnsbMzBXvpoKW/2fMLhv8Hq4RBS/JOaliUQrEfHT9WNBCvsVrZT0uTZkxeyFEvRkyBbROO7GvrkjrBVrCeRlXm6k5sKFKM6G0E9vLMftwQDnOD58UStO49+ELSil10oGm2pYQvNZ3ZdIEbcRlR31RhAZoSxXOBX87Pw00k1fW73P1URDjV4kZqE1KM0dp5vUjDbK/bTuJxtjGVpyPyg5jNuhfMqRZ2dSIn1ffinOUW3MyxzF7AmiGFtkWG+vRzN5cqUkH305071YAmucDHKflg+WYj9uBz0an70UjduwW7Kcl4+WYTFyNY9JwCc6J1i14/Roz/m30MdmPagbiHGytwWu5LXjvE1fh9ZvmyQFjKMD2auyiGVQ7bCB1nibXmtzDOIZvfmAFaG9uwXG34KGvQHtgww2i3PpABcQcqcB+21b4ywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4hDY7fhNDMXtubjCauSZFyIzYpwMyIaZZk/W7JQxNVNlehmdHMhppGjz4FfwGoiFJR52X9/tkI5pfqofjZ3ayoPny7BTMiBlikBm9i8agqc1oQK26myYrukeaj1pC0YwUaUJzU8wBzLocZ8J76bLK9g82NUOMu+P84ao+Cd+LGzqjYTswolGUGys02bZD8O9cLitoFdNl26V+iga2pkRN5u5aNDR26lEMWl6rNCGGxqHRraoSs6+O6pEF2r4LaHhtDZV9yxGOfUYzFJXRiWMx/KT87s2R2BkqB6EZ3ODGtgiJs4NW75LGOY9Jc7CEtWP/baQuE/tNzWCcM8ZecUCUj2T1g5g3B34L2jPD54P2RS+ZwfmaKzHL82MDl4G2+hXsD5Mi8YSAXU/IAz26BmG22cxnS0Fr1HSc+vtwXom1SO26B9e06VpfXRED2iSrnNc3TsW5bVh6HminUjGrbkZcEWjlcV7m9SCc+5vDO+6QgodT14L2eg0eNDAmSs4PJwPRlD/Aeh40ZyiOuXHhp0X5sAtNy6Ga9dCIQ0WlBOG6nOuSi3BqUBXEnErAbM3xFjygwBiB9ys9QGYCT0zE6/cOxb5wxNgFtMlpsi2WVgz4l5+nlFIGjUH/fDUe5uJ9CEesGb9jRzIuGtNyb3INAq0lzOv7GvD7hx3FdcHcgOtHQL6cGxyaPtpQiAeyhOmeVfBPVXOEXFPqy3G9javGzhx2Gp8X6uNxfaoptIlysGZcWPNx/mtMwufC4hrvNRKv9faaGaCZYvFZ7tl35oNmGCrjAl7FDOLGp+z4oW2Ev2wQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Q5l34pwpx32RoLW6C+/icTPDj14Qxx5vQ32Atx319Vq+Nn0GaxGXm8bi3rXU/7oc09sN6RJyQWtZw3Cfc7W30QTT+HeuRsBX321tmSf+AdTHuSew7DpOCbTENBu1Cq0woZsRLqV9rBoJW0Rv3GH9vH4p1tcv2P9OI99tch/eovdBs/VfKgPfU3yw9FI0erHNMBO4tLynFPZjjM+Te5/VX9YSYwb1yQDt0Phm0mfGYMPL9okhRjghqhJimJuxr0ZZ60Nw9UEsJl9+z/jAmbGtIwPZpCcZ/g6j2+uoRx/HvAmNwrNSlYRKjQKMmMZrXfuXQs7ghNaC84xKqKaVU1E6cLoNzsC+dekL6JYJqsV1eeQ732secx73vN3z9oCgn7sVNv2/4zcRraZJgLvkT7m1uXRItylVX457lqjXoS3GPwP3kAcvxXn8zQc41wQcwKVmDZn9y5GHsX4tMcn941Docs7sHY9K2uAq8fvYRHKNJRXJSra7F+62x2LUbT3x6M2hJhbjuLP/LBFEOS8SxNDvgXtACynHcv/O1TBip+/47c9NBM2usLfvLsM2bY+QFz9VHQoy7Hid/ndfR7dTsmW+Vnr3CfLz+12WX4PWNuLaszvHy/mg8AB+eHg2ars3c7n+9lp5uwvlat+a1F19+jwkzU1tKQEv68pQot2aiZyhAMyZ1hOTJ7+vSWaaC0TfpMWKfSf8JPUNNyXJObD2m8ZKU41wXveUQaK0T8PnL4ycrbK7T+CHP4sNcbQrOPY2Ncn4149fWPieZTqNvtTYD2996Vs6n5ydhXT0H8LlQTUJJB3/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZoP4yHQ0wh7c2xu0P6VKZ+LXlukQ0zcQEwotRq+fynZIM0pzJBpWjjgSQWvOwGRPJa1ojqy+XBo3B4ZUQMz2MZ1Ai3SjkffCFcGgvZmwRJQfmToPYlya9z1bNjp/Ag3yOzlC8O9uCt8F2oHNmNxr2L2Y3GuF33BRDvXDRDDxOzWOpHbChN5ZZS1A87TdYRNl/wo0RzYloIvKoDHcdwqolJ9XgsNln7EzaLEpmDjq/f3jQItZJ+uRPwQNgQndMMmaLnGU24X9YWh0nigv6YbXf2X2QtTeux40/wxpknPmohn4sZ7rQHuh5HLQwjXONo+Xya8uHe+bqalj/20kfn4uaGWfpoJ2xZ9lO6x8bDzEvPzCp6C9dPdNqF33nSi/deo6iLl90gbQfshB196VSXhIwXdx0kzcNxTnwAvJaAq8pyvONe9dMgG0W/rIuIXZ2BZ3T8FkdYtOoxn11p47RPnHdZMh5oNpX4H2l2NorJ45Gh30uw7JgzluHbsRYr6twu/YXkRPLATNXohjOuIWub5W/54KMXP6HQTtFwcmaHti7EpRfvvIRIh5feCvoD0XcCloz3ZbDlpdhjwwQLcefuHCeddqwIMSLu+Npt1qL4N4cir27/e7fQ/avCPzQfuu75eiPHvnXRBzR7ftoL1TOBW0D/ovAu2mOjn+34jD77M9Bc347UXSRjzooiETEzvbb5GmaNNqNCiHz8W+XL0En+VcU+yibNiIh/+MycQktxe+wqSMp+/GNavb5/LBwnwXmsGbsvDvCv/aB7Sg7eheT54t14y81WkQ4zcHnxec2/GwIncn+UwWtgEfmqt74jNySB5IyoaPgMqvWT4EmRxoItcZ19sKf9kghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn9Bmt8eJSjQJ6ky1myu6yQ9oRMNKrQuNLf5VGNfTX5qIQvIw6+a0oCLQXjmKRp1d/dEwFLxWmrrj7kdzUOwezND64sNLQLtz8f2gNXukATgsG0LU3w6iEbJrDma6/MtpabSN3lcJMR9VjgLN0IxGunMONB/ZvLJYFjnCIEZnGGov/DQGcR2mJi9jsSZRa93pCNDM9Rj47akhohy/H9uyPhGHUKnFBlr0FjSlN8TLzzS4sH1Lq9Ccttg0ADRXNfb5HaXSTOiyoTH75X+gGVyTPFe5D8r+YG7AoBd/nwOaRdOurlT8Nw6TXbajpRpjLPUdm0H8+HE8LCK9sAW0b76RYzo5Dw39d/9wO2idc/EwgFfekvcn9hDGfLEMTbvpW9B0+GkfzG7c/RdZt00JPSEmbRn2++U98XCQjO+wfy1NlEbKhO14eMcHoWj0TsvCAyq+OiMzPSdkY8xD39wCWtJJPNBj6dG++Jkl8nv+cA7HmQWn5nbD+TGuwba8etDKvpP9NLwC78uK34eCFtiEY7XGJc29pjOYYX78SMwi/cwBG2hdBuCaNWXdQ6L8zkQ0ThdvTgLNfMNO0JZuGgLapeP2i3LhyViI+Sl2MGg1Bbj+HctMEGVXLR5QUtyCf6f7J90TmoNtVKsMXFKPc39pmeb67YTfaTzYx9UfDet+q2yiHJaL80dhFX6PEBzOqrZRrmtRVbgGFDXgtVrCcF22aA6Lqe8k+3f3yHyIORuOzwvfD/0AtKsvPADaiq6rRDn92B0QYzNq1jXNGpyZKMdZQTCazVU8Pig5C9Ggbx+FjR14RB7W0BSj6bj/iwz2/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfEKbDeJhVjSUFNowLjVYmsDyAzDDcpULs227rGhOy3PK7JQu9MCqQw40rOk8Wmfq0RjmsMnP7B+YBzE/jcKMt7/ZB4JmO4tG0dfPSKNoYCUagdI7oemqwYHZzruES/N6TTN+yd9ze4CW2lwL2kfH0EjeOVsa4ddvRwNlqkKjV3thqUNjkssf+0zUcVlHazEaKIvGYxZSr8TjSimlnOXSMBVQiG3pCGubYa9iEN77gGIvw1o0mmctx9Dc1ZyHBywka8zTtV6Zn8M92IZN0SApZxheyx0l+7e5DuvgMePf6cZ1RQX2b+Uv62bSmAWbojr430ZCsP8XjMNJKaCvNGfX5qDBcNpUzGC9MxuNqnc8uFSUvyvBzMx3XbYKtO/ypoGW3hmz9npMsn/Fd0Yze2VPNCaPDseDOQ7GYly/aJnd90wIGtAnjz4MWvZv3UEbkijnyuLaFIhpwXNAlPkHPOQjPBKXvtYAOZavSscMzkvW43rQXpQOwf5vrUCTcm2GLAeX4Lh3huNYtWoMtN6GZ4sd6zVoyz2gJR1GU/rcQ7eCFnlQfubDgVdBTJjmM988PQk0YyvONSfsMsO6KR4PC+gegH3ZE4Cn3+yskw1rCMDvGG/BQ2Y8ftjWqRYcZwaL/MwgI64HBtO/b9D939LSFw3J5f1x/jN6PQqVDsQ+atmNWjMmI1dhm71My1F4jyv3J4MWkgCS8miediv6yDHVVIFzWGNXHHdz12GfN8Tg/eq/7xpRNseggbuoBJ9HPBn4PHm6SD7DugfiIhm2HZ8XanpgX07/HNuxaLgsJ6/H9e7CJGYQJ4QQQgghhPyHwZcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOITDB6PxjWqod89b4PmMaLJxD5ImmRiN2gyJyfojG5YDdNcaaJq/RXdrJUD0PySuAHrVd4PPzPYy5ttuwoNlP53oSEmZz6azTM+Q5PZ2ZulSyntNzQYn7sCs4RmfIEZWU8/KLN+d38LY049guam7m9gvbLuxoysGQtlatxzV6FpKX4HGuK2rnwcNF8wafiLoJUMw4MGWqWfTPk14LUckdjX/Bqxz3i8pLg9aADT4fLXZL+2o+GrbLA83CB+qx0vphmeHgv2SbcZP9PQKo2JuuSf3hlUlVKqsicaRb0N27o2NKWiGd9ZiAc4ZPQpAK1khTT76g55CCzCzzz00cMY6CMG3IFzoEnTJRpjZMcJz8ZxY8/Aexh2Dueyhlh5X0Pz8Vq1nTTXysO4hjiMizgm56T6NBxT1ko0Cto7ozE04gSab2vT5YC0ZeGArOmCfSSoGMdLQ5w0lYadxWsZWvB7e8zYn+3dNN/TLts/fybOCWEnsQ2P/v0h0HzBtGTMUOxxYAd0VchDWgwD0ZRvqsa2a+iO66vHINtAdyiHqQXHpcGFmrEVtZZQeW/8mtBM3WrFua0hDu+pU3PuREOK7A9+dfh37gTNaRSVmtNoomRbG4vwkIzWKBwrfhX4DORJQqOwp0ReLygdzeZ1Jfgl829/DOvqA1I/eBO02J0aw/YsOQ/E/BwAMWVX4vePWYxxpYPlvU/YhnPkhUnYP5I2Yj+qScexG7Nf1uPsfOwfXT7He9qYgPc+9JQdtIKpkaIctxvnyKru+L3DT2P75FwpPzN2N4Qo07wy0BqW43OheToeUNC0WY7/TjNyISZ7Wypqf2nbGsxfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT2hzhg6dP6MVt3src7HcVxuai3vP6lLwDyOPoJ/BeZ3ct2vS7Alumop7dIPzsK5lc/G9ylEn9+2mh1RCzLYbMLndtKl7QVvbOAQ0Zye5F9RYi23hjNQ1It4Wo8PrO7lxT6K5Gr+jx4p7T831mnsZKvcD+ldpYoI67t20oi/u6w4u1CSR88oVZKnT7N00YPsGFWNc1N15olx3CJMHFc7HPdPmo7gfPOQ87gVN/ClHlHPuwgSY4aexXo0xeB/i9qBforq7rEf5WNwH3zc9D7Sqcty7nRIpE9XlVWKiulszd4L20dkpoJX+hsnYjF5fc/pM3JC67kI30NoT+zgcv5GrcL+tZUyFKLvy0f8UORX9YY3fYCaqyCulv8X0OHq8qu/APtKyEOP63nUUtPyHZRa8lIeyIKb8qVTQEv6E+3ldV+Oe/LpHZaausCtOQEzDXzCBX/jj2FfPzbOJcsQm3J98+g1swy5v47UqpuO4jV8iJ4+hvbMhJndHx/XBvHexHxl3o7mpvpv8vpG70DNQPQ6TqiV/j59ZNErOW2nLcAycn4xrWNJm9EGUDtLsc8+XfbdwDM7N4dhllL03rvv+ZTjHGoJkXOgRjKnSzKcBlRqPZxc5x9afwrE/dORZ0PbmdwItNhwTTRY6ZN1MOpOdP3oW2ouQJHxGq5yJ/cj/oFx3KtEypEI34Hpe2QOfORK3Or1isC9HHsZ2qu6qeYbCaUCVDZD30FSF16pPxmvVpmH/sGdEgtaQLutvcONYcWuewssGY1zEcVm32jRsr/BPce2uHYXrQ+KnOJdUjpFxnnlYMdf9/35SSf6yQQghhBBCCPEJfNkghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6hzQZxSy0aQ4I1ptoWbxOxJimZtVJjMjHie0/pOpl8LsGjydC2Hw1yBmc1aNZ9aJgMKpL1X3+0B8TEnMW6Lj/VG7SIYk3yNZM0xBmcaGqzFqLhydCMTiZTk5cZyIRGN387GoaUSWMaxz9VLqsUHeH4fZzlHfdu6p1UTiml/O3Ynq0Bso7+VZiQJ64UL1Y2CE3dBT+kibJFk8jOfAT/LrhQM1YK8J66Y6XJOu0X7LdNCXj90in4nYKL0KwYUCXNhEY/HK8nCuNB09HolEZAtxv72mffTwUt/ILGcIc5JVWQJmGfNw4HjpX2xJyFpr3AcrwXJfukKTrqApr3y39BI3PMSTRgFi+XhxLEG9FY6tmKc2BQAc6Vmzf1AS3FKvvlrqNdIKZ7uR20mjfQ5B/kQtN40utyPJqi0cAY/5pmDmzC75n5oJf5NghNpumfgaQlaREufY4w2acPr8+EmABNssn2Ivg3XMN0mTotNbI9jRpPceR6NGs3xGBczAF5/YZE/LvY/TgPO8LxnoZcwPmnKVK2uZ/m8BIHnkWhrEV4//zw/BhlzJL1NTVjeyX8rukLoZpEhT/IcR3qwe9z/vWuoIVF4oIbkINrqa2nPMylPhXN14ZA/Mz2YlDcBdAOLMQ55drb14ny58snQsyjj/4A2nM/XAta2jOnRfn8AXxGu2X+GtA+WDYNtLDeeABQ3QF5T2+eshFivi+bAJptLCZVrtyNyfPuHi6v91UuHpjS+9LToB3cggdR/PbgG6I8cet9EPPB7R+C9lTe5aB9NOdn0BZUjBLlqmE4vwY48YCItsJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT+DLBiGEEEIIIcQnGDwejYObEEIIIYQQQv6X8JcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4BL5sEEIIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4BL5stIHNmzcrg8Gg/W/37t0dXT1ykXDw4EE1a9YsFRERoQIDA1WvXr3Uu+++29HVIhcB8+fP//+dAw0GgyosLOzoKpI/ONnZ2eqaa65RSUlJKjAwUGVmZqoXXnhBNTY2dnTVyEXAgQMH1NSpU1VoaKgKCQlRkydPVocPH+7oav3X4NfRFfhv4v7771eDBw8WWkZGRgfVhlxMrF27Vs2cOVP1799fPfPMMyo4OFjl5OSogoKCjq4auQi444471MSJE4Xm8XjUnXfeqVJTU1ViYmIH1YxcDFy4cEENGTJEhYWFqXvvvVdFRESoXbt2qWeffVYdOHBALV26tKOrSP7AHDx4UI0cOVIlJyerZ599VrndbvXBBx+oMWPGqL1796pu3bp1dBX/4+HLxv8Fo0aNUnPnzu3oapCLjNraWnXjjTeqGTNmqMWLFyujkT9IkvZl2LBhatiwYULbvn27amxsVNdff30H1YpcLHz77bfKbrer7du3q549eyqllLr99tuV2+1W33zzjaqurlbh4eEdXEvyR+WZZ55RAQEBateuXSoyMlIppdQNN9ygunbtqp566im1ZMmSDq7hfz58avm/pK6uTrW2tnZ0NchFxKJFi1Rpaal6+eWXldFoVA0NDcrtdnd0tchFzqJFi5TBYFDXXXddR1eF/MGpra1VSikVGxsr9Pj4eGU0GpXFYumIapGLhG3btqmJEyf+80VDqf/T98aMGaNWrFih6uvrO7B2/x3wZeP/gptuukmFhoYqq9Wqxo0bp/bv39/RVSIXAevXr1ehoaGqsLBQdevWTQUHB6vQ0FB11113qebm5o6uHrkIcTqd6qefflLDhw9XqampHV0d8gdn7NixSimlbrnlFnX48GF14cIF9eOPP6oPP/xQ3X///SooKKhjK0j+0DgcDhUQEAB6YGCgamlpUcePH++AWv13wW1UbcBisagrrrhCTZ8+XUVFRamTJ0+qN998U40aNUrt3LlT9e/fv6OrSP7AZGdnq9bWVjV79mx1yy23qFdffVVt3rxZvffee8put6vvv/++o6tILjLWrFmjKisruYWKtAtTp05VL774onrllVfUsmXL/qn/5S9/US+99FIH1oxcDHTr1k3t3r1buVwuZTKZlFJKtbS0qD179iilFA/IaAN82WgDw4cPV8OHD/9nedasWWru3LmqT58+6sknn1SrV6/uwNqRPzr19fWqsbFR3Xnnnf88fWrOnDmqpaVFffzxx+qFF15QXbp06eBakouJRYsWKbPZrK666qqOrgq5SEhNTVWjR49WV1xxhYqMjFQrV65Ur7zyioqLi1P33ntvR1eP/IG5++671V133aVuueUW9fjjjyu3261eeuklVVxcrJRSqqmpqYNr+J8Pt1H9m2RkZKjZs2erTZs2KZfL1dHVIX9g/ufn22uvvVbo/7NXfteuXe1eJ3LxUl9fr5YuXaqmTJki9jAT4it++OEHdfvtt6vPPvtM3XbbbWrOnDnq888/V/PmzVNPPPGEqqys7Ogqkj8wd955p3rqqafUokWLVM+ePVXv3r1VTk6Oevzxx5VSSgUHB3dwDf/z4cvG/4Lk5GTV0tKiGhoaOroq5A9MQkKCUgrNkTExMUoppaqrq9u9TuTi5bfffuMpVKRd+eCDD1T//v1VUlKS0GfNmqUaGxvVoUOHOqhm5GLh5ZdfVqWlpWrbtm3q6NGjat++ff88qKVr164dXLv/fPiy8b/g3Llzymq18q2W+JSBAwcqpXBfaFFRkVJKqejo6HavE7l4WbhwoQoODlazZs3q6KqQi4TS0lLtDgKn06mUUjwhkrQL4eHhauTIkap3795Kqf9zeEtSUpLKzMzs4Jr958OXjTZQXl4O2pEjR9SyZcvU5MmTmfeA+JT/2Rf/+eefC/2zzz5Tfn5+/zyphRBfU15ertavX68uv/xyFRgY2NHVIRcJXbt2VYcOHVJZWVlC//7775XRaFR9+vTpoJqRi5Uff/xR7du3Tz344IN8BmwDNIi3gauvvloFBASo4cOHq5iYGHXy5En1ySefqMDAQPXaa691dPXIH5z+/furm2++WX3xxReqtbVVjRkzRm3evFn9/PPP6sknn/znNitCfM2PP/6oWltbuYWKtCuPPfaYWrVqlRo1apS69957VWRkpFqxYoVatWqVuvXWWzkHEp+ydetW9cILL6jJkyeryMhItXv3bvXll1+qqVOnqgceeKCjq/dfgcHj8Xg6uhL/6bz77rtq4cKF6uzZs6q2tlZFR0erCRMmqGeffVZlZGR0dPXIRYDT6VSvvPKK+vLLL1VRUZHq1KmTuueee9SDDz7Y0VUjFxHDhg1T586dU0VFRf88ApKQ9mDv3r3queeeU4cOHVKVlZUqLS1NzZs3Tz3++OPKz4//bkp8R05Ojrr77rvVwYMHVV1d3T/73sMPP8yEkm2ELxuEEEIIIYQQn8CNZoQQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Ql82SCEEEIIIYT4hDYfTj16/WOguT6KBa1wnCx3f6sYYs7elgha57fPgJZ3t0wBn/reCYjJero7aN3eygMt+4E00DK+qRTl03eGQ0yXRU34mTf5gxa9E5uyYoJDlBOWmSGm/Eq8fuDWYNAc42pFOWBdCMTUjG4GzVOGdXWHtoJmqpb1N7gMeC3Nq+m5Rx5G0QfcfeAG0HZ9OgC0K+7dKMq/vDceYsbdtRu0dV8OA63HNadE+dBa7GvjLj2I19rUH7TQ7pWg1dTJDMyZCaUQk1UcA5rFH+9fRFAjaM2t8p7WNlghxoC3WTXXYZ8Z2CVPlA+cSIeYxNQK0IpyokGbOuQIaFvOdxbluLA6iMkvjQTt3LVPgeYrur74DmjOEDdo7gCpGQLxfnlaNDkqNGPO2CgHnTvciX/XpLmW5r6aqzHOGSnrZmjGGJMDL2Zw4fV184PHT56sHliIQU6cypRfA2rNMfJawflYr1ZNUnNLLZ7u3hin+dsAGdcaiffNasM59swVf8UP9QGdPnkDtPhN2J5BtxeKsuGZCIjxe7kctNancKxaXi0T5ebn4yHG9HQZaC1/iwPtwjxsz5Ad8oZ5r3NKKRW4GjtI3STsILp10zmhRpT9V4fitcbh3Bm0PQi0pjFyTgpaj59nH4X9I/BYAGiNvXHdt56ScY0p2F7+ZTg+s55unzW425IXQEt7rgW04lfk2Ep4CNvkwtvYJskP4j0tWiD7R/yj+HnOj3BONN+FuS/K38a2i7lX1s3zJba5ugPrWvwGPsvFP+IAzfK57Fstd4XhtV7FMaz7noFfyLFRfz8+fxc9i+tRwkv4vQd9hmvwrz+NEuXw0SVY19P4PJJ7/yOg6eAvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT2mwQL9uWAFrzZWj8MZZLY07B7CT8UI35r/iaTND8vTy19ilo0HVFoKGnYiKawYMK0BBYNlwaTk34dVTZADSB+VWj4bAaq6b8CqXRtrwfxrha0bxj74/moHCLNEFV90YjUFosmpDPNaGhJyGxCrTiRmkO7JSJxv7zJWg0bC92fYZmcI/GF/vFGmkIj0TPllp8BK8V2YT39HydPDAgoAxjQvyw01iqsa8NjTsP2roT0kgenV4PMadKOoE2bPgx0DZt7QPagGFZonzgTBeISemN97nkOB7gUBgvjW0BF3DqaEpELSgXb1JeD00/2i+vHz4dzfJlh3EuUdei5CsyxuSCVt2M5sHhMTLucDXWe2LMadA+Pz4ctGuH7Rfl708NhJjZffGQgl82DwVtxPjjoG3d1VOUx2v61s7f+oKWMPECaKUrk0ELnSzvY9CPaLzNfxQkFbgc513zaDlvBeyzQYz1DuzPjZ/j2qUuxbky4k1Zt5rHcTyG/Q3rpa5AyRekrEAt8LwdtMpvZH+LOoV9rfhnXLDijuO9L/qxl4w5dBJisg5pDmk5WQCa+XQKaBGn5QSd2w37R0wxrvFVpTjuAsvw1IKiCmkwDi/HdbOmAE8VCM3Hz6wtknULO4frdH0yHsIRcQqv1RyFcSHnZd0cEfhvwaZmzckP7UTYb3hvGlPwe1h/lHN+awwa8F17NGb+BDR1t+yWn+mKxDF59gzWITMADxhp3owHALki5QECWUfxMIJMN65Frq24hrlteLjBsYPSxJ3ZWAQxng24PrhtWP9D++WzXDcHPsfVFdtAa9Qsm5tK8FkgYYc8tMA0ER+eur2PbaHuR0kHf9kghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn9Bmg3j4CMwmWHEAMximDZNG2AsVaHBNmIDmwpLVaC5sTJSGKdNxNEelp2D20hoLGlxrh2LGzoiN0lhkSEHnursYjUy6zLKWEmxKZ7isv7UUzbKtpZit2b8O3wGrW70MusV4rQu1+L2D7dhmRS1RoFns8jPzz2AGWF1W4vbi5gfQHfndizNA+3jOp6L8lyO3QcyPYz8C7c496HJ6vstSUX4o4A6IuTF8F2hLAzAb+azwQ6CtsklT9+NxayBmSyQauR6MXQ/awUy8908krhLlueGpEHNXp82g/eXQdaC92vVX+Xe774SYUQnnQNugsK/dn7wBtIf8bxHlToFofjuBntB2JX8FHjwRvxPnjD3Rg0W5NQDH86paHF8JeP6A2lk/RMYE4zxzuL4faJ3deHBB8SKcizv7y7j8nzIgJqWxGjT3JjRbJhfjvO7eIOdPz8kzEJP+DBqHDZrPbKiS2asDczGm7gPMcB2+LQe0pipsC/PJfFn+Kh1jCnG9aS8cd+OYCJpXA9oVCw+I8pZfsU3uuHcpaMuW9ATtlvvkvPv7st4Q8+SM30Bb8vko0PpOQaN66R7ZxuOGnICYrE1Yr5RMNKq27MQxFZUg26fVisZeSxqacd070Qyd2kuae13r8Pkndgg+Jxl24RyY1B+Nwg0n5EEGnjgcw57qjpsEk+48C1rdY3j4wvx3VovyolumQ8xj8xaD9t3uS0EbeblcN/M24Px07bDdoB34ph9oPS/H/lezWpquJ1yChyQUfIHzk20yHkRh+hUn8MFD5H2u9cf+Fzwd+4zpVzx8YNhQOb9WfYqH/8Sl4sEXwWdw/Sl2oBk/tFo+I+eURUJMhsKx0lb4ywYhhBBCCCHEJ/BlgxBCCCGEEOIT+LJBCCGEEEII8Qlt9myUH8b9iZY63MRfvFzuhTVqPqFoA/ozjBo/gKlRio3xGFRdgvvKLIkYZz2Jex1bQmXZ7wT6M6wVuA/Psgu/lAHzCSlniPRVWKswoVBTFL7vGVvwM40t8jMtmq1zfpqEP7pEheYa9HsEe+Vgqg6DEBWSo8mi10588ulM0AKM2J53/Xy7KNs0/e/qVfeAhjvQlXoxR36mQbOnXofBhfehixn3Uprq5b3vbsHkUqoa91Z2NaNWnYffoFM/mQhSNeH9G+hfCJpRkwhxS71MumlA25LaV457W41OjHsuC++lxS7LO8vQHxFY2sYb4CNabPj5jkj0XNWmyE5nwG6qqrviuA8ox+s3xZpF2R+37avmKOzkwWifUI0x2C8DS+RnNkdjTEAp9ktHOMaFaJKjtQTLuLDwXhBT1R3bMCwXO1idV9LIViv2+bpkzRw1Cr0XZf2x/SNtnUW5oj9+x6AizcTYTvh9jmuduzoPtF/emCjK4Y37IObLV2eBZivfC9pn78uxGleLe9pfXjcbtO7NuA99zxHcb5/ulAvn5rPoUevUgItrYXUoaPE1GGdvlnNljB1jmjQ+CHMd9r/cM9L7ktaEMcX70DeSUoeLcP4B9DrEV3rVrQLHRaAmsWx7cer3rqAlufFB5I2v54pyvBm//9ufzgUtWrPwbF7XT5QTQ9HL8MNWTIaabsW4Qxu7gZYSKeu2cSd6ktJDsV6Fp3AeSEvBzzyz06vPRKN3uOygJkFlEiZCPLRcrq9JoZjgsOVX9Bq5g/AeOfbh+HEHyus5qzBZojJhvdoKf9kghBBCCCGE+AS+bBBCCCGEEEJ8Al82CCGEEEIIIT6BLxuEEEIIIYQQn9Bmg/idl2LCsU9PjQDt96EfivK4rfdBTM74L0HL2HQTaBtHvSfKk3ffBTHrvT5PKaXGNz8I2rS+x0FbdVSaFQd3y4WY7B/QVKQ0Hq3G0RqzTr00p4WcQGOvGo2JqZwufAeMCZHJw/IL0SxoMGHFDEbUAoPQ8FQVLs3x3bqicfhsJCaRaS82P/wmaJOeewS0wzcsEOUxf30AY2YtAG3c0YdBW9x9oShPXPEYxIQY0XDoNmOb+2sOQHAFS+dwjRvNYwndMIlYqQvjUrphkqvjLSGi3LvneYhJ8kMTYmsQ1v9amzSZ/mAeCzF3pG4F7U3TVaC91u0X0B5YJ5ME9onEpFd7/PGQivYkeT2OG3MVGuaCzso+UZeJiZwSVmJSKPtgTL4WfUBev7IvHmKRsgb7Q3VXNB3GHkC3fmO0XAIij6PptSkSTdeWWuwjfk3ohA/JkfNWcwyayM2YF1G5rDhg4LABzZjSHUjQEoTzqbke/7jFq2lDMEelag1q85L5/5zQezWu/6N4KMPcx9eK8uaNmRBz7Z9XgbZuYw/QLrtjsyjv/R1N3pePQAP6iS+7g5baBeeo5khpqA4LtUNMfTyOny6xuD6d74GHSqRGyrjCbqkQ0zUd58WqFDzEJilDmt4dEbgeBvbG9bzpEJqJEwfi/OY4JMe/MQaN1Q7NIQztRcx4bHPHEWyDkFFyzXLvw+8fNBH7gusk3ufWADnPGFtx3vGYcd7xmHB8ex+C838+VF7Pdloz7zhwTow4guZpUyNOPiF5Ms6vHk3kQYV4T01NmonMu16aGN28qQyoNcfic4up1qu/GfE7ukP//aSS/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfEKb3W6LFkwBzapxvc7c+bgoB5ohRKVX3wGa2Y7vPePKHxVlvwb8vGkKTeOWEvzQVS19QAs6L7/+PmdniAnVJKQNKURzTdQHGFiVKesRcRqNnPbxeK3mnZgZt3msNKca6vDWRaajOa2iPAS0UUnofNymZJbd19LQxPua/zTQ2ovpj6OB209jfh/x6oOiHNCI5rHhH6CxPFCTtX3wyodEOcKBMU8XTgfNv1qTyR0UpQK9+t8/qvpBTOUuzEhblYn3vmQXZqTdEy/789m1mEl5QtPVoAUV4Fic8rtsC1sFhKiXF18JWnADttlN628BLbJexh2vQrO0v71jM4jrMl3H7EXTuL2nTf5dD+wPZQMSQTO2avqNUxryWkIwJm8GmvaCijRGQQ1+Xn26qgf2rYhTaJA0NWkMhs2aDM7d5fxjO40HaVg1WZGdYWhObPQyqpvrcWxHlaIBsyUM14PmCPyeHq9B2hrUtjZsLwx/wvq0FuBcvmlOP1F2FeRAzOp5I/EDyrJA2vrwMFH2t5+FmF/2DwSte7MdtHoHjp/gOnkPkyPLIaa4Eg3GY6Kwrkvz0Szf2yaN2DWFaPzuE47G5z1VOJ/am2SfjKrF/l61D03OkVVo9D6/D6+fVCn7rrsUx0BwEfb59iLwNhynrXl4OEDQsSQpaDKDB9yM5mZ3JI7TzPdl2znjbRATcQRXV1MzzgPR+2tBcwXLQ3s8mn9+N7jxeweV4JzoDsA5xeXV5T1mrGv8JlxMnRFoGo8+7NVmLqxX4i/5oHmCcH2I2Y2Zxg1ebRZ6Br+PqcwOWlvhLxuEEEIIIYQQn8CXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE9psEK/qh8akyP34ruKeUynKnpWY6TqzF2ZCzd2cClr3fnmifHYrxgT4o9GoDn1oKigO09SGr5MpY11WbI7GRDTh1GaiZrajmcsZJw039SkYE26sA806Gg1DA6Jl+svtLWimGhqL5qCVJb1BO1mNpmOPR5oPX7hwKcScKe+4DOL3PvczaB8+NRe0fzz6d1F+4DHMYP/OzZ+C9tdn0bS8YqrMNH7jQTSpz4k6CNphTy/QzrWi4aslVPajem83mVLKEY0mxN1NaPR2dsbDB5zejlcNN3XaCdr7LXNAu37YLlFefRANpsMnHgft5AfYFtcO2QPa2n0jRLlzGI6BEwEdm0FcR8EkNK8avG6ZR5NR3qBJEKu711Xd5JzUmIgxBhcah+vS8DPdfjhneHcR77orpVRtMs6LLWGo+aEPVrWEyrLJgcZEs+YQB6MT6x/sZcr06DKIa7L9+lfi9YMDce2Cz0SvsvJrwOu3F6aFeHM8l+FhIvNXrBflLwfi4SgP/fAjaH8fMQ60v332oSj/dTTODV9O/By0l7+bB9pr3b8B7d4h8rCYJ2J3QMzdk7qCNjvkKGjf3jAEtFlhcn5eMmQYxMyPwDlw6ZBLQHuh+2pRfivpGoi56Zo1oC0/NgG0IWNPgZZ7qJso+yfjYQpNuaGgtRetn2vM6X/BvlXznKx34At4SE3J42jgjvg4GLQL10lzc9KPmsMeJqPxu9p74lFK+V2Fz1qtP3nFTauCmFIDPsPGXIFZ50tW4AEFKbNyRbnAiVnuE7yemZVSqv5TTTb162TdPB/bIOb8DPze3d/CtbR8Kpr2IzfKCby2Oy5Snlrsk22Fv2wQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZs9GcA7u/w4/jT4Iz5tyT67bhHvzipekgmbC7XrqRK5MfGPV7U2ux4QlJtyOplwufK+qTZHfydm1EWLMZ3CvfUwf3ANXvQ19EKZg+d0tFbgnv6oG9zD7H0CtYKbcl+g4ZoOY9S24tzVlKX7v4htwX59ln7wBZ3Brq3Ifw/3p6nKUfMEb72PyuUA/3EM6/8MHRTlEE/PYe7eBFtyC+6FnL5GJ7KIacR/5a9lTQbPUYtzP1bif2DvxWrED2zcoD8fd0XpMTBVwHMdBVmfpsTFrtlt+cHY0aIZWrP/3xwaJcqTGc7B7NfqDbE5s/xXfod8jqEHG7V3XE2LCNe3antSNQl+MqxLHdOceMpHY2fPodRrWFZOx7TrSBTTLCLmf13EK9/L2vASvdeRUJ9C6X4mJ0A6vzxTl5JHop8vfkwRaUE9MIOrYi3VrTpWTcU0ztpdxGO65NmxGL4L/JGmiqMjBz+vc0w7a2SxMEDlnyF7Qft05WJSHDzwDMScW9QCtvah6D+9pUM1+0N557lpRDmtGX9lzf0GPWqj9EGjX/vCAKGfUn4aYdwvRk2CuwrV0Ux22XfxO2T9OX433qtMqnJt/n4jzg+1L9AZselF+ZswBnENWTEXfQdQRjNs3Re63DyzDen2wbyxonWvQ57NrdyZonarlpNpcjM8BtrKOS+qXuxfXnch0bKfKQ7Le4Rl4LedB/G7Nkfjd3PVyjXSE4fNMpwici8r88BlnaAx6WrcESR/gtGT00iwPxPVqVDQmt/zBgp6Nfjbptc0NRs9Gz7Bi0DaE4lgf7uXJ3ReOXhI/nEpVXa9o0Pyz8Lmibqisv6UUY1r6Yf3bCn/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZoN45LRC0ErdiaBN/NNuUf79HBq53un/HWgPHboKtNu6SRPft8Fosr0kEQ2NR4PQZNaQh+bbljRpSDJnoxncojHcFJ2LAs3QDTNaWQ3SPBUxHdswyIwG+vrJaKIsb/Qy3luwXt1jMQtV/i1otBwdjwlpNnqZy1PDMAHOuTg0dbUXc2/bCNpPX40HbdW9fxPly55/DGKGXHcEtCMfoklwzIhjMuY0GqAHRuE93ZqAhuB4Sw1oNT2kcTDKgg7u5Bl5oCX420Fr6Ir9KN4qO+8uTYLKafG5oG20Yf+e2E0aQ/fs6w8xrZoDFlx5aFxv6IdGa2uFTHhp7IH9z52NBtD2JGwTfheXGQ+tKM+SRkqzpt33laJBVIWi4bQ2S45fdwCaKI9koTHREo7z0aGN3UBrSZEG3dzDOKdH9y8DreII9vE5czE52s/HBsh6jcAEVvYLNtAMg7CPNNXJ9h835ATElDvwpJGuXYtASw/AuXLkIGkOTQlA4+mOXh2X1M//TjSSmk52Bm3GnzeL8q6tGDP3mbWgbdjRHbSXrlgkyl99ORFiro9bB9qCLpjwblAQzjU/TJXJPPtZcW16dwb+m+jwwGzQPukzHbSRQfJQhG97Y+LCYUF4rc8G4PecFCb728ZUTPw3f8B20NasxkM4Rgw7Cdq5nbL9w1JwzWg6g4citBfJg3GtK3TifDF7inwGXFuGp81cMWcbaIuXjgItJF62QUM8Ps8YmnFeru6Oc25Bow20mm5yzs1rRNN178vRNJ7fhHEt/XH9Pt8k6xs0UvOM1oj3tB6ndHW2Tq7LdjwPSKUPxOfhsjy82LyrcMwubJwkygPH4/c+VYpzRFvhLxuEEEIIIYQQn8CXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE9psEDe8gVkIEy+g2eXk59JEnNQPP+LxwZi91GgFSX1zUmYm9RjR9LPbmQqaoQANQ7EH8W89Xt7O1gCMcYSjAdSvHjMrWnPxe7YGyi+VH4UG68BENBU1FqPJ0a9WvheaG7Bex49g1klrGdZ1YxSa5c218no3D9kBMe+1oLmuvVj2Nn62xQ/v1+XPSUO4ET236sgHaAY3aBKz7v9expnd+Hlb8jA9agB6YFVVK977oDzZZy70RvNb7qZU0LrPLsHPzMETA/Ykyb8NLMY+s2LHQNBsNfg91+/sK2OaMSZoFx6w4DFgnP9pHJ9KyThHAY6BMFfHZhCvRZ+tCulZAZrRq5mtrZpsrcVodjfbMa41URq4LXl4eIQ7Bs3U7nzsbynDNAbPndLg6e7aADGVh9EMbkjDuGW/DQfNv5c0+tedRDNkZC8cMDXH0IBp7ioPPNi0Dw8fMTVo/v1MI72TiOuZq0m2f1Qcng5irsJ71F5Yb8cv4jqP2eN3DLGJsseDfXT9ZX1B81TjQQAfPCQPbgmqQwPqO+fQTB1cgIdFdDHj80LsHjmmy2bhuIjaj9/bcilO2CH5OD/Y3XJOCsHmUokmXIOjNc8LK8b3E+WwXCfE/PTjWNDiS/GwhgPLe4EWVy3HeulpXA9iSzQLWjtR9UsSaGac8tXvP0tDuAXPLlE/r8Cs3IHYPZTjgGyDQDvel9IcPNAk8hiudccauoAWLc8PULtD0iEmfCeurdU9sR6RR/AzD8+S86v/MhvEnIjDuSgyF/t3QY18vos4jzG1J/AeBXgw7vPlOGZtFfI77T6MDvSoun9/DeYvG4QQQgghhBCfwJcNQgghhBBCiE/gywYhhBBCCCHEJ/BlgxBCCCGEEOIT2mwQz5uNxri4bWjis78oDYyBq9H5bZ2ATqD63WiSsfSVGVybT9swxoIZXZs0mXiLx4KkQk/Lr1+fikYadyBePy65CrSS85rMniYvM40bDURmE9bVY0XNr0S2v6E/ZhdVhWiqbY7G7xRYpHnH9KraX/fNghCTX8eZ0654ZD1oP/4DTU4PPvizKL/3tyshps/tx0A78hlmB7/nzt9E+R8fXwYx13Y7gPU6Nha0QCO65Bq6SUNgsiZj8b4IvH+9gwpA+01zn4dG54ny8uAEiJk3ditoP5WMBW3EUJk992gOGhxNk9GI6lmKc0TUaMyE3PRjnCgHpGAG8ZZToaC1JwnbcC64YPnXGX11Wb/jtuEYrEvRzA+1XpnVNQmsTTtx3LdqPPglG9E86AqVc5SnEB2frkj80PQoO2h5XTTm6WY5xxo0IRWFeGCFUXNYhztXmoet1diGmvMIVECp5uCPCmwgo5fftykbjafmDvznuYK3sc6JjyaDNnnpIVFeN7kHxNyxag1oH02fCtqvHy0Q5Wsvuw1iFnT7ErTbBj0Amo6666UJv58/ZnsvvwTXnTQzjqnq6XhoQQ9LqSjXTsIYfxx2yn4lmsYvDT8syjuTB0DMu7d8DNqLh24GbdIVe0E7fKS/KMf2LYWYxrxY0NqLmh54HxI2Y1zFVfJwgOAfcE6pG+EAzZyN/bt1gnzOMSzDuaJLdzz4ovIIjou0EZidvv6wnBMT4nANdtfiARlJmXhvXDvw3gQHybao99ggptOkPNAqv8DDfqImyLHR+gl+XuvNeNhG8Ot46IJ9Lh5uYFsp5+qqyTgwIo5r3P5thL9sEEIIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE9os0HcWozOPr9mNA6G/irNikZd1t9v0DQaGIpxVfnSDBRSioaV+iQzaOZqrKt/Jf5tQIU0mbnHYMbY+hI0XzY4MKOktRjr4cqUJjPLYbyWXaF5JzgLr1XfWbZ18B40SoWg50cFlqKRrh59oiosR5q/zMMwK3HzwX9thvUVX/08CTR/bCb1/Kq5ohyuMaRu3YJmcGxNpf5xZowoazzeqrYVD0Awo7dQlbfgfQ7Mlocp2Hugkc5aiv8e8HsF1l9n+rc7peHOD5P6qmO1aBo3o4dSna+T997oxPFap8n6HKY5U6B6QzxoAV7Z2Z0n0QwehF2yXTk/RfNvM5rpzRwnG9pVgPe1chbeDGcdZgdPTZVZnYt34f1yX4LzVqvGTO/XHeMs+2XPb8UpShmcuEwUhNlA02WGb0qQ81ZoIc7DtRHYiIGF2NaNfb06QA1+Xs8pZ0A7vrobaDPm7AJt2cpLRDl2SAnEVGzHvttemFfYULRngfTdO9NEOabuBMS88No80GJqc0AbsFoavXtUojH284rRoEWcQQPwYYcmA/Uqmyif64VrTNgp7H9HpuC9D94SBFrzJXIBCNmIMeeGYKe3LUZtQ7o02oeex+ef25eigT6tGReOVb8PBi3RKRfw4pNoTI7RZNBuL/zLcDE1aZ4B1WnZdm4/rLMxH++fAR9V4AAdj2YKviQqF7QVBjSIdwrGg30OhKeIcqDmhInmEJyz6hqx/v5hGNcpUM65p4ISIaa3DQ9FWBuSClrnIGmWz7LhXFSVg2uwOxUbrSUf15qazrL+7mrNIQw98XmnrfCXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE9rs2egz7TRoh/xxL+zYKYdFeWdhGsT8vc+PoN2550+gTcqQ+293puC1Ii1oVAiMwcQs57MwAcqQuXIv65acLhDjnexOKaUcDjQLtCTjvkzrKbl30YTbWFXsVtwH6QzCfYPRe7yS+mm8MGE5uA/c7Y/XD8vCujrD5B6+xtXhEOOHtoN24/LLt4P2y/IRoH1/2XuifEshJpe6a8Zq0L76EhNavdP7J1G+b/8dEJNsxX2gzZegaSPSgpq7v0xcF+qHpgS/odiXM4IwKea+9M6gmb02wZrHYtK9tCBMAnSwKxothtrkXu1tURqvRzdMNOk6j96B+u44EPwrpQ+qNViT1M2kGYztSNQB/LeZyr5YT0+u3Bfu1iSos63DveOVg7HdC/fLdnZq5hlViZ6QgExMithYjfuMzWGybi4r1lXnG2oqw2u5QzT7yb1uWeMQnKPMeXgtp847Uiz3Czcl4n7xE6VxoDUlYdyybPQ9mbrLNiuvxUo44jousWnLpXbQWk+iD2LIHTKpX+7uVIiZef8W0PbsxjZZPPEfovzUp7dAzPyoJaDd1bU/aKlmnLeqhsj1O9CIc0PrWJxX3JrN+y2T0JNU7pLjLPbafIhxenCNLB0KkhobekqUt0ZdAjGvXroItH9suhq0ebM3grbq0FhRTu6FnqGaHJx324vAwbh+VLZg4stIL69TcyE+eyUO0iRvtKOfITZQroklMbgGnKrDMe+YqvGxufE+Vw6X/W9IBCac3TIV59ch8RcwboRmTvSaAG+9eznE7KnB51rXZFz3g/zk3F/VFz0V143aCdqvxaNAu3fqKtA+sU8X5XmjtkHM91VjQGsr/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfEKbDeK1t6ERKN2Cxq0LX0uzTmwSJgF5q3wuaIkpaLrecok0mVnRn6SCZhWCVnAATVSavDJq18o+ouxKQbN5qCahUEMSmjtjjuL1ja3SwNOiSQ7jb0eTT1MUfmZdJ/kFdAlw6jX10iXBcYZgQhdrhaybYSQalJpP2/Bi7cSaj9AMHqAxDN/xljSEmzVG+q8/RzO4uRHj7vA6tCDEjvXabU/Hax1CY2lzV+zfxoPScb/ejAcuqE1o1N85Az8z7CT2maNpchy41+AY3jYdO1LYaTTSbY3NEGWrHUKU4xCmRtQl9bQUYVJMj1f13RZNB1eaDI3tSJPGnOgOR8O2oUrea4+/ZozH4v0ytOL1g7yS4LXUasZuJbZxQxKe5hCNOdtUi1ciqoAKvJbLglr8bpwrz0/GuvlHSoNn6wWcoyx1+L0bk9HUbQyVn2ksw89r1SSDDGzE6zc50PRpsMvJsiUKzeC6xGbtRcKLOJkbszGhWf7caFE21GIivt039gXNUIGHRdz/xP2ibCtDY+8thzFBYOJ+NOgebu4EWqdf5L3ZPxTntsgvsc8kvI8HIIR/i/NuYQ85fza8hYb6h269Cuu1Evv3/Yb5opx2Ac3sf3v9OtAiqvDgj0WLJoAWXyYPT8g9hsbnhAJNEr12wvM7JoyztmqS4P0qDeG6g3EqV6EZPFAzjxVtl/cruARjTpZhO/mvwXlg4yW4vtr2y7VoV2QqxJg347rmdwPO6bbduK5VJsu+++U7l0JMLXZ5ZcPzmNTuGNmXIzXttfQ8msGtNRj3/pGxoAV5DdnNZXhgkl/Dv39IC3/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZoN41s0RoKUtR+fPuXnSmNN5cTPE5F2ORqPY/WjI8jZB68zO+YVoetVZ+FqD0dBjcnhl5TZjTG0mGrL69sAspEdC0PxmbJIVDslFc011N7wF/tVo6Gn08kC5NabNIPTKK3sv/E5+NZrsqzZ5vbRQNPgVZ+L124vu806Bdvz7HqDNv/N3Uf7m/WkQM/lPu0Bb//kw0F4f9IsoP3PqBogZEpYH2r6YrqCl+WP2XGdfmVX88tTjEPNDChrj58RmgfZVz2jQpsdIR/AvMWikuyzxJH5mZAxoszKOifLve4dDzKAZWP/jX/cELX4wZmmtvRAvyoZgHHcua8caxAPKcMwFF6Dx3xtnINa7qj+aj4PyMa6mu4yzHcex65xuB81vNx4s0PsuPMVi91J5SIZpUhXEqBU4Xzc9gZ/pqkAjZadIGZdTjGbf5mico3RmeWuANOP7XcCMvc2RmgMJ0Eus/BqxHd1e/k7/KrwfjYmak0baiXOPYX06v4pG235fnRDlI1egA/XGn1aD9vUVU0Bb9/a7ojznspshZsmAj0G7PeZB0EYFZoO2YIQ0zI4MOgMx710+HrQ6N467zD/j/NPZUibKJUOxDX/u9yVoN6c+BNqXsz4U5b+uvQ1ivn7mbdAevOEu0O66ETNJ/7Zjoign9cYM4vWn40FrL1KuOQda5YJU0Po+eViUj76MhxEMuecIaAffwqzzXcbJAxDKP8LPSwnHw2zK3GgQ79/5PGiFm+TBJ7bgeogpc+Ozb2kzHsChNN5ps9FrntdMH7ps6sZ1+FxrvU7OzYb3cc0fehe265mH8Tmp842YAb10UWdRDjLj4SeOPN3BLW2Dv2wQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT2izQTztNzR6u/3RbJW2VJpKjC1ohEz9EY1Pzlg09ITmyuoFFaFhpSkeszZGHUIXTtkQdO8kr5MZO8v7Y1bZgAo0xBwPxQzlusyyjiRpeg8sxeauzsT3PVsOtlllgIwLKsC/q+2MdQ05i/VqxaTuyuTVtGfOoPEwOFfTXWah5AsOrEaTk0XjF353ozQ5hmmyjC8+NBC0cDf2mYUlQ0XZrxFCVFUrGl6tFXhvKlrRUGY6LTPemrvjfTdrzPxOD35xayEaJr3NaUYntkWRQ5MdVfM9KxyyrgasqtqZi0bUECN+ZuEhNDkG+8k4Uwlmhzbi8G9Xmi6rAa3hAt7X4BR5uIJ7F5q1Q3LwHurMzcqrnb0zfiullPOYDTSz5lI71vYGLdDrMIrqPKxrQKTmYIsy/ExjKd6zsmDZb6zl2J+bkvAwAL9abB+PR9ajLg07YUJXPIihcjcejNDcCQ83sebJ+vechQcxHDyXAlp7EbQVM2Qb7Wj0XPXpSFGObzgLMa/941rQEhvwhJHem+4Q5W61eHDIp5UjQbPU4oEvxxy4psTvkvfwwlw8jCB+Da475aNx3B35oA9oF56SB2CEn8GBsaBkImjWalxLn86+XJSNmjF22U8Pg5bmxgl1wTLMJJ3qknHns2MhJrHy3zfo/m/JXt0ZtPhqfC7cuEyur7FNOHFv+w7X4LBmnAeOnUkW5QTNuuP24PykWysC/bBPuryWzdhA7N+ac0FUUqAdtAuaZ42MEDkfFVtTIcbPqDmYKAmfa6urZZ+3ReIcuWo7muwjO2O9cs8ng2aLldcrLUOTepBm/Wkr/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfEKbDeLd3sEMzisPYGbIW4ZvFeUvNo2FmEtHnMZrbUPDkDG2SZTL7GiaMdmaQKtwY2ZZE4apmnQZ16DJDus24fuYp0xjXtWYb615sr4VffH6HhNqhWPxM01N8vqGEZg1M9NmB624GxrpwixolKprlt/J0oxt3dSABvr24oo520D7eTkaE3+49H1RvqnoAYh5fdTPoD137nrQHklaI8rz4tEgF+HXAFr4aDwAwahJHRo4sEKUdcbvvlNwrFiNeP8ihuNn+huk4S51fB7EJFuxH9Wno1HPZpbmxYYUNLWNSMMMs4cO9wIttEclaK0l0ozWGoZ18Pi1ebryCQ01OK+oUKxnc5McO840jFF+GqOnG+eQwEivdvfHMTi0Vw5ohzZ2Ay16cClo9SuleVqXuTuoEPtuczTODwbNV6qtlvX1C8Frmaux3/s1YD1as7zmshD8wMpdaAZ3xKCr1FSB9Xd2k2198GAGxPjFak5PaCeax2Eq9JYTaOLsd+MxUS7ZiWbQCfN2g3ZiR3fQloz8SJQfi70TYv4UsQu0TZmXgNbTgpmSC8bLta6LV8ZvpZSKuTsXtGQ/O2h1l2L253Sv65WOxr7wWvRO0O7vhGbzv3X+XZRfDJ4PMVdP3g7arjVDQBs0Cuf14s2yv4Ukolm5MdoGWnvR2BUPVajRHAoRfIk0RbuO4qET3a7ETPHnvuoK2oz+B0V5+3F8ThwchvPa8v7Y54P8NPXvIssmA85PDaOxX9W34vxRMwivX9UiD5CJvyIPYrqH4tr9W388TOHB3ltE+b1z0yHm2nE7QFtaPAq02d2Ogrb2kByzY1LxYImdoWhAbyv8ZYMQQgghhBDiE/iyQQghhBBCCPEJfNkghBBCCCGE+IQ2b4LOuSUNtC4hmDll57tyr2NqAu4vP7EM90PGYP4a1RQp9/uaHDrPA+6j9hhwv69fE/6tsVVq/tWady+NZNEkWvPHbejK5ZU8z9+O9TJotnO7/TGutrtsx5YjuA/yTIANr6XJ7tWUjHsQm2plZcf2wD2VW8oxsV57sWYB+jPCNMl27vvr/aIc4I9Bz32N/gxrJca9en6GKOsSKe6v6QSafTPuG6+5Gv0MzTvlfuvT03EQnF6J+1g7XV2Fn7kVP/PoDLso569LhRjLFNzDHHgep4UDnWUys0BNW2yzZoIWoknCVFWOCTxDvC6X0AkHVOMx/I7tSdBJ3J9cn6oZwCVyP29YEY7nkAJsmPoE9C6YmmVb2Wqxn2YdQn9G/Hmsl/NYDNajVdajJVRThxb0RvhX4v23YM5D5eoqzXLGI9iG5jqNV86i2Tvt9acGF7Zrc7zmfmjwT9fsh6+S602cJkFgSS4mnWsvOr2uWcNy8kAru0J6WwzNuCf8xB04l5uKKkC75dUHRTm2FD0VLxXMAC3yGK4xlW70GyVtlH2rfBYmSS37AJ89Mt7GOSriZ/zbc31kn4/fgP371qB5oKUewmR19yy/SZS75KFfb+tzw0ALKsW+dvIH9MfEl9hFuSHbBjEpOR2X2bTz19j//Grwu6mjcqA6Q3Guq3oG180AG84z+94dIMqBToxZuWEwaFHHsVrbS9FvYCuV32lPBtYrdD32qwPT0BMSsR19HKciZf/zrMT5Iy86FbSwcmzrt20y+WRYCc5/P2wYAVqQpsvsKMUEvN6Jet0ezcPvv5/Tj79sEEIIIYQQQnwDXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE9os0H8zB1hoHVajmad7Ottopy6DI0uedPQpBWzDz/TPEUa1lpXYQIjXSI+i8azVJ+CmrVKvmu1aBJOuc34d4GZdrx+lg20gFLppmnV5ARr6oXZBgOPYmBiijTMlpehmTi0O5pqa85EYFwgmt+ayqV5r0GTtEaTl67dGHEvdpCd76ExbPqjMvHNqjdGQ8yo2YdB2/MtmseeTFkpyreG3gsxg8LyQdudhKbuFM0JAsYhdlHuF1YAMcf6J7TpWt2mZoPWPVgaQ/d2RaPloHCs/5EMNL/1iSgU5fVWrNecwftBW5uDyb1GZGKyoAP50rCq86E1xXRgB1RKNfTApE3+53GcuLtK46gxHw2GpVfhuA//XWOOHSMPhkj9CetVehmaokMX4sRVjN5B1XmxdA82X4Ytn7wBr18yEb+35bBG85N/69Ec8tE8AyfssB8wGWnNcNn+/mdwnmyxgaRCzuG/qRlb8ZACY6j87uYVaOa03qDJDttO5D+B9ybt2WjQhnwv3bF7Z2NywpsXLQftq0sngrblr++I8pwTmNTv1eSvQbum52Og9dYszBXz5VjpZsZTBkpGYZ+pcuFYLJ+DCRd7+BeLsr0r9oXlI/4B2ry1j4D27DSZDPabZbMg5rpXVoL22/VjQZswH5MqHjsoD87RHWJQn4j9tr0Y/y4mjNt8FxriJ30sE/CuvxUnnpu+xv738f1XgDbrxfWivPqBsRAzcnQWaGd34wEIwy9D1/iJt3uLcnoUrq3FJpyLukXjQQlnQ/EZOT1U9ucLHpxThs44BtrZ17H+PbrJ5K1nN+CBLA/fvRi0j56bC1rvqELQDtTKuaSuFQ/z0OQwbjP8ZYMQQgghhBDiE/iyQQghhBBCCPEJfNkghBBCCCGE+AS+bBBCCCGEEEJ8QpsN4qlLMQukoRWNW8lrpfnbqMk+m7oS/84ZjKbxyuPSTBNVhdfymPB9KbAU4xw2TRbf89J8WZ+EzaHLPF7TGeN0mcCbI+XfBmkyCTc0oJEzdh8auAtCpCE8eRMa5Czf4/Vj3RrD03jMJBzdIOt6sB5NziEF/4v0kf9LNvwwBDSLJjv4wlVjRNmm6eFbV6IZPFBjXH2ncLIo+9vxWrEaQ6NZk2G+swUNZc1npKEspTtm8HVdwKy7vQdfAO3t/ZjFd/5Maej7/vwYiFEDUAo4h0bf8xnyoAETdj+1Jh+z4up6zJFSNJf7eXk7W1w4H1grOq7/KaWUOcAJmisD58UAq4yr7oeTg6EFO2Z9In6/sCPyXrjNeK3ERXi/DC7sz1GH8PpVPazy76rw78oGWkGzHQJJBZTjvFu93+tQD/QzK0e9xogYh2MoI0Fm9M7Lw4MMVALOnY4aHEPhI0pBa9wlM9R3fvIUxFSs6A2aQl+rTwhaHYxiJX6P5e/LcR5TcxpiXnnvetASqs6ANmK/zJqdlIfz2NK6PqBFHqsDrUQzpsO/l9+pYoBmPdyB/bZoBvZ53QELdUNkXMRJHK+P5eENDDuH/ejZXbNFuVsdToLvfTcbtBR3NWi/L8WDMzo1y7WkqRjvd1Ql1r+9+O7HCaAl+uGBCV8tmiLKMWGYwvrlz68FLTwA57YPtsrPTArFvnCiMg40PzPGnazGQ3VcFhmXEoT3qsSdClqXkHLQcpu7gDYkPE+U802dISanBg8+ag7H+S+rWk6eHs13fG439r8oK8adrdVMxF5h2VVYL3PDv39IC3/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZoP4lLe2gPbRfszO/OpwmWXzqV1zIGZA5zzQDpxIx8qFSvORIx8zxjbGaQwrHnyHcoxGw5pzt8wM6UH/mnKEo7mmczQaefP90LgVHijr7x6A1xoUjga/vXGY7jw+SBq98wLjIWb4CMzMvCMHDUmPDVgK2hsHpBn66l4HIOb7w5ixu7145raFoL34CZocT/zpPVG+5HnM+r3mlr+BNuP9x0F7PeU3UZ4VjDHRJszyauqGfa3QGQ5aSI8qUa7QZDW+bcoG0I40dQKtSz80jR9olBnDM0bnQUyzGw2Zjig0+kZb60U5G/9MDU/E6+/29AVtQgpmfF17QB4A0DuyGGL2+WlMbe2IxYIGRocDp9CGei/TtT+2p8GI81ZTJppSGxvk9etScW4LKEVNMwWqxmSsv6VSTnr+SfUQU+fEDLrGJMzWbK9D025IjDS9hn+O16quRwO6n8aIeGGTnBct6DtVrhNoBtdRtw5NpS2J8j7t2NwLYpxJmpNA2omWmXbQXMfQ9DruLpmd+sQONK5ef8ca0DavRPP7132/EuXHO90OMXNDMa39wgFTQAvSnKJSdoXs84FGjGm4Gg/hsBnx5ldMxvFjNsh1uUhzRsajidtAez3pBtBe8nq2+erzmRAz7nJcN89sw2zQg6dhNuvC7fI+maPRfN0cgSb49iJoGD731OdGgNb/0pOiXHgAM9hPvhozqG//+1DQxg+Q2bXPbOwJMWPi8blnXQyuFROi80BbGyvnAaPCead2PM51xc24VtsHYp/MbZIma8d4fF6YHJML2tJO+Hx3Y/JRUV4Ug4b9AZ3zQcvZj4f9xAbgM0p5iHw+jQ7A8VSNj+Bthr9sEEIIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfYPB4PG3K0jGl3zOgNSXh/luTQ+57rU3Bfbw6Kvvjvma/evku5ArEqnpsmGgrZj1uKG/QJIkKKpaf2apJfmK1Y72aIvFawUXo2ajoI/dba7bHK0ck/l0C2mOUvYt3skTNtcKxfdya5g/OxMQ1NQUywdxrk36AmJdOTgft+KwX8AN8wJA/vQWaW5PUpi24NU4l3R73qgHy3tiO4R8O+NNR0Pb8hkmuBszGPboHf5N7wjMvRS/DydW437LXNEy+dWJlN9Asl0hPiHMX7q91BmOf8a/GdnVEyDhdgr2mWLxWYCHG1XbR+JtOyBtgH4X7RcM34d7+g58+DJqvGHTz26CZG3B+UIZ/3S+tFThvOSKwf4Vkyz2+jmj0JBg0M3hFH0yU1xyludeVsq6NA3GfeOQabPfaVPyOFtxar5qj5WdGH9IlZsVruTX+OWewjNMlltRsuVYGzRLnCMUB79cs42pw6Km4Xdh3t//6mKYi/++ZPOR50IxZ50EzhMu53FOLPhyPZk+4ykHfV+MYmagzcNMJiDnzN/S2dH8Fr2VahPe+9XaZuC74c1yb6u7G/fddvsgBLftW9KbUvSbnkaDnMFFeyTDU4jdjZ67sJ/fpRx3AujYl4jNRYD5eq3gcJkyL2ybn67PXo88vcQt6WrauQC+hL5g88DnQTNW4998bd6jGR3UW+62rPw44v3J5fWc8eiVarThZ6OYU72dTpZRyhsi/re6Kc7DtLI55RwjOH5Z6vH5dirx+UJFuvUDJ6NQkvg6Sn2nSJCLWPWOaGzGuqpsmwWbWv/Y36Z5Nd/78KIoa+MsGIYQQQgghxCfwZYMQQgghhBDiE/iyQQghhBBCCPEJfNkghBBCCCGE+IQ2J/VrelOTcGoRGpgibpTGn5DX0IhWdieaEON+QmNVeT9ZDs3CdyP/S9F8VZMRA1qLDY05LquXAd1fY8qpQCNN4FRMxFd0FD/TFSwNN/7leK1LBqIpeFcIJjjMSCkS5ZwTCRAzZshJ0DYfR+NwVHADaHY/2f7LKvpDjMvVce+mtlvQcNii6VsT35QJmtY/Ogpierx8DLRjL2DyuVGDD4rygbUDISbAhEZfa0WbzlxQIedln7Sa0PxnrcRrhZlxLAYXYlynyHJRzq5Dg3gPjSn93Jdo1MuYLRMn5S/ERE1pg/EeVWYng9anbx5oBUdknw8Oxu+oFBqV2xO/Jo3BugbNg/5lMglUSwRmQrJUYqKoFhuaHw1N3idBoNmyuiueAhF9GNvv3OXoHkzaIPvcuUxcEix1OHcaW3EuiziNp1YUXiLHh/8mvH55PzSzRx3Da5kb5fxjwKZXFjv+nV89aoYWTYLGODkHRm+tghhl0jjX24n8J9BJmvZXTOo39mc5b22e1h1i7l+8BLR3p+IBIFs++USUp0+8CmL2zsKDE65beDdoX6Z/ANrkKdJc/1UiJm+9p9v9oD0UvQm0uUMGgfZWF3nQyUvW+RDz7QNY/8e33gLaI3+W1/rq+hkQM/yVPaAduKsfaN2uOw1a5VGZrNWdgGO4PrHj5sDgd/G5p+FeNO+PX7hXlDfPxAME4jbis0TRHXjig+tDqVluxDo0fY5tEvJn1MwLcDy7bpJx5ns1c92uSNDCH8Cks613h4EWfI88nKH5TXxui3nqHGh19+K4NrxjF2XHi/j8E/JsAWiOB7D+NTfiWhb6i5yrC6fZMOZIJWhthb9sEEIIIYQQQnwCXzYIIYQQQgghPoEvG4QQQgghhBCfwJcNQgghhBBCiE9os0Hc8y4aoJsy0bBW+W2KKDcOxBjPQTQ01nYCSQV7eV102REbW1B0m9D8EpGB5qDGUpnF068J6xpQiYYhhxObLfIYfmbpWOlgjN+JjsZT5WjeSyzBuNJUabRNP4jmsb3FvUGLKsV6nS9JAi3UKyP0zlY0lgcUasyRl6PkC5rfQmOVUZMueMNDI2WMC+9f9mA0ollGodH79B2ZohygMWafeBrb3ObA6x9agia56EppXD3yWw+ICS9BI+v2lWhmD9dkRz2zRN7DoAqMOf0r3uegJozLWyQN4QHV2Pb2r9AMbm3Ea9W8gnFBFq8+/xkeGOHx0ziC25GGePy3mYY4nMvqp8v5ISQH/64+FectgxPnn0KvTMPRe/FaAZr76gjH6yevxXvmnV07ci/Obf527M/hmMReGVyaeXeFNMe3BmBdgwtRc2syABtb5PUd4TgflQ1CA33YWTSLlo7BvhR8RrZZ46Vo0uy8GA83aS+C1mCma4MDMzj//OZkUY5qwkMgnnv2JtAimzCrc9qK20S5R1MZxGxswrlZl8ld9y+b/l7zSKzmwA2XBfuCVZN12YTnAKidDTKreEMCjtfZq9GAnhaJffLpFVeLcoYH237FdyNBS2y2g3Z0dSZoKc3yep5a7Mv+NW07fMQXHDzcGbSQcTgGP9g5XpSjxuGcUrgoETRLf/xu9ZvlIUS2kXhfKg9gZ3D2AUlVF+GcaBsl2zjVimPlbE+sa6YfzomnR+MBLBNs8npru+GDbnEhXj9oWBBonlr53Y0Z2Jcv7MLDhcI1baG2aZ7dh8j2D87CGPtAnBPbCn/ZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/QZoN4wMOFoNWfQWOLYaQ0OTmybRDjCkFzXtTef52Z1aMJqTmD1zdovlVFgSYu8V8bTpviNOIFvBba55WK3CUNSU2RGlNtbzQA13bGd0CTlzmyYCyaHltS0cDcpDGweqz4vZ02+ZnWWMwy3hjQcdlLB7+4H7TN718C2uh7ZAbXg3/BrN+9DmAHOfwMaiPfl9fa+tAwiJn65hbQfntlAmhX37gRtFUvjpHXumYXxGz8GL/jNVdsBu33N8eANnOezKa+5l00L4ZOKgHN/RX25oZxsj/4/4bmxfJJaJpL/hnbNe8y7N+dVsj+fX4qxqSsQnNge2KpxfHbkIgmusACWffaDKy3xx+1EX3QnNjqkdeq743ZtvuE4dz8/R7sN6FxaGitLZFGfFt8NcTkZYWDFt4dM8mWnEGDpH+q/MyyAo3xX9MWsdtwsm+M82qLVJzHwjAxs9bYH5CHmmVMhSi7dkdBTGUv7PfthX08mtNDCjCDc9LNZ0W56TCaOsc/uhO0fQU4V26b+o4oX7vqEYiZHVQB2hM34bpjNeA9Db9JmtLDjPh3urqGGHFesU9pBO2eiMOi/GXf8RCzeMr7oN27FU3jT07/TZS/W3spxMRPR5N9i6b9o0ZiBuqGE3Le1a3T9RqDe3vx54nLQfuu61DQ3s5YJsq3OW+FmK0z3wJt+sHbQPu53xeifOk6vC/rJ78D2n3nMNP97XEHQduQIg/oGWbDbN63ProVtDwnjjv/efgsd0lwjijXXovPULdE4/Wvdd4O2pI+X4vy5ZX3QMxV/fE5aWkLPrc8c/WPoD274kpRfmXmIoj589prQGsr/GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfILB4/G0KSXlsKvfBK2qu8ax7eWXNKBnRpnQR6o1f3t5I5WfJnmruQ6rb25ErTEG36tCCqUBS5epVJcJtVWTvjR6B2ZW9RR7aemYudsZEQCasRmNYeYimQG9NdYGMWWD0Xzp19Q2U6vHS+o8PhdiTmRh/fNvfRw0XzDwlrdB8+4fSinl1yy/r0eTidjcoMm4HIYXcwbLv9X1ZXsfFAPz0bzYmIqZcf1qZFyr5uAES9W/PjhBKaVMzfg9W4NkWwQWYoxB47k2OTRjqsGrXTVtH5qHBxQ0JKCh2VyvyRjtNfZ09XKbsf47Fj+KgT6iz4NoRKzthvfMECpTGfvlaQ5zSMD+YNFkuHUFyHY3NWEbDByPrugDGzFDsSsQ76vRIa/njMN6GWuwPxs0Z2sYWzSZfGPl9QyN2J89VrzZ/pq2iLlEmmpLDuHpHfE7sGLNukzjwzAuJFt+z+YYbK/0n2tBW7vvOdB8wZAb0VQbsbccNGdsqChbcnFtauyFWb8DzqLRu3BGvCgnbLFDzOkHcA2L2YhG5uoZeOiIIUdmSrb2xOvXXQgFTYVpxk+uZpylyTkpYgvOR45I7Lex+3Auq+gtrx+3E/tCdQ9cg8NP4sEMxSPwO8Uclg84uTOxriHncOI98v5DoPmC3sv+ClpDI9YxLVYeHpFzAQ8c6ZJcClpWPo7niGjZxlWag34mDzwG2tqDvUEL0RyQUVch+9/34z+GmBv33AxaQmQNaMXVeE/PjPpGlDM23QQxSdF4KEf+eTyc4vXRP4vyE+uvhpjY1CrQyrLxWteN2QHaoh3DRfm9KV9DzKOHrgTtzBXYL3Twlw1CCCGEEEKIT+DLBiGEEEIIIcQn8GWDEEIIIYQQ4hPanNSv9BLc12hswT2trUFy/21QAe6XdeK2RhV6TrOfuFVq/jWavd6afdyhey+AZou24fVL5f42dwwmr3IfOQWaqUdX0FQZ7ndVnbySHp7FhD8VN/cFzb9G47MYI/cWWuwYU9NVs/e5Ct8nzbh1UbV6bbvN3pEKMZYOzKl246O/g/bt36aDdsWT60R55WOYxCnpmWzQCl7qAtr8t5eK8tcPzoaYabftAW3tvhGgPTX/F9Be/ULuubx6Mib1+/0jTMQXfSX2b8db8aA13C33lQbusEHMhSk4fjqtwBudP1P2o+RV2P/OT8G920mb0KCVNwP3c2f8UC/KheNx/2to7r9OwulLdF6W2B3YfnUpsh0CyjTj2YFt4LJinHcCVP80TFxW3IhtFT0Y90TPSToM2sMRMonVs+U9IeanrAGgRYTg/vvK2iDQlF3uczc2a+ajClwjdHNUSZX8nvHbsT8E5eJe6sDzRaCFnU0HzbBzr6xrH/S9GKvrQWsvSofjuGwNwP3wVSPlmEtcil67wlnoNYtfidcKnCr7UZERE9QN7Yqeob2NOJ9+NOh70N6OmSzKf0tfAjFXtWCyt4WDPwftSs+doD0+aI0of7wH53A1zA5SZb0NtLrB0lMRWBYMMWWjsF1bQnF81mZiXGugnDfcAZqkfqltstj6hPp69MQYC1ArMNtE2ePGOTK/Ep+1dJ41u9nruacS54p1p7qDFnYSH21rzDg/WYrlZ/5p9y0QE7IN17X8wVjXgFyc07u658lr7dBcqz/W1XoBr//k3jny8wrx7ypt2Cc9QdjXfjrdH7RL+smksk8evxxi/Pz+/TWYv2wQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT2izQTz6AGp1yWj8MTVJA48Rc+9ok/o1RWsSzflJrTkC340izrSA1pKOJja3Bf/W4pEmJUNJJcT4dUrGa5nRpGQMQde767g0zvmlpkBM1HFMHmSuRBNo2FmZPMcZimYkjwlNRUanzsSPbW2tlHEhRzRGIE3Ow/biq3fRDB5Yh4bJ356fKMr+TjRHVTyA99QUitf6/sYpomwMxpg9jwwGLTgAP/PNBZiAJ8Qur7f6PTSDhxbjtaq/xfoHmDRm2Q/DRNlcj4Ox888gKZcZx0rm+3ZRdsSj6TF1OWbdbAnDftptQQFozV3kmI04hd/bEdqx/zaSdgMeLFDtCAQtzCjvRdZxNOh6gjSJO0tx/FrK5RRtzA6DmPMJOPfoDoZ4v+tY0N5zeh2g4MS/0yWpLAtHI6KlWpNAs480ksek4Bx7Y6fdoH2ROxy0b7ovFOWbg26EmEmpR0D7duk40FzpOO92uyDvU8G4CIhJ2Nxxk6ClGtedgAqck4KPSNNuYBGa2gPO4P0LyUNX/oVtclxGnsNxebwUD6fwL8W63rv/WtCcjXJ+eMCF82RLM46L6/ehkVfVYNwPBXJ+1iUPdpzCMRWqadfaSrkGW2o0SVhLNWbfSryWsQnHmZ/Xsm9s1Mx3HXhIizUAn7VaW9Eg7m0iDjmOa4B5HCZEVBewT9oDZZuHn8LnmdIYvKmh57GfuvyxHrazsq6VzTifR57Edc3lj0bvsFz8zFJ/eb2wPFyDG1Kwz9iy8UaHjpEJPGtW47qiRuBYb96NBz+8dv+3oD32sRxT5lE4V9eewTmxrfCXDUIIIYQQQohP4MsGIYQQQgghxCfwZYMQQgghhBDiE/iyQQghhBBCCPEJBo/H03EpKQkhhBBCCCF/WPjLBiGEEEIIIcQn8GWDEEIIIYQQ4hP4skEIIYQQQgjxCXzZIIQQQgghhPgEvmwQQgghhBBCfAJfNgghhBBCCCE+gS8bhBBCCCGEEJ/Alw1CCCGEEEKIT+DLBiGEEEIIIcQn/H+b0u2tEQW8ggAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(10,4))\n",
    "for i in range(10):\n",
    "    invNet = net_list[i]\n",
    "    icenter = invNet.center.data\n",
    "    j, k = i//5, i%5\n",
    "#     print(i, j, k)\n",
    "    axs[j,k].imshow(icenter.data.cpu().reshape(28, 28))\n",
    "    axs[j,k].set_title(f\"{i}\")\n",
    "    axs[j,k].set_axis_off()\n",
    "# fig.tight_layout()\n",
    "plt.savefig(\"./invex_out/MNIST_BasicInvex_cnn_centroids.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invertible+Cone = Invex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflib.flows import SequentialFlow, ActNorm, ActNorm2D\n",
    "from nflib import res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import DistanceRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvCNN_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        actf = irf.LeakyReLU\n",
    "\n",
    "        flows = [\n",
    "            ActNorm2D(1),\n",
    "            irf.ConvResidualFlow([1, 28, 28], [16], kernels=5, activation=actf),\n",
    "            irf.InvertiblePooling(2),\n",
    "            ActNorm2D(4),\n",
    "            irf.ConvResidualFlow([4, 14, 14], [16], kernels=5, activation=actf),\n",
    "            irf.InvertiblePooling(2),\n",
    "            ActNorm2D(16),\n",
    "            irf.ConvResidualFlow([16, 7, 7], [16], kernels=5, activation=actf),\n",
    "            irf.Flatten(img_size=(16, 7, 7)),\n",
    "            ActNorm(16*7*7),\n",
    "            DistanceRegressor(16*7*7, inv_temp=0.25)\n",
    "                ]\n",
    "        self.model = nn.Sequential(*flows)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1, 28, 28)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_mixup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.4122818112373352\n",
      "Train Acc:67.64%, Test Acc:93.32%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.178267702460289\n",
      "Train Acc:96.60%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.1838635951280594\n",
      "Train Acc:98.59%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.2052469402551651\n",
      "Train Acc:98.94%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.12574224174022675\n",
      "Train Acc:99.10%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.11998306959867477\n",
      "Train Acc:99.30%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.12569481134414673\n",
      "Train Acc:99.39%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.13647200167179108\n",
      "Train Acc:99.52%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.11129426211118698\n",
      "Train Acc:99.57%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.10627156496047974\n",
      "Train Acc:99.67%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.16590999066829681\n",
      "Train Acc:99.69%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.13936731219291687\n",
      "Train Acc:99.81%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.12985914945602417\n",
      "Train Acc:99.76%, Test Acc:99.59%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.11648132652044296\n",
      "Train Acc:99.91%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.17034505307674408\n",
      "Train Acc:99.86%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.10372260212898254\n",
      "Train Acc:99.85%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.11262498050928116\n",
      "Train Acc:99.91%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.10275694727897644\n",
      "Train Acc:99.90%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.1143302395939827\n",
      "Train Acc:99.92%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.08886084705591202\n",
      "Train Acc:99.95%, Test Acc:99.44%\n",
      "\n",
      "Class: 0 -> Train Acc 99.94934999155834 ; Test Acc 99.64285714285714 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.35416051745414734\n",
      "Train Acc:78.83%, Test Acc:97.71%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.20843765139579773\n",
      "Train Acc:98.30%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.17106013000011444\n",
      "Train Acc:98.94%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.1216389462351799\n",
      "Train Acc:99.21%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.15364916622638702\n",
      "Train Acc:99.33%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.13061755895614624\n",
      "Train Acc:99.37%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.13689622282981873\n",
      "Train Acc:99.53%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.11356649547815323\n",
      "Train Acc:99.58%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.10439745336771011\n",
      "Train Acc:99.67%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.08434692770242691\n",
      "Train Acc:99.70%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.07830937206745148\n",
      "Train Acc:99.73%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.11723615229129791\n",
      "Train Acc:99.81%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.1284632831811905\n",
      "Train Acc:99.83%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.166805699467659\n",
      "Train Acc:99.79%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.10277661681175232\n",
      "Train Acc:99.85%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.1018969789147377\n",
      "Train Acc:99.89%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.08909904956817627\n",
      "Train Acc:99.87%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.11844797432422638\n",
      "Train Acc:99.90%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.1345456838607788\n",
      "Train Acc:99.91%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.07998526841402054\n",
      "Train Acc:99.95%, Test Acc:99.52%\n",
      "\n",
      "Class: 1 -> Train Acc 99.94808662118065 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.31301626563072205\n",
      "Train Acc:64.48%, Test Acc:86.92%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.293169230222702\n",
      "Train Acc:93.89%, Test Acc:95.78%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.14520159363746643\n",
      "Train Acc:96.90%, Test Acc:97.63%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.13118591904640198\n",
      "Train Acc:97.77%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.11485420912504196\n",
      "Train Acc:98.15%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.17582325637340546\n",
      "Train Acc:98.71%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.11936347186565399\n",
      "Train Acc:98.86%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.15947744250297546\n",
      "Train Acc:99.04%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.13626761734485626\n",
      "Train Acc:99.15%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.16909128427505493\n",
      "Train Acc:99.23%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.11203957349061966\n",
      "Train Acc:99.34%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.18815279006958008\n",
      "Train Acc:99.30%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.15076011419296265\n",
      "Train Acc:99.55%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.1498718559741974\n",
      "Train Acc:99.49%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.06718491017818451\n",
      "Train Acc:99.55%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.16419418156147003\n",
      "Train Acc:99.70%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.18128395080566406\n",
      "Train Acc:99.72%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.03927335888147354\n",
      "Train Acc:99.77%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.1054176315665245\n",
      "Train Acc:99.87%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.10526944696903229\n",
      "Train Acc:99.77%, Test Acc:98.93%\n",
      "\n",
      "Class: 2 -> Train Acc 99.86572675394427 ; Test Acc 99.12790697674419 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.6195154786109924\n",
      "Train Acc:65.76%, Test Acc:90.00%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.25512582063674927\n",
      "Train Acc:92.63%, Test Acc:96.49%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.15163321793079376\n",
      "Train Acc:96.18%, Test Acc:97.33%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.18684621155261993\n",
      "Train Acc:97.07%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.17579708993434906\n",
      "Train Acc:97.83%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.25907859206199646\n",
      "Train Acc:98.43%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.1218692883849144\n",
      "Train Acc:98.79%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.18322116136550903\n",
      "Train Acc:98.73%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.22693632543087006\n",
      "Train Acc:99.00%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.09578517079353333\n",
      "Train Acc:99.10%, Test Acc:98.76%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.11733166128396988\n",
      "Train Acc:99.40%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.11911235004663467\n",
      "Train Acc:99.41%, Test Acc:98.76%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.10010095685720444\n",
      "Train Acc:99.50%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.10035806894302368\n",
      "Train Acc:99.67%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.06803423911333084\n",
      "Train Acc:99.62%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.08110611140727997\n",
      "Train Acc:99.69%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.12316495925188065\n",
      "Train Acc:99.71%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.1523323506116867\n",
      "Train Acc:99.85%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.10489553213119507\n",
      "Train Acc:99.86%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.08301548659801483\n",
      "Train Acc:99.89%, Test Acc:99.06%\n",
      "\n",
      "Class: 3 -> Train Acc 99.8858261295058 ; Test Acc 99.15841584158416 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.441390722990036\n",
      "Train Acc:67.38%, Test Acc:90.99%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.20305949449539185\n",
      "Train Acc:96.11%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.19335779547691345\n",
      "Train Acc:98.31%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.24706970155239105\n",
      "Train Acc:98.71%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.15367251634597778\n",
      "Train Acc:98.78%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.1370888203382492\n",
      "Train Acc:99.06%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.16038218140602112\n",
      "Train Acc:99.07%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.12959417700767517\n",
      "Train Acc:99.20%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.2013896107673645\n",
      "Train Acc:99.26%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.13943162560462952\n",
      "Train Acc:99.30%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.07413645088672638\n",
      "Train Acc:99.30%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.17272287607192993\n",
      "Train Acc:99.43%, Test Acc:99.24%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.14485454559326172\n",
      "Train Acc:99.49%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.11883991211652756\n",
      "Train Acc:99.58%, Test Acc:99.24%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.12978136539459229\n",
      "Train Acc:99.64%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.07141360640525818\n",
      "Train Acc:99.65%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.14922769367694855\n",
      "Train Acc:99.70%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.1358458250761032\n",
      "Train Acc:99.78%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.12320925295352936\n",
      "Train Acc:99.76%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.12119040638208389\n",
      "Train Acc:99.81%, Test Acc:99.24%\n",
      "\n",
      "Class: 4 -> Train Acc 99.81170831906881 ; Test Acc 99.38900203665987 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.47301924228668213\n",
      "Train Acc:61.20%, Test Acc:87.00%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.2513748109340668\n",
      "Train Acc:94.29%, Test Acc:96.58%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.2458304911851883\n",
      "Train Acc:96.87%, Test Acc:97.25%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:868,  Loss:0.20374953746795654\n",
      "Train Acc:97.80%, Test Acc:97.59%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.14797639846801758\n",
      "Train Acc:98.16%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.18889416754245758\n",
      "Train Acc:98.49%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.15465787053108215\n",
      "Train Acc:98.75%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.1411236971616745\n",
      "Train Acc:98.95%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.2027600109577179\n",
      "Train Acc:99.02%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.1296105533838272\n",
      "Train Acc:99.06%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.15270866453647614\n",
      "Train Acc:99.27%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.18694594502449036\n",
      "Train Acc:99.44%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.12338035553693771\n",
      "Train Acc:99.51%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.13464945554733276\n",
      "Train Acc:99.52%, Test Acc:98.21%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.15215565264225006\n",
      "Train Acc:99.59%, Test Acc:99.05%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.10928938537836075\n",
      "Train Acc:99.80%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.12252508103847504\n",
      "Train Acc:99.74%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1309996098279953\n",
      "Train Acc:99.74%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.077921561896801\n",
      "Train Acc:99.76%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.11883889138698578\n",
      "Train Acc:99.89%, Test Acc:98.60%\n",
      "\n",
      "Class: 5 -> Train Acc 99.88931931377975 ; Test Acc 99.04708520179372 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.30944332480430603\n",
      "Train Acc:68.98%, Test Acc:89.67%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.2639014720916748\n",
      "Train Acc:95.93%, Test Acc:97.76%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.18026265501976013\n",
      "Train Acc:98.06%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.22302256524562836\n",
      "Train Acc:98.56%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.16625553369522095\n",
      "Train Acc:99.00%, Test Acc:98.70%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.15353605151176453\n",
      "Train Acc:99.09%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.11280170828104019\n",
      "Train Acc:99.20%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.17734496295452118\n",
      "Train Acc:99.28%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.11944887042045593\n",
      "Train Acc:99.37%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.13627472519874573\n",
      "Train Acc:99.45%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.1651134043931961\n",
      "Train Acc:99.58%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.11281318217515945\n",
      "Train Acc:99.53%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.13774679601192474\n",
      "Train Acc:99.65%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.10076185315847397\n",
      "Train Acc:99.68%, Test Acc:99.48%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.08482560515403748\n",
      "Train Acc:99.71%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1307467818260193\n",
      "Train Acc:99.83%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.14883016049861908\n",
      "Train Acc:99.82%, Test Acc:99.53%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.08810392022132874\n",
      "Train Acc:99.77%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.13191814720630646\n",
      "Train Acc:99.83%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.11488369107246399\n",
      "Train Acc:99.82%, Test Acc:99.32%\n",
      "\n",
      "Class: 6 -> Train Acc 99.83102399459277 ; Test Acc 99.53027139874739 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.40985384583473206\n",
      "Train Acc:68.38%, Test Acc:89.49%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.18337973952293396\n",
      "Train Acc:94.28%, Test Acc:96.01%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.22465293109416962\n",
      "Train Acc:96.86%, Test Acc:96.60%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.20758645236492157\n",
      "Train Acc:97.30%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.22326692938804626\n",
      "Train Acc:97.91%, Test Acc:97.76%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.12927177548408508\n",
      "Train Acc:98.36%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.18511702120304108\n",
      "Train Acc:98.55%, Test Acc:97.13%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.1092013344168663\n",
      "Train Acc:98.64%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.17552801966667175\n",
      "Train Acc:98.75%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.2151050716638565\n",
      "Train Acc:98.99%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.1162995994091034\n",
      "Train Acc:99.21%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.11938657611608505\n",
      "Train Acc:99.31%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.12957800924777985\n",
      "Train Acc:99.39%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.165673166513443\n",
      "Train Acc:99.41%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.1451544612646103\n",
      "Train Acc:99.48%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.1099221259355545\n",
      "Train Acc:99.63%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.15087279677391052\n",
      "Train Acc:99.61%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.10541307926177979\n",
      "Train Acc:99.70%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.1757948249578476\n",
      "Train Acc:99.78%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.14657354354858398\n",
      "Train Acc:99.82%, Test Acc:98.98%\n",
      "\n",
      "Class: 7 -> Train Acc 99.81644054269752 ; Test Acc 99.0272373540856 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.467110812664032\n",
      "Train Acc:64.75%, Test Acc:86.04%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.2888090908527374\n",
      "Train Acc:89.57%, Test Acc:94.20%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.07623188197612762\n",
      "Train Acc:95.33%, Test Acc:94.46%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.0562233105301857\n",
      "Train Acc:96.59%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.2872472405433655\n",
      "Train Acc:97.86%, Test Acc:97.18%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.01362559199333191\n",
      "Train Acc:97.85%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.15255999565124512\n",
      "Train Acc:98.59%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.02489868737757206\n",
      "Train Acc:98.79%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.26167017221450806\n",
      "Train Acc:98.93%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.04119968041777611\n",
      "Train Acc:98.97%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.003950424492359161\n",
      "Train Acc:99.19%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.026783928275108337\n",
      "Train Acc:99.26%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.022887999191880226\n",
      "Train Acc:99.34%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.19226665794849396\n",
      "Train Acc:99.43%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.003596061607822776\n",
      "Train Acc:99.37%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.10745356231927872\n",
      "Train Acc:99.53%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.025242887437343597\n",
      "Train Acc:99.61%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.023230649530887604\n",
      "Train Acc:99.69%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.0016724166925996542\n",
      "Train Acc:99.68%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.019167814403772354\n",
      "Train Acc:99.68%, Test Acc:98.77%\n",
      "\n",
      "Class: 8 -> Train Acc 99.69236028029397 ; Test Acc 99.12731006160165 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.46932724118232727\n",
      "Train Acc:69.55%, Test Acc:89.40%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.3205728530883789\n",
      "Train Acc:92.37%, Test Acc:94.50%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.21474261581897736\n",
      "Train Acc:95.50%, Test Acc:95.99%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.23042237758636475\n",
      "Train Acc:96.76%, Test Acc:97.18%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.23431283235549927\n",
      "Train Acc:97.59%, Test Acc:97.72%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.14889979362487793\n",
      "Train Acc:98.07%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.1622512936592102\n",
      "Train Acc:98.25%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.1455049216747284\n",
      "Train Acc:98.61%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.14094386994838715\n",
      "Train Acc:98.69%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.15210860967636108\n",
      "Train Acc:98.94%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.1382880061864853\n",
      "Train Acc:99.04%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.12350601702928543\n",
      "Train Acc:99.18%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.14208970963954926\n",
      "Train Acc:99.36%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.14609825611114502\n",
      "Train Acc:99.42%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.1004643663764\n",
      "Train Acc:99.36%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.08932307362556458\n",
      "Train Acc:99.55%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.10733625292778015\n",
      "Train Acc:99.56%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.14421789348125458\n",
      "Train Acc:99.65%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.1448899358510971\n",
      "Train Acc:99.67%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.17628610134124756\n",
      "Train Acc:99.70%, Test Acc:98.71%\n",
      "\n",
      "Class: 9 -> Train Acc 99.69742813918305 ; Test Acc 98.86025768087215 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = InvCNN_MNIST()\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "            with torch.no_grad():\n",
    "                yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 99.94934999155834 ; Test Acc 99.64285714285714\n",
      "Class: 1 -> Train Acc 99.94808662118065 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.86572675394427 ; Test Acc 99.12790697674419\n",
      "Class: 3 -> Train Acc 99.8858261295058 ; Test Acc 99.15841584158416\n",
      "Class: 4 -> Train Acc 99.81170831906881 ; Test Acc 99.38900203665987\n",
      "Class: 5 -> Train Acc 99.88931931377975 ; Test Acc 99.04708520179372\n",
      "Class: 6 -> Train Acc 99.83102399459277 ; Test Acc 99.53027139874739\n",
      "Class: 7 -> Train Acc 99.81644054269752 ; Test Acc 99.0272373540856\n",
      "Class: 8 -> Train Acc 99.69236028029397 ; Test Acc 99.12731006160165\n",
      "Class: 9 -> Train Acc 99.69742813918305 ; Test Acc 98.86025768087215\n",
      "Total Accuracy (Argmax) is : 0.98089998960495\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19265"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(10,4))\n",
    "for i in range(10):\n",
    "    invNet = net_list[i]\n",
    "    invertible = SequentialFlow([*invNet.model[:-1]])## excluding distance regressor\n",
    "    icenter = invertible.inverse(invNet.model[-1].centers.data)\n",
    "    j, k = i//5, i%5\n",
    "#     print(i, j, k)\n",
    "    axs[j,k].imshow(icenter.data.cpu().reshape(28, 28))\n",
    "    axs[j,k].set_title(f\"{i}\")\n",
    "    axs[j,k].set_axis_off()\n",
    "# fig.tight_layout()\n",
    "plt.savefig(\"./invex_out/MNIST_InvertibleInvex_cnn_centroids.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
