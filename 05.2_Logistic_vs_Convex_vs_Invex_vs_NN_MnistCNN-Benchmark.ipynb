{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, os, pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "import mylibrary.nnlib as tnn\n",
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data():\n",
    "    global train_data, train_label\n",
    "    randidx = random.sample(range(len(train_label)), k=len(train_label))\n",
    "    train_data = train_data[randidx]\n",
    "    train_label = train_label[randidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_seeds = [147, 258, 369]\n",
    "# network_seeds = [369]\n",
    "network_seed = 369\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "actf = nn.LeakyReLU\n",
    "# actf = nn.ELU\n",
    "\n",
    "learning_rate = 0.005\n",
    "lambda_ = 2\n",
    "criterion = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "use_mixup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_OneClass_Balanced(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label, class_index):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.class_index = class_index\n",
    "        \n",
    "        mask = (label==class_index)\n",
    "        self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self.class_data = torch.nonzero(mask).reshape(-1)\n",
    "        self.other_data = torch.nonzero(~mask).reshape(-1)\n",
    "        \n",
    "        random.seed(network_seed)\n",
    "        self._shuffle_data_()\n",
    "        self.count = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2*len(self.class_data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "#         randidx = np.random.permutation(len(self.other_data))\n",
    "        randidx = random.sample(range(len(self.other_data)), k=len(self.other_data))\n",
    "        self.other_data = self.other_data[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.class_data):\n",
    "            idx = self.class_data[idx]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            idx = self.other_data[idx-len(self.class_data)]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "            self.count += 1\n",
    "            if self.count >= len(self.class_data): \n",
    "                self._shuffle_data_()\n",
    "                self.count = 0\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "# test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_all = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "# test_loader_all = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # img, lbl = train_dataset[11010]\n",
    "# img, lbl = test_dataset[10]\n",
    "# print(lbl)\n",
    "# plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnivariateCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels:list, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        assert len(channels)>1\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(channels)-1):\n",
    "            la = nn.Conv2d(channels[i], channels[i+1], kernel_size=(5,5), stride=2, padding=1)\n",
    "            layers.append(la)\n",
    "            layers.append(actf())\n",
    "        layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(channels[-1], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1, 28, 28)\n",
    "        x = self.features(x)\n",
    "        s = x.shape\n",
    "        return self.fc(x.reshape(s[0], s[1]))    \n",
    "    \n",
    "\n",
    "class ConvexCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels:list, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        assert len(channels)>1\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(channels)-1):\n",
    "            la = nn.Conv2d(channels[i], channels[i+1], kernel_size=(5,5), stride=2, padding=1)\n",
    "            layers.append(la)\n",
    "            if i>0:\n",
    "                layers[-1].weight.data *= 0.2\n",
    "            layers.append(actf())\n",
    "        layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(channels[-1], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,28, 28)\n",
    "        for i in range(2, len(self.features)-1, 2):\n",
    "            self.features[i].weight.data.abs_()\n",
    "        for i in range(0, len(self.fc), 2):\n",
    "            self.fc[i].weight.data.abs_()\n",
    "            \n",
    "        x = self.features(x)\n",
    "        s = x.shape\n",
    "        return self.fc(x.reshape(s[0], s[1]))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5953],\n",
       "        [3.6228]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnn = UnivariateCNN([1, 16, 32, 64])\n",
    "cnn = ConvexCNN([1, 16, 32, 64])\n",
    "cnn(torch.randn(2,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 8, 8]), torch.Size([2, 1, 14, 14]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Sequential(nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2),\n",
    "             nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2))\n",
    "# b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=4)\n",
    "b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2, dilation=2)\n",
    "x = torch.randn(2,1,32,32)\n",
    "\n",
    "a(x).shape, b(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 4, 4]), torch.Size([2, 1, 4, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Sequential(nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=2),\n",
    "                 nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2),\n",
    "                 nn.Conv2d(1,1, kernel_size=5, padding=2, stride=2))\n",
    "b = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=4, dilation=4)\n",
    "x = torch.randn(2,1,28,28)\n",
    "# nn.Conv2d()\n",
    "\n",
    "a(x).shape, b(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.502179741859436\n",
      "Train Acc:71.64%, Test Acc:74.69%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.41291874647140503\n",
      "Train Acc:84.88%, Test Acc:87.40%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.2867847979068756\n",
      "Train Acc:89.68%, Test Acc:75.87%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.23302306234836578\n",
      "Train Acc:91.80%, Test Acc:87.96%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.28443029522895813\n",
      "Train Acc:92.55%, Test Acc:88.98%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.2573814392089844\n",
      "Train Acc:92.99%, Test Acc:94.54%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.20436663925647736\n",
      "Train Acc:93.89%, Test Acc:90.31%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.2413509041070938\n",
      "Train Acc:93.53%, Test Acc:91.38%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.1579991579055786\n",
      "Train Acc:94.61%, Test Acc:90.51%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.17704105377197266\n",
      "Train Acc:94.43%, Test Acc:95.00%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.25889015197753906\n",
      "Train Acc:94.83%, Test Acc:93.88%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.1945742964744568\n",
      "Train Acc:95.03%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.11924849450588226\n",
      "Train Acc:95.13%, Test Acc:91.94%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.23458383977413177\n",
      "Train Acc:95.59%, Test Acc:93.16%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.20232556760311127\n",
      "Train Acc:95.27%, Test Acc:95.87%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.22026963531970978\n",
      "Train Acc:95.57%, Test Acc:94.69%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.1565781682729721\n",
      "Train Acc:95.69%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.2716021239757538\n",
      "Train Acc:95.88%, Test Acc:95.46%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.20637591183185577\n",
      "Train Acc:95.89%, Test Acc:96.07%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.20821385085582733\n",
      "Train Acc:96.08%, Test Acc:95.15%\n",
      "\n",
      "Class: 0 -> Train Acc 96.08306601384433 ; Test Acc 96.3265306122449 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.3049895763397217\n",
      "Train Acc:81.69%, Test Acc:92.51%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.23263108730316162\n",
      "Train Acc:95.31%, Test Acc:94.41%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.1536022573709488\n",
      "Train Acc:96.78%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.18918372690677643\n",
      "Train Acc:97.37%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.27494099736213684\n",
      "Train Acc:97.78%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.18580077588558197\n",
      "Train Acc:97.85%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.17363472282886505\n",
      "Train Acc:98.00%, Test Acc:98.33%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.1995394080877304\n",
      "Train Acc:97.95%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.1087968498468399\n",
      "Train Acc:98.04%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.10375559329986572\n",
      "Train Acc:98.05%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.18286070227622986\n",
      "Train Acc:98.06%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.2490338385105133\n",
      "Train Acc:98.10%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.13962045311927795\n",
      "Train Acc:98.11%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.17422325909137726\n",
      "Train Acc:98.15%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.18371887505054474\n",
      "Train Acc:98.30%, Test Acc:98.94%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.19604654610157013\n",
      "Train Acc:98.16%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.24602441489696503\n",
      "Train Acc:98.29%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.23272641003131866\n",
      "Train Acc:98.48%, Test Acc:98.94%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.1423395425081253\n",
      "Train Acc:98.21%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.13498681783676147\n",
      "Train Acc:98.41%, Test Acc:98.59%\n",
      "\n",
      "Class: 1 -> Train Acc 98.47967962029071 ; Test Acc 98.98678414096916 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.5215120911598206\n",
      "Train Acc:72.69%, Test Acc:76.99%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.34391874074935913\n",
      "Train Acc:84.52%, Test Acc:84.98%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.23404069244861603\n",
      "Train Acc:89.27%, Test Acc:83.43%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.5562332272529602\n",
      "Train Acc:91.50%, Test Acc:91.13%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.16792455315589905\n",
      "Train Acc:92.48%, Test Acc:90.21%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.10398342460393906\n",
      "Train Acc:93.86%, Test Acc:95.20%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.13363231718540192\n",
      "Train Acc:93.45%, Test Acc:92.93%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.3874112665653229\n",
      "Train Acc:94.12%, Test Acc:95.78%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.24875637888908386\n",
      "Train Acc:94.49%, Test Acc:94.72%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.2708955407142639\n",
      "Train Acc:94.58%, Test Acc:94.67%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.2984393239021301\n",
      "Train Acc:94.95%, Test Acc:94.96%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.25883767008781433\n",
      "Train Acc:95.48%, Test Acc:95.69%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.1871442198753357\n",
      "Train Acc:95.19%, Test Acc:95.78%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.22082757949829102\n",
      "Train Acc:95.64%, Test Acc:96.08%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.2539908289909363\n",
      "Train Acc:95.62%, Test Acc:94.48%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.20333337783813477\n",
      "Train Acc:95.76%, Test Acc:95.59%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.20425382256507874\n",
      "Train Acc:95.85%, Test Acc:95.74%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.1659824699163437\n",
      "Train Acc:96.07%, Test Acc:94.14%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.07975003123283386\n",
      "Train Acc:95.96%, Test Acc:97.14%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.1587374210357666\n",
      "Train Acc:96.02%, Test Acc:94.91%\n",
      "\n",
      "Class: 2 -> Train Acc 96.07250755287009 ; Test Acc 97.14147286821705 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.36400243639945984\n",
      "Train Acc:78.54%, Test Acc:87.72%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.4198724925518036\n",
      "Train Acc:90.86%, Test Acc:92.13%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.3824049234390259\n",
      "Train Acc:92.59%, Test Acc:90.10%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.09967142343521118\n",
      "Train Acc:93.24%, Test Acc:95.40%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.29864493012428284\n",
      "Train Acc:94.03%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.11428874731063843\n",
      "Train Acc:94.47%, Test Acc:91.34%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.19411815702915192\n",
      "Train Acc:94.49%, Test Acc:96.14%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.2013624906539917\n",
      "Train Acc:94.37%, Test Acc:91.93%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.208204448223114\n",
      "Train Acc:95.38%, Test Acc:92.18%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.16473735868930817\n",
      "Train Acc:95.22%, Test Acc:94.21%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.24540506303310394\n",
      "Train Acc:95.46%, Test Acc:95.50%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.42531049251556396\n",
      "Train Acc:95.34%, Test Acc:95.84%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.27410340309143066\n",
      "Train Acc:95.59%, Test Acc:92.33%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.07386313378810883\n",
      "Train Acc:95.59%, Test Acc:90.99%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.14284859597682953\n",
      "Train Acc:95.96%, Test Acc:95.15%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.41901978850364685\n",
      "Train Acc:95.78%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.1198115274310112\n",
      "Train Acc:95.76%, Test Acc:95.00%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.30823859572410583\n",
      "Train Acc:96.10%, Test Acc:93.42%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.13909952342510223\n",
      "Train Acc:96.09%, Test Acc:93.42%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.25714269280433655\n",
      "Train Acc:96.19%, Test Acc:97.33%\n",
      "\n",
      "Class: 3 -> Train Acc 96.19148589137171 ; Test Acc 97.32673267326733 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.38753607869148254\n",
      "Train Acc:75.93%, Test Acc:86.15%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.21488171815872192\n",
      "Train Acc:92.49%, Test Acc:93.69%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.18841128051280975\n",
      "Train Acc:93.58%, Test Acc:93.43%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.2030428647994995\n",
      "Train Acc:94.04%, Test Acc:94.45%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.19239889085292816\n",
      "Train Acc:94.66%, Test Acc:95.26%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.2936701774597168\n",
      "Train Acc:95.35%, Test Acc:94.96%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.26789140701293945\n",
      "Train Acc:95.29%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.17208963632583618\n",
      "Train Acc:95.53%, Test Acc:95.26%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.1543252170085907\n",
      "Train Acc:95.50%, Test Acc:93.99%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.2604433000087738\n",
      "Train Acc:95.81%, Test Acc:96.59%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.22520974278450012\n",
      "Train Acc:96.02%, Test Acc:96.03%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.21994753181934357\n",
      "Train Acc:95.86%, Test Acc:96.79%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.25202298164367676\n",
      "Train Acc:96.15%, Test Acc:93.13%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.17161603271961212\n",
      "Train Acc:96.22%, Test Acc:95.77%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.12717881798744202\n",
      "Train Acc:96.19%, Test Acc:96.95%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.12906219065189362\n",
      "Train Acc:96.47%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.20655637979507446\n",
      "Train Acc:96.61%, Test Acc:95.01%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.11096647381782532\n",
      "Train Acc:96.54%, Test Acc:96.44%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.1482575684785843\n",
      "Train Acc:96.78%, Test Acc:97.05%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.15220344066619873\n",
      "Train Acc:96.53%, Test Acc:97.51%\n",
      "\n",
      "Class: 4 -> Train Acc 96.7819239986306 ; Test Acc 97.50509164969449 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.5320016145706177\n",
      "Train Acc:76.56%, Test Acc:87.44%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.2767752707004547\n",
      "Train Acc:89.67%, Test Acc:85.26%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.2470032125711441\n",
      "Train Acc:92.68%, Test Acc:91.93%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.2119303047657013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.29%, Test Acc:93.83%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.24745318293571472\n",
      "Train Acc:94.83%, Test Acc:96.13%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.20287036895751953\n",
      "Train Acc:95.03%, Test Acc:95.80%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.1972137689590454\n",
      "Train Acc:95.42%, Test Acc:96.30%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.25880295038223267\n",
      "Train Acc:95.67%, Test Acc:95.63%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.2320770025253296\n",
      "Train Acc:95.99%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.246842160820961\n",
      "Train Acc:96.19%, Test Acc:93.05%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.14881765842437744\n",
      "Train Acc:96.37%, Test Acc:96.64%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.22326210141181946\n",
      "Train Acc:96.26%, Test Acc:96.86%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.1039741262793541\n",
      "Train Acc:96.19%, Test Acc:96.36%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.11739006638526917\n",
      "Train Acc:96.35%, Test Acc:96.75%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.22225986421108246\n",
      "Train Acc:96.55%, Test Acc:96.08%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.1546502411365509\n",
      "Train Acc:96.57%, Test Acc:95.18%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.19527067244052887\n",
      "Train Acc:97.12%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1869395524263382\n",
      "Train Acc:96.74%, Test Acc:95.91%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.2033744752407074\n",
      "Train Acc:96.76%, Test Acc:95.35%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.22633236646652222\n",
      "Train Acc:96.80%, Test Acc:95.46%\n",
      "\n",
      "Class: 5 -> Train Acc 97.12230215827337 ; Test Acc 96.8609865470852 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.45146259665489197\n",
      "Train Acc:73.17%, Test Acc:83.77%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.29003527760505676\n",
      "Train Acc:88.08%, Test Acc:90.34%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.27394187450408936\n",
      "Train Acc:91.89%, Test Acc:91.70%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.2669994533061981\n",
      "Train Acc:93.33%, Test Acc:92.01%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.2322641760110855\n",
      "Train Acc:94.44%, Test Acc:94.73%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.20111268758773804\n",
      "Train Acc:94.90%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.24041244387626648\n",
      "Train Acc:95.53%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.22514605522155762\n",
      "Train Acc:95.71%, Test Acc:95.62%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.08743688464164734\n",
      "Train Acc:95.82%, Test Acc:94.10%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.16983644664287567\n",
      "Train Acc:95.96%, Test Acc:96.09%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.1806136518716812\n",
      "Train Acc:96.18%, Test Acc:96.09%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.1829453408718109\n",
      "Train Acc:96.49%, Test Acc:95.46%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.21392515301704407\n",
      "Train Acc:96.48%, Test Acc:92.38%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.1730395406484604\n",
      "Train Acc:96.73%, Test Acc:96.76%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.18922732770442963\n",
      "Train Acc:96.70%, Test Acc:95.93%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.14906415343284607\n",
      "Train Acc:96.93%, Test Acc:95.82%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.15048113465309143\n",
      "Train Acc:97.09%, Test Acc:96.24%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.27472180128097534\n",
      "Train Acc:96.95%, Test Acc:96.50%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.16461987793445587\n",
      "Train Acc:97.22%, Test Acc:95.77%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.19615615904331207\n",
      "Train Acc:97.20%, Test Acc:97.55%\n",
      "\n",
      "Class: 6 -> Train Acc 97.22034471105103 ; Test Acc 97.54697286012527 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.38477838039398193\n",
      "Train Acc:74.76%, Test Acc:88.52%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.3609587550163269\n",
      "Train Acc:88.66%, Test Acc:88.72%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.2649296522140503\n",
      "Train Acc:90.02%, Test Acc:88.38%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.5421812534332275\n",
      "Train Acc:91.40%, Test Acc:92.90%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.15951567888259888\n",
      "Train Acc:92.27%, Test Acc:91.05%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.17919674515724182\n",
      "Train Acc:92.80%, Test Acc:90.27%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.23877331614494324\n",
      "Train Acc:93.17%, Test Acc:92.02%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.1905001699924469\n",
      "Train Acc:93.73%, Test Acc:93.58%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.12212669849395752\n",
      "Train Acc:94.96%, Test Acc:93.58%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.17683497071266174\n",
      "Train Acc:95.16%, Test Acc:91.44%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.19412606954574585\n",
      "Train Acc:95.20%, Test Acc:96.21%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.13292540609836578\n",
      "Train Acc:95.00%, Test Acc:95.09%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.1526222676038742\n",
      "Train Acc:95.36%, Test Acc:94.46%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.17924313247203827\n",
      "Train Acc:95.28%, Test Acc:92.90%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.1256081610918045\n",
      "Train Acc:95.79%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.21697737276554108\n",
      "Train Acc:95.77%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.1815153807401657\n",
      "Train Acc:95.86%, Test Acc:95.57%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.3039509654045105\n",
      "Train Acc:95.87%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.23387674987316132\n",
      "Train Acc:96.17%, Test Acc:95.57%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.21392202377319336\n",
      "Train Acc:96.19%, Test Acc:95.67%\n",
      "\n",
      "Class: 7 -> Train Acc 96.19313647246608 ; Test Acc 96.20622568093385 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.3553699851036072\n",
      "Train Acc:68.14%, Test Acc:78.44%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.46738600730895996\n",
      "Train Acc:84.46%, Test Acc:90.45%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.3319067060947418\n",
      "Train Acc:88.09%, Test Acc:90.91%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.06030808761715889\n",
      "Train Acc:89.62%, Test Acc:90.81%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.18988287448883057\n",
      "Train Acc:90.06%, Test Acc:88.04%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.032246723771095276\n",
      "Train Acc:89.96%, Test Acc:85.11%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.5488424897193909\n",
      "Train Acc:91.35%, Test Acc:90.14%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.37722599506378174\n",
      "Train Acc:91.15%, Test Acc:91.43%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.368284672498703\n",
      "Train Acc:92.31%, Test Acc:86.04%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.15314382314682007\n",
      "Train Acc:92.02%, Test Acc:86.24%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.06571659445762634\n",
      "Train Acc:92.58%, Test Acc:90.20%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.01851539872586727\n",
      "Train Acc:93.08%, Test Acc:95.17%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.10901562869548798\n",
      "Train Acc:93.28%, Test Acc:93.48%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.3322601020336151\n",
      "Train Acc:92.80%, Test Acc:69.92%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.057519230991601944\n",
      "Train Acc:92.89%, Test Acc:93.02%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.06542561948299408\n",
      "Train Acc:93.97%, Test Acc:87.32%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.062069252133369446\n",
      "Train Acc:93.86%, Test Acc:93.38%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.21713480353355408\n",
      "Train Acc:93.98%, Test Acc:96.15%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.0016676465747877955\n",
      "Train Acc:93.84%, Test Acc:85.93%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.6321905255317688\n",
      "Train Acc:93.86%, Test Acc:94.82%\n",
      "\n",
      "Class: 8 -> Train Acc 93.98393437019314 ; Test Acc 96.14989733059548 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.5557764172554016\n",
      "Train Acc:62.51%, Test Acc:77.80%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.44062796235084534\n",
      "Train Acc:81.38%, Test Acc:82.51%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.43716883659362793\n",
      "Train Acc:84.43%, Test Acc:83.94%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.5365292429924011\n",
      "Train Acc:85.98%, Test Acc:84.24%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.33263054490089417\n",
      "Train Acc:87.83%, Test Acc:85.38%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.2545408010482788\n",
      "Train Acc:88.63%, Test Acc:82.85%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.2639926075935364\n",
      "Train Acc:88.81%, Test Acc:87.36%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.23239368200302124\n",
      "Train Acc:89.82%, Test Acc:87.96%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.3330628573894501\n",
      "Train Acc:89.88%, Test Acc:90.39%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.2570061683654785\n",
      "Train Acc:90.59%, Test Acc:84.69%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.22767110168933868\n",
      "Train Acc:91.09%, Test Acc:88.06%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.28113552927970886\n",
      "Train Acc:90.91%, Test Acc:85.68%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.27548906207084656\n",
      "Train Acc:91.47%, Test Acc:89.74%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.2682812511920929\n",
      "Train Acc:91.96%, Test Acc:87.76%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.21408097445964813\n",
      "Train Acc:91.96%, Test Acc:86.27%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.2777880132198334\n",
      "Train Acc:91.63%, Test Acc:85.43%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.41210389137268066\n",
      "Train Acc:92.02%, Test Acc:82.71%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.3897702991962433\n",
      "Train Acc:92.15%, Test Acc:90.83%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.2757926881313324\n",
      "Train Acc:92.21%, Test Acc:90.54%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.2191687673330307\n",
      "Train Acc:92.49%, Test Acc:91.97%\n",
      "\n",
      "Class: 9 -> Train Acc 92.49453689695747 ; Test Acc 91.97224975222993 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = ConvexCNN([1, 16, 32], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "            with torch.no_grad():\n",
    "                yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 96.08306601384433 ; Test Acc 96.3265306122449\n",
      "Class: 1 -> Train Acc 98.47967962029071 ; Test Acc 98.98678414096916\n",
      "Class: 2 -> Train Acc 96.07250755287009 ; Test Acc 97.14147286821705\n",
      "Class: 3 -> Train Acc 96.19148589137171 ; Test Acc 97.32673267326733\n",
      "Class: 4 -> Train Acc 96.7819239986306 ; Test Acc 97.50509164969449\n",
      "Class: 5 -> Train Acc 97.12230215827337 ; Test Acc 96.8609865470852\n",
      "Class: 6 -> Train Acc 97.22034471105103 ; Test Acc 97.54697286012527\n",
      "Class: 7 -> Train Acc 96.19313647246608 ; Test Acc 96.20622568093385\n",
      "Class: 8 -> Train Acc 93.98393437019314 ; Test Acc 96.14989733059548\n",
      "Class: 9 -> Train Acc 92.49453689695747 ; Test Acc 91.97224975222993\n",
      "Total Accuracy (Argmax) is : 0.9412000179290771\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.1804620772600174\n",
      "Train Acc:86.23%, Test Acc:94.74%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.18958808481693268\n",
      "Train Acc:95.75%, Test Acc:97.04%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.198486790060997\n",
      "Train Acc:97.21%, Test Acc:97.24%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.17238833010196686\n",
      "Train Acc:97.78%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.13299264013767242\n",
      "Train Acc:98.27%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.17925728857517242\n",
      "Train Acc:98.51%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.14914283156394958\n",
      "Train Acc:98.73%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.13187280297279358\n",
      "Train Acc:98.97%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.12645836174488068\n",
      "Train Acc:99.09%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.18057182431221008\n",
      "Train Acc:99.17%, Test Acc:98.62%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.16148313879966736\n",
      "Train Acc:99.07%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.15103358030319214\n",
      "Train Acc:99.21%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.11444096267223358\n",
      "Train Acc:99.28%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.12282464653253555\n",
      "Train Acc:99.38%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.13376066088676453\n",
      "Train Acc:99.38%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1522301733493805\n",
      "Train Acc:99.51%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.1224607452750206\n",
      "Train Acc:99.47%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.17246827483177185\n",
      "Train Acc:99.60%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.1187882199883461\n",
      "Train Acc:99.62%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.11299744993448257\n",
      "Train Acc:99.59%, Test Acc:99.54%\n",
      "\n",
      "Class: 0 -> Train Acc 99.62012493668749 ; Test Acc 99.64285714285714 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.13804267346858978\n",
      "Train Acc:94.09%, Test Acc:98.85%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.1511746495962143\n",
      "Train Acc:98.37%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.11808193475008011\n",
      "Train Acc:98.61%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.15926505625247955\n",
      "Train Acc:98.80%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.14788022637367249\n",
      "Train Acc:98.80%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.12266390770673752\n",
      "Train Acc:98.80%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.09441517293453217\n",
      "Train Acc:99.03%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.11606942862272263\n",
      "Train Acc:99.01%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.10212311148643494\n",
      "Train Acc:99.22%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.1256958246231079\n",
      "Train Acc:99.25%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.12172568589448929\n",
      "Train Acc:99.33%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.19803737103939056\n",
      "Train Acc:99.39%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.0962444469332695\n",
      "Train Acc:99.40%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.14714877307415009\n",
      "Train Acc:99.50%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.13801109790802002\n",
      "Train Acc:99.53%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.12461511045694351\n",
      "Train Acc:99.47%, Test Acc:99.07%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.1490289270877838\n",
      "Train Acc:99.55%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.13564050197601318\n",
      "Train Acc:99.64%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.11279543489217758\n",
      "Train Acc:99.58%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.08764942735433578\n",
      "Train Acc:99.67%, Test Acc:99.07%\n",
      "\n",
      "Class: 1 -> Train Acc 99.67368733313556 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.37959763407707214\n",
      "Train Acc:83.21%, Test Acc:90.36%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.2376047819852829\n",
      "Train Acc:93.43%, Test Acc:95.88%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.2014264464378357\n",
      "Train Acc:95.42%, Test Acc:96.17%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.20733661949634552\n",
      "Train Acc:96.37%, Test Acc:96.56%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.14069752395153046\n",
      "Train Acc:97.15%, Test Acc:96.03%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.12020328640937805\n",
      "Train Acc:97.61%, Test Acc:95.69%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.13407845795154572\n",
      "Train Acc:97.82%, Test Acc:97.63%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.2529689371585846\n",
      "Train Acc:97.85%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.1741374284029007\n",
      "Train Acc:97.98%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.10230457782745361\n",
      "Train Acc:98.25%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.1652321219444275\n",
      "Train Acc:98.36%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.20071864128112793\n",
      "Train Acc:98.52%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.17944419384002686\n",
      "Train Acc:98.54%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.19315506517887115\n",
      "Train Acc:98.70%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.07995714247226715\n",
      "Train Acc:98.69%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.09391672164201736\n",
      "Train Acc:98.81%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.15205185115337372\n",
      "Train Acc:98.98%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.07819971442222595\n",
      "Train Acc:98.98%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.1429133266210556\n",
      "Train Acc:98.98%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.11101866513490677\n",
      "Train Acc:99.12%, Test Acc:98.69%\n",
      "\n",
      "Class: 2 -> Train Acc 99.11883182275932 ; Test Acc 98.74031007751938 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.19830000400543213\n",
      "Train Acc:82.93%, Test Acc:95.59%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.3743743896484375\n",
      "Train Acc:96.37%, Test Acc:97.43%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.15018106997013092\n",
      "Train Acc:97.68%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.08567086607217789\n",
      "Train Acc:98.10%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.1337411254644394\n",
      "Train Acc:98.12%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.09745374321937561\n",
      "Train Acc:98.34%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.11519807577133179\n",
      "Train Acc:98.65%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.11190500110387802\n",
      "Train Acc:98.74%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.08024057000875473\n",
      "Train Acc:98.99%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.09675008803606033\n",
      "Train Acc:99.01%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.16840632259845734\n",
      "Train Acc:99.05%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.13490892946720123\n",
      "Train Acc:99.21%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.1324869841337204\n",
      "Train Acc:99.23%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.059841979295015335\n",
      "Train Acc:99.26%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.10483502596616745\n",
      "Train Acc:99.33%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.3118214011192322\n",
      "Train Acc:99.42%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.0969623327255249\n",
      "Train Acc:99.38%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.1702343374490738\n",
      "Train Acc:99.41%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.13994523882865906\n",
      "Train Acc:99.58%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.06405433267354965\n",
      "Train Acc:99.41%, Test Acc:99.01%\n",
      "\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.15841584158416 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.23982928693294525\n",
      "Train Acc:82.34%, Test Acc:97.40%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.14335325360298157\n",
      "Train Acc:97.85%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.15335391461849213\n",
      "Train Acc:98.50%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.12210483849048615\n",
      "Train Acc:98.76%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.21075105667114258\n",
      "Train Acc:98.68%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.11386895179748535\n",
      "Train Acc:99.02%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.1309921145439148\n",
      "Train Acc:99.12%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.1302165985107422\n",
      "Train Acc:99.14%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.14932456612586975\n",
      "Train Acc:99.20%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.08988761156797409\n",
      "Train Acc:99.33%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.1495891511440277\n",
      "Train Acc:99.38%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.16353864967823029\n",
      "Train Acc:99.32%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.1476287543773651\n",
      "Train Acc:99.44%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.12028200179338455\n",
      "Train Acc:99.41%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.11658769845962524\n",
      "Train Acc:99.48%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.13557186722755432\n",
      "Train Acc:99.53%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.18525664508342743\n",
      "Train Acc:99.52%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.12945471704006195\n",
      "Train Acc:99.53%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.1409398317337036\n",
      "Train Acc:99.58%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.14161859452724457\n",
      "Train Acc:99.61%, Test Acc:99.49%\n",
      "\n",
      "Class: 4 -> Train Acc 99.60629921259843 ; Test Acc 99.54175152749491 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.3016887903213501\n",
      "Train Acc:82.38%, Test Acc:91.82%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.20363691449165344\n",
      "Train Acc:93.02%, Test Acc:92.15%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.16057659685611725\n",
      "Train Acc:95.95%, Test Acc:95.57%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:868,  Loss:0.15785810351371765\n",
      "Train Acc:97.18%, Test Acc:96.97%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.18532609939575195\n",
      "Train Acc:97.84%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.1583007574081421\n",
      "Train Acc:98.17%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.14335201680660248\n",
      "Train Acc:98.20%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.21838518977165222\n",
      "Train Acc:98.45%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.16314858198165894\n",
      "Train Acc:98.59%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.21017208695411682\n",
      "Train Acc:98.77%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.14147599041461945\n",
      "Train Acc:98.74%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.15156495571136475\n",
      "Train Acc:98.83%, Test Acc:99.10%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.09501968324184418\n",
      "Train Acc:98.99%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.08736466616392136\n",
      "Train Acc:98.81%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.1709200143814087\n",
      "Train Acc:99.05%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.117319256067276\n",
      "Train Acc:99.04%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.1268780678510666\n",
      "Train Acc:99.16%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1466900259256363\n",
      "Train Acc:99.21%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.15686221420764923\n",
      "Train Acc:99.23%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.17042173445224762\n",
      "Train Acc:99.29%, Test Acc:98.99%\n",
      "\n",
      "Class: 5 -> Train Acc 99.2897989300867 ; Test Acc 99.10313901345292 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.2077164649963379\n",
      "Train Acc:84.82%, Test Acc:95.35%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.1803015172481537\n",
      "Train Acc:96.89%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.1403782218694687\n",
      "Train Acc:98.24%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.16347092390060425\n",
      "Train Acc:98.77%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.12698158621788025\n",
      "Train Acc:98.76%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.11239638924598694\n",
      "Train Acc:98.92%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.12295404821634293\n",
      "Train Acc:99.09%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.18133968114852905\n",
      "Train Acc:99.08%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.13413743674755096\n",
      "Train Acc:99.19%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.14196336269378662\n",
      "Train Acc:99.26%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.12594693899154663\n",
      "Train Acc:99.35%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.16191288828849792\n",
      "Train Acc:99.43%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.1240246593952179\n",
      "Train Acc:99.48%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.07806704938411713\n",
      "Train Acc:99.45%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.15184958279132843\n",
      "Train Acc:99.47%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1246243342757225\n",
      "Train Acc:99.56%, Test Acc:99.48%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.11428627371788025\n",
      "Train Acc:99.61%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.15936179459095\n",
      "Train Acc:99.61%, Test Acc:99.53%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11686903983354568\n",
      "Train Acc:99.64%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.09980972111225128\n",
      "Train Acc:99.64%, Test Acc:99.58%\n",
      "\n",
      "Class: 6 -> Train Acc 99.63670158837445 ; Test Acc 99.58246346555325 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.2671484053134918\n",
      "Train Acc:85.06%, Test Acc:92.41%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.18784119188785553\n",
      "Train Acc:95.55%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.16933974623680115\n",
      "Train Acc:97.23%, Test Acc:96.98%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.19241642951965332\n",
      "Train Acc:97.31%, Test Acc:97.71%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.09435970336198807\n",
      "Train Acc:97.89%, Test Acc:96.94%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.14230617880821228\n",
      "Train Acc:98.48%, Test Acc:96.16%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.14463546872138977\n",
      "Train Acc:98.56%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.1213400661945343\n",
      "Train Acc:98.47%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.15879616141319275\n",
      "Train Acc:98.85%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.12247806042432785\n",
      "Train Acc:98.83%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.09170859307050705\n",
      "Train Acc:99.03%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.17424611747264862\n",
      "Train Acc:98.95%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.1336062252521515\n",
      "Train Acc:98.99%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.1410990208387375\n",
      "Train Acc:99.05%, Test Acc:99.17%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.13184624910354614\n",
      "Train Acc:99.08%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.13963961601257324\n",
      "Train Acc:99.17%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.13108742237091064\n",
      "Train Acc:99.39%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.11897862702608109\n",
      "Train Acc:99.40%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.11873172968626022\n",
      "Train Acc:99.31%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.14647677540779114\n",
      "Train Acc:99.51%, Test Acc:98.64%\n",
      "\n",
      "Class: 7 -> Train Acc 99.50518754988029 ; Test Acc 99.17315175097276 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.0888645201921463\n",
      "Train Acc:80.95%, Test Acc:92.30%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.3702276349067688\n",
      "Train Acc:92.73%, Test Acc:92.56%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.023279989138245583\n",
      "Train Acc:94.74%, Test Acc:96.61%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.02956424653530121\n",
      "Train Acc:95.82%, Test Acc:96.77%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.015788279473781586\n",
      "Train Acc:96.52%, Test Acc:97.79%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.4062718451023102\n",
      "Train Acc:97.06%, Test Acc:96.97%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.21542233228683472\n",
      "Train Acc:97.52%, Test Acc:96.15%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.06078759580850601\n",
      "Train Acc:97.95%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.3028002381324768\n",
      "Train Acc:98.06%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.12469369173049927\n",
      "Train Acc:98.33%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.009352878667414188\n",
      "Train Acc:98.50%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.13798624277114868\n",
      "Train Acc:98.57%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.16518639028072357\n",
      "Train Acc:98.81%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.11803603172302246\n",
      "Train Acc:98.75%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.0042509776540100574\n",
      "Train Acc:98.93%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.0663013681769371\n",
      "Train Acc:98.81%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.010093149729073048\n",
      "Train Acc:99.03%, Test Acc:98.92%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.314830482006073\n",
      "Train Acc:99.16%, Test Acc:98.87%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.014579261653125286\n",
      "Train Acc:99.21%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.05483465641736984\n",
      "Train Acc:99.30%, Test Acc:98.72%\n",
      "\n",
      "Class: 8 -> Train Acc 99.29926508289182 ; Test Acc 98.92197125256673 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.22302323579788208\n",
      "Train Acc:79.57%, Test Acc:90.68%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.18452173471450806\n",
      "Train Acc:92.45%, Test Acc:93.16%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.23750662803649902\n",
      "Train Acc:94.28%, Test Acc:94.80%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.1888790875673294\n",
      "Train Acc:95.88%, Test Acc:95.84%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.16795587539672852\n",
      "Train Acc:96.51%, Test Acc:95.79%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.13087183237075806\n",
      "Train Acc:96.91%, Test Acc:96.78%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.14902682602405548\n",
      "Train Acc:97.50%, Test Acc:96.93%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.11774980276823044\n",
      "Train Acc:98.03%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.14860795438289642\n",
      "Train Acc:98.21%, Test Acc:97.52%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.2118111103773117\n",
      "Train Acc:98.35%, Test Acc:97.57%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.12796105444431305\n",
      "Train Acc:98.67%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.09007184952497482\n",
      "Train Acc:98.59%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.1424645632505417\n",
      "Train Acc:98.71%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.15226441621780396\n",
      "Train Acc:98.89%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.11268064379692078\n",
      "Train Acc:98.99%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.14906056225299835\n",
      "Train Acc:98.92%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.210347518324852\n",
      "Train Acc:99.07%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.18221092224121094\n",
      "Train Acc:99.13%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.14765681326389313\n",
      "Train Acc:99.24%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.12328241020441055\n",
      "Train Acc:99.29%, Test Acc:98.17%\n",
      "\n",
      "Class: 9 -> Train Acc 99.28559421751555 ; Test Acc 98.26560951437067 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = UnivariateCNN([1, 16, 32], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "            with torch.no_grad():\n",
    "                yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 99.62012493668749 ; Test Acc 99.64285714285714\n",
      "Class: 1 -> Train Acc 99.67368733313556 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.11883182275932 ; Test Acc 98.74031007751938\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.15841584158416\n",
      "Class: 4 -> Train Acc 99.60629921259843 ; Test Acc 99.54175152749491\n",
      "Class: 5 -> Train Acc 99.2897989300867 ; Test Acc 99.10313901345292\n",
      "Class: 6 -> Train Acc 99.63670158837445 ; Test Acc 99.58246346555325\n",
      "Class: 7 -> Train Acc 99.50518754988029 ; Test Acc 99.17315175097276\n",
      "Class: 8 -> Train Acc 99.29926508289182 ; Test Acc 98.92197125256673\n",
      "Class: 9 -> Train Acc 99.28559421751555 ; Test Acc 98.26560951437067\n",
      "Total Accuracy (Argmax) is : 0.9793000221252441\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mixup = True\n",
    "use_check = False\n",
    "check_every = 2\n",
    "check_size = 100\n",
    "\n",
    "m_,s_ = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.5909543037414551, MinVal:0.8676339983940125, gp: 6.44832484633755e-17\n",
      "Train Acc:46.17%, Test Acc:76.07%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.3354240953922272, MinVal:2.0141360759735107, gp: 7.606768226345064e-37\n",
      "Train Acc:87.41%, Test Acc:93.32%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.22962957620620728, MinVal:1.5341095924377441, gp: 1.704854733112834e-28\n",
      "Train Acc:92.77%, Test Acc:94.64%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.23411162197589874, MinVal:1.2865544557571411, gp: 5.091819069732541e-24\n",
      "Train Acc:94.08%, Test Acc:95.10%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.19331051409244537, MinVal:1.765328288078308, gp: 2.738273829559003e-32\n",
      "Train Acc:94.93%, Test Acc:96.28%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.15277491509914398, MinVal:1.5068694353103638, gp: 5.529063684563874e-28\n",
      "Train Acc:95.70%, Test Acc:95.31%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.15293139219284058, MinVal:1.1833570003509521, gp: 2.7625325774858694e-22\n",
      "Train Acc:96.48%, Test Acc:96.73%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.14416582882404327, MinVal:1.04512357711792, gp: 5.263976116130585e-20\n",
      "Train Acc:96.78%, Test Acc:97.14%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.1680499166250229, MinVal:0.805983304977417, gp: 8.990376997212806e-16\n",
      "Train Acc:97.12%, Test Acc:97.60%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.1622166484594345, MinVal:0.6684703230857849, gp: 2.8954358984208117e-13\n",
      "Train Acc:97.63%, Test Acc:97.60%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.17035584151744843, MinVal:0.4992721974849701, gp: 1.5858110657962499e-10\n",
      "Train Acc:97.80%, Test Acc:97.09%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.16703058779239655, MinVal:0.5102486610412598, gp: 1.7188718504090872e-10\n",
      "Train Acc:98.22%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.13645562529563904, MinVal:0.5302790403366089, gp: 7.34258001622301e-11\n",
      "Train Acc:98.35%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.19955220818519592, MinVal:0.3245376944541931, gp: 1.6927712920278282e-07\n",
      "Train Acc:98.55%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.16821293532848358, MinVal:0.6048248410224915, gp: 5.524889573615965e-12\n",
      "Train Acc:98.73%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.18395154178142548, MinVal:0.407254159450531, gp: 6.358287230057158e-09\n",
      "Train Acc:98.87%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.15691885352134705, MinVal:0.5620139837265015, gp: 1.2797081103133046e-11\n",
      "Train Acc:99.16%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.13865116238594055, MinVal:0.36754292249679565, gp: 3.043669849489561e-08\n",
      "Train Acc:99.19%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11676431447267532, MinVal:0.7349829077720642, gp: 1.7919295401355208e-14\n",
      "Train Acc:99.25%, Test Acc:98.72%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.14203524589538574, MinVal:0.4536654055118561, gp: 9.882605844779846e-10\n",
      "Train Acc:99.49%, Test Acc:98.98%\n",
      "\n",
      "Class: 0 -> Train Acc 99.4850582475097 ; Test Acc 98.9795918367347 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.1538020372390747, MinVal:0.7088269591331482, gp: 9.104181167632341e-14\n",
      "Train Acc:91.86%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.16266106069087982, MinVal:0.5135893225669861, gp: 1.2601752974461533e-10\n",
      "Train Acc:98.18%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.15018907189369202, MinVal:0.70631343126297, gp: 5.4722936251860865e-14\n",
      "Train Acc:98.40%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.13835836946964264, MinVal:0.7006317377090454, gp: 7.87645095630049e-14\n",
      "Train Acc:98.61%, Test Acc:99.07%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.1431669294834137, MinVal:0.59380042552948, gp: 7.369990902283963e-12\n",
      "Train Acc:98.67%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.1240135207772255, MinVal:0.49993273615837097, gp: 6.129363128160037e-10\n",
      "Train Acc:98.89%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.12525674700737, MinVal:0.4025769829750061, gp: 1.0405833528182029e-08\n",
      "Train Acc:98.97%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.14555074274539948, MinVal:0.4559999406337738, gp: 1.7304523369787717e-09\n",
      "Train Acc:99.01%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.11995355784893036, MinVal:0.4379839301109314, gp: 3.789098368400801e-09\n",
      "Train Acc:99.12%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.11744654178619385, MinVal:0.356784462928772, gp: 6.332926716368092e-08\n",
      "Train Acc:99.24%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.1355971246957779, MinVal:0.4606669247150421, gp: 1.047339104331968e-09\n",
      "Train Acc:99.29%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.16232220828533173, MinVal:0.3642159402370453, gp: 4.702224387642673e-08\n",
      "Train Acc:99.45%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.11579629778862, MinVal:0.4392978250980377, gp: 2.3585482455956708e-09\n",
      "Train Acc:99.47%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.13127721846103668, MinVal:0.6490617990493774, gp: 1.1779948761239667e-12\n",
      "Train Acc:99.47%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.13097123801708221, MinVal:0.5788964629173279, gp: 8.836757714458798e-12\n",
      "Train Acc:99.70%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.12964914739131927, MinVal:0.5639140605926514, gp: 1.768224108800176e-11\n",
      "Train Acc:99.57%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.11656229943037033, MinVal:0.5915787816047668, gp: 1.1440831788889216e-11\n",
      "Train Acc:99.59%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.15616190433502197, MinVal:0.48847341537475586, gp: 3.279145011081397e-10\n",
      "Train Acc:99.64%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.10810402035713196, MinVal:0.6479437351226807, gp: 5.654491631867931e-13\n",
      "Train Acc:99.59%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.0801740288734436, MinVal:0.6706553101539612, gp: 3.839014067578972e-13\n",
      "Train Acc:99.70%, Test Acc:99.25%\n",
      "\n",
      "Class: 1 -> Train Acc 99.69593592405815 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.3358526825904846, MinVal:1.1676539182662964, gp: 1.1084683679769606e-21\n",
      "Train Acc:69.13%, Test Acc:87.55%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.27116337418556213, MinVal:1.2187187671661377, gp: 1.4385961554955838e-22\n",
      "Train Acc:92.83%, Test Acc:95.01%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.13748425245285034, MinVal:1.2389863729476929, gp: 6.39254507396678e-23\n",
      "Train Acc:96.19%, Test Acc:96.80%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.2043583244085312, MinVal:1.3871259689331055, gp: 3.7845910076769143e-25\n",
      "Train Acc:97.09%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.13623636960983276, MinVal:0.9258619546890259, gp: 2.4515143542427956e-17\n",
      "Train Acc:97.58%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.16260796785354614, MinVal:1.1623963117599487, gp: 2.6000130441358215e-21\n",
      "Train Acc:98.09%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.16086457669734955, MinVal:0.7742148637771606, gp: 7.582621156128604e-15\n",
      "Train Acc:98.28%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.23354780673980713, MinVal:0.7778773307800293, gp: 6.550780866376466e-15\n",
      "Train Acc:98.44%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.11681573837995529, MinVal:0.6476135849952698, gp: 1.1988568774864983e-12\n",
      "Train Acc:98.76%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.14730165898799896, MinVal:0.720753014087677, gp: 7.180782796720533e-14\n",
      "Train Acc:98.82%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.1356310397386551, MinVal:0.73545902967453, gp: 3.572050763359959e-14\n",
      "Train Acc:98.87%, Test Acc:98.79%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.1158159077167511, MinVal:0.8375872373580933, gp: 1.0121767375189847e-15\n",
      "Train Acc:99.11%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.08901797980070114, MinVal:0.5462455153465271, gp: 7.364350795846519e-11\n",
      "Train Acc:99.01%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.1798572689294815, MinVal:0.7502658367156982, gp: 2.3284898450571037e-14\n",
      "Train Acc:99.14%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.1228903979063034, MinVal:0.884354829788208, gp: 9.249900877759929e-17\n",
      "Train Acc:99.29%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.1146019697189331, MinVal:1.1215413808822632, gp: 8.088403866297218e-21\n",
      "Train Acc:99.45%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.11356561630964279, MinVal:0.5137275457382202, gp: 2.5845670048596503e-10\n",
      "Train Acc:99.38%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.14203284680843353, MinVal:0.82779860496521, gp: 1.042450118570327e-15\n",
      "Train Acc:99.51%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.09135399013757706, MinVal:0.7033271789550781, gp: 1.2909482781809506e-13\n",
      "Train Acc:99.28%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.1351006031036377, MinVal:0.7813853025436401, gp: 5.6876288821359165e-15\n",
      "Train Acc:99.50%, Test Acc:99.08%\n",
      "\n",
      "Class: 2 -> Train Acc 99.513259483048 ; Test Acc 99.07945736434108 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.34919726848602295, MinVal:0.47565969824790955, gp: 2.7688136228221083e-09\n",
      "Train Acc:81.84%, Test Acc:93.91%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.39460113644599915, MinVal:0.35733938217163086, gp: 1.8585340910703962e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.95%, Test Acc:97.13%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.15849657356739044, MinVal:0.6083126068115234, gp: 1.1074221401008444e-11\n",
      "Train Acc:96.70%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.19061410427093506, MinVal:0.6396447420120239, gp: 2.1994149123488738e-12\n",
      "Train Acc:97.67%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.20631951093673706, MinVal:0.565158486366272, gp: 4.325428556994915e-11\n",
      "Train Acc:98.16%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.10381584614515305, MinVal:0.5942614078521729, gp: 1.4537937693959169e-11\n",
      "Train Acc:98.56%, Test Acc:96.78%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.11105737835168839, MinVal:0.523272693157196, gp: 2.3101927315583026e-10\n",
      "Train Acc:98.51%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.13773779571056366, MinVal:0.8967038989067078, gp: 1.2154249137208347e-16\n",
      "Train Acc:98.84%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.15247158706188202, MinVal:1.018035888671875, gp: 6.036014994969753e-19\n",
      "Train Acc:98.97%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.10665667802095413, MinVal:0.872552752494812, gp: 1.9806156847268524e-16\n",
      "Train Acc:98.96%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.13978642225265503, MinVal:0.7449695467948914, gp: 3.621951168348604e-14\n",
      "Train Acc:99.14%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.1741061955690384, MinVal:0.8438490629196167, gp: 6.299739253172486e-16\n",
      "Train Acc:99.18%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.16988615691661835, MinVal:0.6566019654273987, gp: 1.1156839341275315e-12\n",
      "Train Acc:99.21%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.1039411723613739, MinVal:0.9431408047676086, gp: 1.732677362013596e-17\n",
      "Train Acc:99.37%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.15625132620334625, MinVal:0.6769120693206787, gp: 4.951153961645083e-13\n",
      "Train Acc:99.45%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.25058242678642273, MinVal:0.9137678146362305, gp: 3.8066087474804335e-17\n",
      "Train Acc:99.40%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.0758180096745491, MinVal:0.759264349937439, gp: 1.8915934695885352e-14\n",
      "Train Acc:99.40%, Test Acc:98.91%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.15077288448810577, MinVal:1.2738707065582275, gp: 3.413012701781587e-23\n",
      "Train Acc:99.44%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.19588017463684082, MinVal:1.1604194641113281, gp: 2.1518289783548317e-21\n",
      "Train Acc:99.56%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.13452090322971344, MinVal:0.9929848313331604, gp: 1.901591654922895e-18\n",
      "Train Acc:99.58%, Test Acc:99.21%\n",
      "\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.20792079207921 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.1849936693906784, MinVal:0.4403407871723175, gp: 5.386354473557731e-09\n",
      "Train Acc:79.58%, Test Acc:97.76%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.1414012312889099, MinVal:0.6077807545661926, gp: 3.891161698410528e-12\n",
      "Train Acc:97.78%, Test Acc:97.61%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.1481066793203354, MinVal:0.5267569422721863, gp: 1.1133517718864283e-10\n",
      "Train Acc:98.56%, Test Acc:99.19%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.1302618384361267, MinVal:0.26231467723846436, gp: 2.679865019672434e-06\n",
      "Train Acc:98.80%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.1754695028066635, MinVal:0.45441311597824097, gp: 1.7819454800616086e-09\n",
      "Train Acc:98.90%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.12459278106689453, MinVal:0.6297407150268555, gp: 1.1569929042609672e-12\n",
      "Train Acc:99.05%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.17799660563468933, MinVal:0.4403977394104004, gp: 2.2418529255219255e-09\n",
      "Train Acc:99.11%, Test Acc:99.08%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.1544528305530548, MinVal:0.4674991965293884, gp: 9.03320584999534e-10\n",
      "Train Acc:99.26%, Test Acc:98.52%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.12913715839385986, MinVal:0.4124410152435303, gp: 6.862158841158816e-09\n",
      "Train Acc:99.26%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.13444288074970245, MinVal:0.4348239004611969, gp: 6.311060563035653e-09\n",
      "Train Acc:99.40%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.1365794986486435, MinVal:0.519146203994751, gp: 1.1596935217683679e-10\n",
      "Train Acc:99.26%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.17056375741958618, MinVal:0.41451290249824524, gp: 6.309896605216636e-09\n",
      "Train Acc:99.25%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.127848818898201, MinVal:0.4448336362838745, gp: 1.9487382818539345e-09\n",
      "Train Acc:99.40%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.11774570494890213, MinVal:0.5927177667617798, gp: 5.181736983939089e-12\n",
      "Train Acc:99.49%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.11374012380838394, MinVal:0.36119386553764343, gp: 5.84109258738863e-08\n",
      "Train Acc:99.43%, Test Acc:99.59%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.11683734506368637, MinVal:0.4708901345729828, gp: 6.962233012330898e-10\n",
      "Train Acc:99.48%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.13785779476165771, MinVal:0.30011749267578125, gp: 7.101142500687274e-07\n",
      "Train Acc:99.47%, Test Acc:99.69%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.13503475487232208, MinVal:0.5402366518974304, gp: 4.158889899130713e-11\n",
      "Train Acc:99.51%, Test Acc:99.64%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.09224892407655716, MinVal:0.5469608306884766, gp: 3.982951121694889e-11\n",
      "Train Acc:99.54%, Test Acc:99.69%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.16044218838214874, MinVal:0.33894312381744385, gp: 1.5235109174227546e-07\n",
      "Train Acc:99.62%, Test Acc:99.08%\n",
      "\n",
      "Class: 4 -> Train Acc 99.62341663813763 ; Test Acc 99.69450101832994 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.3927873373031616, MinVal:0.6291785836219788, gp: 1.029111258016302e-12\n",
      "Train Acc:78.82%, Test Acc:90.75%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.23549151420593262, MinVal:0.3503447473049164, gp: 6.623585591114534e-08\n",
      "Train Acc:93.26%, Test Acc:93.83%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.12704400718212128, MinVal:0.4828949570655823, gp: 4.3849088249281465e-10\n",
      "Train Acc:96.07%, Test Acc:96.47%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.15481138229370117, MinVal:0.5342637896537781, gp: 4.598372030373277e-11\n",
      "Train Acc:96.84%, Test Acc:97.59%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.247423455119133, MinVal:0.3318394124507904, gp: 2.460663779402239e-07\n",
      "Train Acc:97.63%, Test Acc:98.21%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.16214945912361145, MinVal:0.8178524971008301, gp: 5.093519867052632e-16\n",
      "Train Acc:98.04%, Test Acc:97.98%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.12244517356157303, MinVal:0.5497109889984131, gp: 2.3204818275224248e-11\n",
      "Train Acc:98.18%, Test Acc:97.93%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.1954326331615448, MinVal:0.8933411240577698, gp: 2.867088405064334e-17\n",
      "Train Acc:98.52%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.14879092574119568, MinVal:1.0946338176727295, gp: 9.452688037099985e-21\n",
      "Train Acc:98.63%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.22406408190727234, MinVal:0.6414480805397034, gp: 5.844047576593348e-13\n",
      "Train Acc:98.60%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.14357499778270721, MinVal:0.7106018662452698, gp: 7.063101460039883e-14\n",
      "Train Acc:98.64%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.182102769613266, MinVal:0.8695012331008911, gp: 6.386991720022458e-17\n",
      "Train Acc:98.94%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.1348443478345871, MinVal:0.8875311017036438, gp: 3.103244168609038e-17\n",
      "Train Acc:98.99%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.138687402009964, MinVal:0.9386013746261597, gp: 4.054033688818315e-18\n",
      "Train Acc:98.84%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.1793166548013687, MinVal:0.826433002948761, gp: 4.889842853951455e-16\n",
      "Train Acc:99.03%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.09617365151643753, MinVal:0.9085437059402466, gp: 1.3559084216784513e-17\n",
      "Train Acc:99.22%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.13466951251029968, MinVal:0.7081066370010376, gp: 4.403657546578864e-14\n",
      "Train Acc:99.27%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1433425396680832, MinVal:0.5796034336090088, gp: 6.938122819322157e-12\n",
      "Train Acc:99.34%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.11622114479541779, MinVal:0.7843305468559265, gp: 1.925713311956654e-15\n",
      "Train Acc:99.37%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.15102145075798035, MinVal:1.1710901260375977, gp: 3.6988266634006397e-22\n",
      "Train Acc:99.34%, Test Acc:98.54%\n",
      "\n",
      "Class: 5 -> Train Acc 99.37280944475188 ; Test Acc 98.99103139013454 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.1866999715566635, MinVal:0.5797684788703918, gp: 1.0835813149534523e-11\n",
      "Train Acc:80.27%, Test Acc:95.41%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.16625061631202698, MinVal:0.48705169558525085, gp: 3.713556129270046e-10\n",
      "Train Acc:97.23%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.1772308200597763, MinVal:0.5735192894935608, gp: 1.8214858441001347e-11\n",
      "Train Acc:98.47%, Test Acc:98.80%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:948,  Loss:0.17350026965141296, MinVal:0.3557813763618469, gp: 6.868783941627044e-08\n",
      "Train Acc:98.73%, Test Acc:98.28%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.1184062659740448, MinVal:0.4782955050468445, gp: 4.97184959868946e-10\n",
      "Train Acc:98.85%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.1402582973241806, MinVal:1.0138187408447266, gp: 2.432738698506337e-19\n",
      "Train Acc:98.99%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.13905565440654755, MinVal:1.1099740266799927, gp: 4.949206589631595e-21\n",
      "Train Acc:99.15%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.1568649709224701, MinVal:1.2778247594833374, gp: 6.127293671143745e-24\n",
      "Train Acc:99.20%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.1388392448425293, MinVal:1.4091908931732178, gp: 3.137695483111739e-26\n",
      "Train Acc:99.14%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.1756681650876999, MinVal:1.461872935295105, gp: 3.814509558990992e-27\n",
      "Train Acc:99.29%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.14185567200183868, MinVal:1.5756696462631226, gp: 4.0231824916102073e-29\n",
      "Train Acc:99.28%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.13461440801620483, MinVal:1.7849849462509155, gp: 9.298021459734103e-33\n",
      "Train Acc:99.43%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.12495773285627365, MinVal:1.5566481351852417, gp: 8.610113566891724e-29\n",
      "Train Acc:99.36%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.16896532475948334, MinVal:1.9928113222122192, gp: 2.46619346171552e-36\n",
      "Train Acc:99.42%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.146890327334404, MinVal:2.259783983230591, gp: 5.251506124903684e-41\n",
      "Train Acc:99.53%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.10540696233510971, MinVal:2.8327457904815674, gp: 0.0\n",
      "Train Acc:99.43%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.14223931729793549, MinVal:1.3815375566482544, gp: 9.483974229835475e-26\n",
      "Train Acc:99.49%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.14452792704105377, MinVal:2.0849359035491943, gp: 5.72411365017573e-38\n",
      "Train Acc:99.59%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.14338818192481995, MinVal:3.4586427211761475, gp: 0.0\n",
      "Train Acc:99.60%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.12895594537258148, MinVal:2.518406867980957, gp: 2.802596928649634e-45\n",
      "Train Acc:99.63%, Test Acc:99.22%\n",
      "\n",
      "Class: 6 -> Train Acc 99.62825278810409 ; Test Acc 99.4258872651357 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.32160359621047974, MinVal:0.6349512934684753, gp: 1.1540721720285085e-12\n",
      "Train Acc:82.22%, Test Acc:93.68%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.21962673962116241, MinVal:0.2554705739021301, gp: 3.972909780713962e-06\n",
      "Train Acc:95.00%, Test Acc:96.01%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.13507835566997528, MinVal:0.3644093871116638, gp: 6.273878483398221e-08\n",
      "Train Acc:97.10%, Test Acc:96.25%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.17224161326885223, MinVal:0.6320809125900269, gp: 1.1938698727537167e-12\n",
      "Train Acc:97.35%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.10141265392303467, MinVal:0.48378440737724304, gp: 7.080816488702624e-10\n",
      "Train Acc:98.12%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.1534581482410431, MinVal:0.5404801368713379, gp: 5.6835394030008146e-11\n",
      "Train Acc:98.40%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.14189176261425018, MinVal:0.6858630776405334, gp: 1.385071934532564e-13\n",
      "Train Acc:98.73%, Test Acc:98.39%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.17531804740428925, MinVal:0.9251800179481506, gp: 1.0951786110598993e-17\n",
      "Train Acc:98.62%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.1457991600036621, MinVal:0.7397036552429199, gp: 1.606842676765089e-14\n",
      "Train Acc:98.91%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.129735067486763, MinVal:0.46873727440834045, gp: 8.183045352438967e-10\n",
      "Train Acc:98.91%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.09937790036201477, MinVal:1.2154483795166016, gp: 2.2237410840908977e-22\n",
      "Train Acc:98.93%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.2278764545917511, MinVal:1.047125220298767, gp: 7.358948342327509e-20\n",
      "Train Acc:99.03%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.12289037555456161, MinVal:0.4665282368659973, gp: 8.938290108062574e-10\n",
      "Train Acc:99.06%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.17563359439373016, MinVal:0.7959923148155212, gp: 1.9621336111062208e-15\n",
      "Train Acc:99.10%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.1402048021554947, MinVal:1.1738159656524658, gp: 9.249237351277278e-22\n",
      "Train Acc:99.25%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.11938647925853729, MinVal:0.9403411149978638, gp: 5.314630058979221e-18\n",
      "Train Acc:99.17%, Test Acc:99.42%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.17366527020931244, MinVal:1.1042163372039795, gp: 7.546449507677966e-21\n",
      "Train Acc:99.29%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.19871166348457336, MinVal:1.1497669219970703, gp: 1.2090805713530623e-21\n",
      "Train Acc:99.37%, Test Acc:99.17%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.1310342699289322, MinVal:1.1453561782836914, gp: 1.4442095887229406e-21\n",
      "Train Acc:99.37%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.14319218695163727, MinVal:1.188368558883667, gp: 2.581434852325113e-22\n",
      "Train Acc:99.47%, Test Acc:99.27%\n",
      "\n",
      "Class: 7 -> Train Acc 99.4732641660016 ; Test Acc 99.41634241245137 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.23044729232788086, MinVal:0.8598398566246033, gp: 1.9727873797585485e-15\n",
      "Train Acc:67.72%, Test Acc:92.09%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.10976516455411911, MinVal:1.1800832748413086, gp: 5.3936376465005525e-21\n",
      "Train Acc:92.04%, Test Acc:94.66%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.08276034146547318, MinVal:2.5692734718322754, gp: 5.605193857299268e-45\n",
      "Train Acc:94.15%, Test Acc:95.53%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.07836178690195084, MinVal:1.0337251424789429, gp: 1.880972937384092e-18\n",
      "Train Acc:94.87%, Test Acc:95.43%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.16640010476112366, MinVal:1.5435889959335327, gp: 2.613004874268399e-27\n",
      "Train Acc:96.00%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.484296977519989, MinVal:1.158776044845581, gp: 1.2648152174671254e-20\n",
      "Train Acc:96.23%, Test Acc:93.79%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.19940446317195892, MinVal:1.8795067071914673, gp: 3.8163889793964245e-33\n",
      "Train Acc:97.09%, Test Acc:95.69%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.01009473204612732, MinVal:2.8217484951019287, gp: 0.0\n",
      "Train Acc:97.35%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.32191914319992065, MinVal:1.1810802221298218, gp: 5.182777676133422e-21\n",
      "Train Acc:97.62%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.021312706172466278, MinVal:1.641912817955017, gp: 5.11776641898291e-29\n",
      "Train Acc:98.06%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.008980848826467991, MinVal:1.64780592918396, gp: 4.108385030496791e-29\n",
      "Train Acc:98.01%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.024744462221860886, MinVal:1.5226085186004639, gp: 6.0479704561540265e-27\n",
      "Train Acc:98.15%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.0748906284570694, MinVal:1.5041399002075195, gp: 1.2660230682293735e-26\n",
      "Train Acc:98.56%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.07276168465614319, MinVal:2.0320587158203125, gp: 8.541859848367364e-36\n",
      "Train Acc:98.62%, Test Acc:98.00%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.0027439678087830544, MinVal:1.6287037134170532, gp: 8.68054362125175e-29\n",
      "Train Acc:98.60%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.08388237655162811, MinVal:1.32280433177948, gp: 1.7888105757152175e-23\n",
      "Train Acc:98.68%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.007875315845012665, MinVal:2.1726629734039307, gp: 3.167893017523685e-38\n",
      "Train Acc:98.80%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.3113269507884979, MinVal:1.1221030950546265, gp: 5.484035562755527e-20\n",
      "Train Acc:98.95%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.011374356225132942, MinVal:1.2704373598098755, gp: 1.4530412715210116e-22\n",
      "Train Acc:99.09%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.07691547274589539, MinVal:1.6922370195388794, gp: 6.836918142574626e-30\n",
      "Train Acc:99.17%, Test Acc:98.61%\n",
      "\n",
      "Class: 8 -> Train Acc 99.17108186634763 ; Test Acc 98.61396303901438 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.2725397050380707, MinVal:0.2539227306842804, gp: 3.5273367302579572e-06\n",
      "Train Acc:78.18%, Test Acc:90.09%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.1815546303987503, MinVal:0.7310532927513123, gp: 4.162668541568722e-14\n",
      "Train Acc:92.44%, Test Acc:93.41%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.19900517165660858, MinVal:0.5927294492721558, gp: 3.813911426259198e-12\n",
      "Train Acc:93.70%, Test Acc:94.00%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.21739709377288818, MinVal:0.8420103788375854, gp: 3.4842827340247733e-16\n",
      "Train Acc:95.13%, Test Acc:95.64%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.18565146625041962, MinVal:0.7650740742683411, gp: 5.027605986558789e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.81%, Test Acc:95.29%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.1509491354227066, MinVal:0.9487681984901428, gp: 2.7557954309074176e-18\n",
      "Train Acc:96.50%, Test Acc:96.48%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.17523212730884552, MinVal:1.1820836067199707, gp: 3.7217117075877185e-22\n",
      "Train Acc:96.80%, Test Acc:96.73%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.13361099362373352, MinVal:1.1297414302825928, gp: 1.6836848384055777e-21\n",
      "Train Acc:97.48%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.15375612676143646, MinVal:1.4209798574447632, gp: 2.574249578590489e-26\n",
      "Train Acc:97.56%, Test Acc:97.32%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.13974452018737793, MinVal:0.925240159034729, gp: 6.0133999804201294e-18\n",
      "Train Acc:97.69%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.1262916922569275, MinVal:0.9064548015594482, gp: 1.273751354314582e-17\n",
      "Train Acc:98.14%, Test Acc:97.72%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.1433952897787094, MinVal:1.485651969909668, gp: 1.1101941312397585e-27\n",
      "Train Acc:98.12%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.19506920874118805, MinVal:1.1557812690734863, gp: 1.0227812614663467e-21\n",
      "Train Acc:98.49%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.15226267278194427, MinVal:1.4275553226470947, gp: 1.1330508559674523e-26\n",
      "Train Acc:98.60%, Test Acc:96.98%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.11765476316213608, MinVal:1.293183445930481, gp: 2.4373626687383118e-24\n",
      "Train Acc:98.73%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.20286737382411957, MinVal:1.4901113510131836, gp: 9.246658330230361e-28\n",
      "Train Acc:98.78%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.19332338869571686, MinVal:1.6708611249923706, gp: 6.706864362825638e-31\n",
      "Train Acc:98.83%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.1551053375005722, MinVal:1.4737082719802856, gp: 1.783549217679593e-27\n",
      "Train Acc:99.01%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.16065935790538788, MinVal:1.6005401611328125, gp: 1.1733557410359947e-29\n",
      "Train Acc:98.89%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.12662410736083984, MinVal:1.9846274852752686, gp: 2.3730414176243264e-36\n",
      "Train Acc:99.00%, Test Acc:98.51%\n",
      "\n",
      "Class: 9 -> Train Acc 99.00823667843335 ; Test Acc 98.51337958374629 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    lips_net = UnivariateCNN([1, 16, 32], actf)\n",
    "    Net = BasicInvexNet(784, lips_net, lambda_)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if use_check and epoch%check_every == 0:\n",
    "                rand_inp = torch.rand(check_size, 784)*m_+s_\n",
    "                Net(rand_inp)\n",
    "                Net.compute_penalty_and_clipper()\n",
    "                Net.gp.backward(retain_graph=True)\n",
    "            \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))   \n",
    "            Net.compute_penalty_and_clipper()\n",
    "            loss = criterion(yout, y_mix) + Net.gp\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        min_val, gp = float(Net.cond.min()) , float(Net.gp)\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}, MinVal:{min_val}, gp: {gp}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "#                     with torch.no_grad():\n",
    "            yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 99.4850582475097 ; Test Acc 98.9795918367347\n",
      "Class: 1 -> Train Acc 99.69593592405815 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.513259483048 ; Test Acc 99.07945736434108\n",
      "Class: 3 -> Train Acc 99.57592562387865 ; Test Acc 99.20792079207921\n",
      "Class: 4 -> Train Acc 99.62341663813763 ; Test Acc 99.69450101832994\n",
      "Class: 5 -> Train Acc 99.37280944475188 ; Test Acc 98.99103139013454\n",
      "Class: 6 -> Train Acc 99.62825278810409 ; Test Acc 99.4258872651357\n",
      "Class: 7 -> Train Acc 99.4732641660016 ; Test Acc 99.41634241245137\n",
      "Class: 8 -> Train Acc 99.17108186634763 ; Test Acc 98.61396303901438\n",
      "Class: 9 -> Train Acc 99.00823667843335 ; Test Acc 98.51337958374629\n",
      "Total Accuracy (Argmax) is : 0.9812999963760376\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 70000 input points\n",
      "Class: 1 -> Correct 100.0000% on 70000 input points\n",
      "Class: 2 -> Correct 100.0000% on 70000 input points\n",
      "Class: 3 -> Correct 100.0000% on 70000 input points\n",
      "Class: 4 -> Correct 99.9857% on 70000 input points\n",
      "Class: 5 -> Correct 100.0000% on 70000 input points\n",
      "Class: 6 -> Correct 100.0000% on 70000 input points\n",
      "Class: 7 -> Correct 100.0000% on 70000 input points\n",
      "Class: 8 -> Correct 100.0000% on 70000 input points\n",
      "Class: 9 -> Correct 100.0000% on 70000 input points\n"
     ]
    }
   ],
   "source": [
    "## only on training and testing data\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:46<00:00, 120.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:57<00:00, 112.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1 -> Correct 96.5372% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:44<00:00, 121.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 2 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:40<00:00, 124.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 3 -> Correct 99.9951% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:40<00:00, 124.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 4 -> Correct 10.0613% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:39<00:00, 125.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 5 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:38<00:00, 126.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 6 -> Correct 99.9995% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:39<00:00, 125.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 7 -> Correct 99.9503% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [02:53<00:00, 115.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 8 -> Correct 6.5421% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20000/20000 [03:01<00:00, 109.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 9 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Check the constraint on large number of points, including training and test data.\n",
    "from tqdm import tqdm\n",
    "\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    for i in tqdm(range(20000)):\n",
    "        xx = torch.rand(batch_size, 784)\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
