{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, ActNorm, ActNorm2D, BatchNorm1DFlow, BatchNorm2DFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.MNIST(root=\"./data/\", train=True, download=True, transform=train_transform)\n",
    "# test_dataset = datasets.MNIST(root=\"./data/\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=50, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "# Norm1D = BatchNorm1DFlow\n",
    "# Norm2D = BatchNorm2DFlow\n",
    "Norm1D = ActNorm\n",
    "Norm2D = ActNorm2D\n",
    "flows = [\n",
    "    Norm2D(1), ## can remove\n",
    "    irf.ConvResidualFlow([1, 28, 28], [16], kernels=3, activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "    Norm2D(4),\n",
    "    irf.ConvResidualFlow([4, 14, 14], [64], kernels=3, activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "    Norm2D(16),\n",
    "    irf.ConvResidualFlow([16, 7, 7], [64, 64], kernels=3, activation=actf),\n",
    "    Norm2D(16),\n",
    "    irf.Flatten(img_size=[16, 7, 7]),\n",
    "    Norm1D(16*7*7),\n",
    "        ]\n",
    "        \n",
    "\n",
    "# backbone = SequentialFlow(flows)\n",
    "backbone = nn.Sequential(*flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ActNorm2D()\n",
       "  (1): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (2): InvertiblePooling()\n",
       "  (3): ActNorm2D()\n",
       "  (4): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (5): InvertiblePooling()\n",
       "  (6): ActNorm2D()\n",
       "  (7): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (8): ActNorm2D()\n",
       "  (9): Flatten()\n",
       "  (10): ActNorm()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone(xx.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(module):\n",
    "    child = list(module.children())\n",
    "    if len(child) == 0:\n",
    "        return [module]\n",
    "    children = []\n",
    "    for ch in child:\n",
    "        grand_ch = get_children(ch)\n",
    "        children+=grand_ch\n",
    "    return children\n",
    "\n",
    "def remove_spectral_norm(model):\n",
    "    for child in get_children(model):\n",
    "        if hasattr(child, 'weight'):\n",
    "            print(\"Yes\", child)\n",
    "            try:\n",
    "                irf.remove_spectral_norm_conv(child)\n",
    "                print(\"Success : irf conv\")\n",
    "            except Exception as e:\n",
    "#                     print(e)\n",
    "                print(\"Failed : irf conv\")\n",
    "\n",
    "            try:\n",
    "                irf.remove_spectral_norm(child)\n",
    "                print(\"Success : irf lin\")\n",
    "            except Exception as e:\n",
    "#                     print(e)\n",
    "                print(\"Failed : irf lin\")\n",
    "\n",
    "            try:\n",
    "                nn.utils.remove_spectral_norm(child)\n",
    "                print(\"Success : nn\")\n",
    "            except Exception as e:\n",
    "#                     print(e)\n",
    "                print(\"Failed : nn\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_spectral_norm(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  62067\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in backbone.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50, 784])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    tt = backbone(xx.to(device))\n",
    "    print(xx.shape, tt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Linear(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 5\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "\n",
    "\n",
    "    def forward(self, x, hard=False):\n",
    "        x = self.linear(x)*torch.exp(self.inv_temp)\n",
    "        if hard:\n",
    "            x = torch.softmax(x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(x, dim=1)\n",
    "#             x = torch.softmax(x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Distance(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "\n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        self.bias = nn.Parameter(torch.zeros(1, num_sets))\n",
    "#         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 5\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "\n",
    "\n",
    "    def forward(self, x, hard=False):\n",
    "\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        ### correction to make diagonal of unit square 1 in nD space\n",
    "        dists = dists/np.sqrt(self.input_dim) + self.bias\n",
    "        dists = dists*torch.exp(self.inv_temp)\n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists, dim=1)\n",
    "#             x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### C10\n",
    "classifier = ConnectedClassifier_Distance(784, 100, 10, inv_temp=3.)\n",
    "#### for MLP based classification\n",
    "# classifier = nn.Sequential(nn.Linear(784, 100), nn.SELU(), nn.Linear(100, 10))\n",
    "\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  62067\n",
      "number of params:  79501\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in backbone.parameters()))\n",
    "print(\"number of params: \", sum(p.numel() for p in classifier.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(backbone, classifier).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  141568\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'fmnist_actnorm_multi_invex'\n",
    "# model_name = 'fmnist_batchnorm_multi_invex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### Train the whole damn thing\n",
    "\n",
    "# for epoch in range(start_epoch, start_epoch+EPOCHS):\n",
    "#     train(epoch)\n",
    "#     test(epoch)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc    #90.9 without first bn... with 90 ish is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([3.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89.68, 17)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'acc', 'epoch'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fmnist_actnorm_multi_invex'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43masdasd\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard test accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone, classifier = model[0], model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConnectedClassifier_Distance()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 407.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Acc:89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "model.eval()\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(backbone(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "acc = float(test_acc)/test_count*100\n",
    "print(f'Hard Acc:{acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Everything great... collect the images and labes for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 332.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Acc:89.31%\n",
      "[0, 0, 0, 8, 0, 0, 0, 0, 0, 963, 0, 995, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 17, 998, 0, 0, 0, 0, 0, 0, 0, 1078, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 974, 0, 0, 2, 2, 0, 1011, 0, 1016, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 294, 0, 0, 0, 0, 0, 0, 0, 1081, 0, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 471, 1054, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "set_acc = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(backbone(xx), hard=True)\n",
    "        \n",
    "    cls_indx = torch.argmax(classifier.cls_confidence, dim=1)\n",
    "    set_indx, count = torch.unique(cls_indx, return_counts=True) \n",
    "    set_count[set_indx] += count\n",
    "    \n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float)\n",
    "    \n",
    "    ### class_index has 100 possible values\n",
    "    for i, c in enumerate(correct):\n",
    "        set_acc[cls_indx[i]] += c\n",
    "    \n",
    "#     print(set_acc.sum(), set_count.sum())\n",
    "#     break\n",
    "    test_acc += correct.sum()\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx,\tcls,\tacc \ttot,\tpercent%\n",
      "3,\t3,\t6\t8,\t75.00%\n",
      "9,\t9,\t942\t963,\t97.72%\n",
      "11,\t1,\t982\t995,\t98.59%\n",
      "20,\t0,\t7\t12,\t58.33%\n",
      "24,\t4,\t7\t17,\t35.29%\n",
      "25,\t5,\t973\t998,\t97.49%\n",
      "33,\t3,\t924\t1078,\t85.62%\n",
      "42,\t2,\t0\t2,\t0.00%\n",
      "52,\t2,\t830\t974,\t85.22%\n",
      "55,\t5,\t1\t2,\t50.00%\n",
      "56,\t6,\t1\t2,\t50.00%\n",
      "58,\t8,\t961\t1011,\t95.05%\n",
      "60,\t0,\t841\t1016,\t82.68%\n",
      "76,\t6,\t189\t294,\t64.29%\n",
      "84,\t4,\t869\t1081,\t80.39%\n",
      "86,\t6,\t13\t22,\t59.09%\n",
      "96,\t6,\t411\t471,\t87.05%\n",
      "97,\t7,\t981\t1054,\t92.98%\n"
     ]
    }
   ],
   "source": [
    "print(f\"idx,\\tcls,\\tacc \\ttot,\\tpercent%\")\n",
    "for i, (cnt, acc, cls) in enumerate(zip(set_count.type(torch.long).tolist(),\n",
    "                                   (set_acc/set_count).tolist(),\n",
    "                                   torch.argmax(classifier.cls_weight, dim=1).tolist())):\n",
    "    if cnt == 0: continue\n",
    "    print(f\"{i},\\t{cls},\\t{int(np.ceil(acc*cnt))}\\t{cnt},\\t{acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 T-shirt/top\n",
      "1 Trouser\n",
      "2 Pullover\n",
      "3 Dress\n",
      "4 Coat\n",
      "5 Sandal\n",
      "6 Shirt\n",
      "7 Sneaker\n",
      "8 Bag\n",
      "9 Ankle boot\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(train_dataset.classes):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect data points for all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_data_dict = {}\n",
    "\n",
    "for i, (cnt, acc, cls) in enumerate(zip(set_count.type(torch.long).tolist(),\n",
    "                                   (set_acc/set_count).tolist(),\n",
    "                                   torch.argmax(classifier.cls_weight, dim=1).tolist())):\n",
    "    if cnt == 0: continue\n",
    "    idx_data_dict[i] = {\"cls\":cls, \"correct\":int(acc*cnt), \"total\":cnt, \"acc\":acc*100, \"xs\":[], \"ys\":[]}\n",
    "    \n",
    "idx_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(backbone(xx), hard=True)\n",
    "        \n",
    "    cls_indx = torch.argmax(classifier.cls_confidence, dim=1).cpu().numpy()\n",
    "    \n",
    "    for i in range(len(cls_indx)):\n",
    "        regi = cls_indx[i]\n",
    "        x = xx[i].cpu()\n",
    "        y = yy[i].cpu()\n",
    "        \n",
    "        idx_data_dict[regi][\"xs\"].append(x)\n",
    "        idx_data_dict[regi][\"ys\"].append(y)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, val in idx_data_dict.items():\n",
    "#     print(key)\n",
    "#     xs = torch.cat(val['xs'], dim=0).to(device)\n",
    "#     ys = torch.LongTensor(val['ys'])\n",
    "    \n",
    "#     del xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "invbackbone = SequentialFlow([*backbone])\n",
    "invbackbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.centers.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xcenter = invbackbone.inverse(classifier.centers.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmean, dstd = np.array([0, 0, 0]) , np.array([1, 1, 1]) ##f/mnist\n",
    "# dmean, dstd = np.array([0.4914, 0.4822, 0.4465]) , np.array([0.2023, 0.1994, 0.2010])\n",
    "# dmean, dstd = np.array([0.5071, 0.4865, 0.4409]) , np.array([0.2009, 0.1984, 0.2023]) ##cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = xcenter[i].cpu().permute(1,2,0).numpy()*dstd + dmean\n",
    "img = (img - img.min()) / (img.max()- img.min())\n",
    "# img = np.clip(img, 0, 1)\n",
    "\n",
    "plt.imshow(img)\n",
    "print(i)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test reversibility of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ximg = xx[i].cpu().permute(1,2,0).numpy()*dstd + dmean\n",
    "# i+=1\n",
    "# plt.imshow(ximg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = xx.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone(xx).data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xx_ = invbackbone.inverse(invbackbone(xx).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ximg_ = xx_[i].cpu().permute(1,2,0).numpy()*dstd + dmean\n",
    "plt.imshow(ximg_)\n",
    "plt.show()\n",
    "print(\"Reconstruction\")\n",
    "ximg = xx[i].cpu().permute(1,2,0).numpy()*dstd + dmean\n",
    "plt.imshow(ximg)\n",
    "plt.show()\n",
    "print(\"True\")\n",
    "print(i)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ximg_.max(), ximg_.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.centers.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now plot all centers as per index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xcenter = invbackbone.inverse(classifier.centers.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"invex_out/multiinvex_centers_viz/{model_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgsize = [3,32,32]\n",
    "imgsize = [1,28,28]\n",
    "    \n",
    "if isinstance(train_dataset, datasets.FashionMNIST):\n",
    "    train_dataset.classes[0] = 'T-shirt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for key, val in idx_data_dict.items():\n",
    "        print(key, val['total'])\n",
    "        xs = torch.stack(val['xs'], dim=0).to(device)\n",
    "\n",
    "#         print(xs.shape)\n",
    "        zs = backbone(xs)\n",
    "\n",
    "        ### find the medoid in z-space\n",
    "        idx = torch.cdist(zs, zs).sum(dim=0).argmin()\n",
    "        img = xs[idx].cpu().view(*imgsize).permute(1,2,0).numpy()*dstd + dmean\n",
    "        img = (img - img.min()) / (img.max()- img.min())\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"invex_out/multiinvex_centers_viz/{model_name}/zmedoid_({key})_{train_dataset.classes[val['cls']]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        ### find nearest in z-space\n",
    "        idx = torch.norm(zs-classifier.centers[key].view(1, np.prod(imgsize)), dim=1).argmin()\n",
    "        img = xs[idx].cpu().view(*imgsize).permute(1,2,0).numpy()*dstd + dmean\n",
    "        img = (img - img.min()) / (img.max()- img.min())\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"invex_out/multiinvex_centers_viz/{model_name}/znearest_({key})_{train_dataset.classes[val['cls']]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        ### find the medoid in x-space\n",
    "        xs = xs.view(-1, np.prod(imgsize))\n",
    "\n",
    "        ys = torch.LongTensor(val['ys'])\n",
    "\n",
    "        ## save center\n",
    "        img = xcenter[key].cpu().permute(1,2,0).numpy()*dstd + dmean\n",
    "        img = (img - img.min()) / (img.max()- img.min())\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"invex_out/multiinvex_centers_viz/{model_name}/xcenter_({key})_{train_dataset.classes[val['cls']]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        ## find medoid of the data\n",
    "        print(\"xMedoid\", idx:=torch.cdist(xs, xs).sum(dim=0).argmin())\n",
    "\n",
    "        img = xs[idx].cpu().view(*imgsize).permute(1,2,0).numpy()*dstd + dmean\n",
    "        img = (img - img.min()) / (img.max()- img.min())\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"invex_out/multiinvex_centers_viz/{model_name}/xmedoid_({key})_{train_dataset.classes[val['cls']]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        ## find closest data point\n",
    "        print(\"xNearest\", idx:=torch.norm(xs-xcenter[key].view(1, np.prod(imgsize)), dim=1).argmin())\n",
    "\n",
    "        img = xs[idx].cpu().view(*imgsize).permute(1,2,0).numpy()*dstd + dmean\n",
    "        img = (img - img.min()) / (img.max()- img.min())\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"invex_out/multiinvex_centers_viz/{model_name}/xnearest_({key})_{train_dataset.classes[val['cls']]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        del xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Reversibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invback = SequentialFlow(backbone).to(device)\n",
    "# invback.train()\n",
    "invback.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yys_ = invback.forward_intermediate(xx.to(device))\n",
    "    xxs_ = invback.inverse_intermediate(yys_[-1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(invback.flows), len(xxs_), len(yys_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(invback.flows)):\n",
    "    print(invback.flows[-i-1])\n",
    "    print(\"f\", yys_[-i-1].min(), yys_[-i-1].max(), yys_[-i-1].mean(), yys_[-i-1].std())\n",
    "    print(\"r\", xxs_[i+1].min(), xxs_[i+1].max())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invback.flows[2].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs_[0].min(), xxs_[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yys_[-1].min(), yys_[-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
