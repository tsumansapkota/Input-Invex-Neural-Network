{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random, os, pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from classes import DistanceRegressor, \\\n",
    "                LogisticRegression, ConvexNN, BasicInvexNet, LipschitzInvexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_seeds = [147, 258, 369]\n",
    "network_seed = 369\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "actf = nn.LeakyReLU\n",
    "\n",
    "learning_rate = 0.005\n",
    "lambda_ = 2\n",
    "criterion = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "use_mixup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_OneClass_Balanced(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label, class_index):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.class_index = class_index\n",
    "        \n",
    "        mask = (label==class_index)\n",
    "        self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self.class_data = torch.nonzero(mask).reshape(-1)\n",
    "        self.other_data = torch.nonzero(~mask).reshape(-1)\n",
    "        \n",
    "        random.seed(network_seed)\n",
    "        self._shuffle_data_()\n",
    "        self.count = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2*len(self.class_data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "#         randidx = np.random.permutation(len(self.other_data))\n",
    "        randidx = random.sample(range(len(self.other_data)), k=len(self.other_data))\n",
    "        self.other_data = self.other_data[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.class_data):\n",
    "            idx = self.class_data[idx]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            idx = self.other_data[idx-len(self.class_data)]\n",
    "            img, lbl = self.data[idx], self.label[idx]\n",
    "            self.count += 1\n",
    "            if self.count >= len(self.class_data): \n",
    "                self._shuffle_data_()\n",
    "                self.count = 0\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "# test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_all = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "# test_loader_all = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # img, lbl = train_dataset[11010]\n",
    "# img, lbl = test_dataset[10]\n",
    "# print(lbl)\n",
    "# plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:200,  Loss:0.5145545601844788\n",
      "Train Acc:50.19%, Test Acc:97.86%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5180794596672058\n",
      "Train Acc:50.23%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.49276816844940186\n",
      "Train Acc:50.68%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.47931113839149475\n",
      "Train Acc:51.96%, Test Acc:98.62%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5393970608711243\n",
      "Train Acc:52.35%, Test Acc:98.62%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5352065563201904\n",
      "Train Acc:55.47%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5227574110031128\n",
      "Train Acc:54.43%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5396431684494019\n",
      "Train Acc:55.88%, Test Acc:98.67%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5722149610519409\n",
      "Train Acc:58.11%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5416309237480164\n",
      "Train Acc:59.77%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5448659658432007\n",
      "Train Acc:61.73%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.47605592012405396\n",
      "Train Acc:64.13%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5507673025131226\n",
      "Train Acc:62.40%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5378962755203247\n",
      "Train Acc:63.92%, Test Acc:98.88%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5784996747970581\n",
      "Train Acc:65.60%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.556567907333374\n",
      "Train Acc:65.63%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5310576558113098\n",
      "Train Acc:66.98%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5406994819641113\n",
      "Train Acc:68.31%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.6000567674636841\n",
      "Train Acc:69.00%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5258157849311829\n",
      "Train Acc:69.90%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.4870152771472931\n",
      "Train Acc:70.71%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5273196697235107\n",
      "Train Acc:71.64%, Test Acc:98.72%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5119759440422058\n",
      "Train Acc:72.58%, Test Acc:98.88%\n",
      "\n",
      "\n",
      "Class: 0 -> Train Acc 72.57731958762886 ; Test Acc 98.87755102040816 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5757366418838501\n",
      "Train Acc:50.97%, Test Acc:97.84%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5064451694488525\n",
      "Train Acc:56.80%, Test Acc:98.15%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5058391094207764\n",
      "Train Acc:62.93%, Test Acc:98.28%\n",
      "\n",
      "\n",
      "Epoch: 2:800,  Loss:0.5571690201759338\n",
      "Train Acc:65.60%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.49012553691864014\n",
      "Train Acc:69.81%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5635290741920471\n",
      "Train Acc:72.38%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5214437246322632\n",
      "Train Acc:73.52%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.540818989276886\n",
      "Train Acc:76.40%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.5392243266105652\n",
      "Train Acc:78.01%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.5327045321464539\n",
      "Train Acc:78.73%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5226210951805115\n",
      "Train Acc:79.40%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.46489349007606506\n",
      "Train Acc:81.38%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.538142204284668\n",
      "Train Acc:82.33%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.5718343257904053\n",
      "Train Acc:81.96%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.5286102294921875\n",
      "Train Acc:83.67%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.5281524062156677\n",
      "Train Acc:83.60%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.524649977684021\n",
      "Train Acc:84.00%, Test Acc:98.55%\n",
      "\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.523627519607544\n",
      "Train Acc:84.33%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.4969729483127594\n",
      "Train Acc:83.90%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.5229828357696533\n",
      "Train Acc:85.43%, Test Acc:98.55%\n",
      "\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.5000366568565369\n",
      "Train Acc:85.40%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.5335561633110046\n",
      "Train Acc:85.95%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.5385556817054749\n",
      "Train Acc:88.00%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.5867807865142822\n",
      "Train Acc:86.63%, Test Acc:98.46%\n",
      "\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.4605940878391266\n",
      "Train Acc:87.24%, Test Acc:98.50%\n",
      "\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.510169506072998\n",
      "Train Acc:87.57%, Test Acc:98.41%\n",
      "\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.530099093914032\n",
      "Train Acc:87.68%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Class: 1 -> Train Acc 88.0 ; Test Acc 98.54625550660792 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5231406688690186\n",
      "Train Acc:49.96%, Test Acc:93.36%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.581961452960968\n",
      "Train Acc:51.43%, Test Acc:94.04%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5545611381530762\n",
      "Train Acc:51.64%, Test Acc:94.38%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5147527456283569\n",
      "Train Acc:55.08%, Test Acc:94.48%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5548372864723206\n",
      "Train Acc:55.95%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.553816020488739\n",
      "Train Acc:59.60%, Test Acc:94.72%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5212799310684204\n",
      "Train Acc:57.76%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.553977370262146\n",
      "Train Acc:59.06%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5228715538978577\n",
      "Train Acc:60.03%, Test Acc:95.01%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5416966080665588\n",
      "Train Acc:60.48%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5455771684646606\n",
      "Train Acc:62.61%, Test Acc:95.40%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5674116611480713\n",
      "Train Acc:60.20%, Test Acc:94.48%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5802629590034485\n",
      "Train Acc:63.36%, Test Acc:95.06%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5579709410667419\n",
      "Train Acc:64.37%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5117195248603821\n",
      "Train Acc:64.52%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5128772258758545\n",
      "Train Acc:64.80%, Test Acc:95.25%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.523897111415863\n",
      "Train Acc:67.00%, Test Acc:95.20%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5344842672348022\n",
      "Train Acc:65.20%, Test Acc:95.30%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5914225578308105\n",
      "Train Acc:66.75%, Test Acc:95.45%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5093531608581543\n",
      "Train Acc:67.07%, Test Acc:95.16%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5194254517555237\n",
      "Train Acc:66.99%, Test Acc:94.91%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.4712856709957123\n",
      "Train Acc:68.31%, Test Acc:95.06%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5671482682228088\n",
      "Train Acc:67.12%, Test Acc:95.11%\n",
      "\n",
      "\n",
      "Class: 2 -> Train Acc 68.3061224489796 ; Test Acc 95.44573643410853 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5477418899536133\n",
      "Train Acc:49.86%, Test Acc:93.47%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5663865804672241\n",
      "Train Acc:50.97%, Test Acc:94.16%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5414450168609619\n",
      "Train Acc:52.98%, Test Acc:94.11%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5298709869384766\n",
      "Train Acc:56.55%, Test Acc:94.21%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5383734703063965\n",
      "Train Acc:57.00%, Test Acc:94.31%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5409963726997375\n",
      "Train Acc:58.01%, Test Acc:94.50%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5370177626609802\n",
      "Train Acc:59.39%, Test Acc:94.70%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.4912644326686859\n",
      "Train Acc:60.44%, Test Acc:94.80%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.530971884727478\n",
      "Train Acc:60.36%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.4781021773815155\n",
      "Train Acc:63.94%, Test Acc:94.36%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5358640551567078\n",
      "Train Acc:63.31%, Test Acc:94.41%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.5537851452827454\n",
      "Train Acc:63.83%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.534007728099823\n",
      "Train Acc:64.87%, Test Acc:94.75%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5215175747871399\n",
      "Train Acc:64.94%, Test Acc:94.70%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5614319443702698\n",
      "Train Acc:66.46%, Test Acc:94.46%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.4917111098766327\n",
      "Train Acc:71.00%, Test Acc:94.50%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.5148254036903381\n",
      "Train Acc:67.77%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.5167309045791626\n",
      "Train Acc:68.51%, Test Acc:94.80%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.49834907054901123\n",
      "Train Acc:69.09%, Test Acc:94.26%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5384302735328674\n",
      "Train Acc:68.75%, Test Acc:95.00%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.50813227891922\n",
      "Train Acc:70.33%, Test Acc:94.75%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.5956133604049683\n",
      "Train Acc:69.72%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.517283022403717\n",
      "Train Acc:70.47%, Test Acc:94.95%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.5796144008636475\n",
      "Train Acc:69.67%, Test Acc:94.85%\n",
      "\n",
      "\n",
      "Class: 3 -> Train Acc 71.0 ; Test Acc 95.0 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5722525715827942\n",
      "Train Acc:49.66%, Test Acc:95.72%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.509173572063446\n",
      "Train Acc:51.34%, Test Acc:96.18%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5475192666053772\n",
      "Train Acc:53.64%, Test Acc:96.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5106757879257202\n",
      "Train Acc:55.33%, Test Acc:96.18%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5453128218650818\n",
      "Train Acc:59.28%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.521665096282959\n",
      "Train Acc:61.60%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5808333158493042\n",
      "Train Acc:60.13%, Test Acc:96.33%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5715281963348389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:61.60%, Test Acc:96.38%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5752459764480591\n",
      "Train Acc:63.23%, Test Acc:96.28%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.48756495118141174\n",
      "Train Acc:64.34%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5136403441429138\n",
      "Train Acc:65.23%, Test Acc:96.38%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5440595149993896\n",
      "Train Acc:67.37%, Test Acc:96.54%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5845538973808289\n",
      "Train Acc:68.62%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5023119449615479\n",
      "Train Acc:68.25%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.4997398257255554\n",
      "Train Acc:68.49%, Test Acc:96.44%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5358188152313232\n",
      "Train Acc:69.97%, Test Acc:96.54%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5366041660308838\n",
      "Train Acc:69.98%, Test Acc:96.64%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5245886445045471\n",
      "Train Acc:71.33%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.5042750835418701\n",
      "Train Acc:71.68%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.47352486848831177\n",
      "Train Acc:74.09%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5423820614814758\n",
      "Train Acc:72.73%, Test Acc:96.79%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5769064426422119\n",
      "Train Acc:73.30%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5346744656562805\n",
      "Train Acc:73.62%, Test Acc:96.69%\n",
      "\n",
      "\n",
      "Class: 4 -> Train Acc 74.0909090909091 ; Test Acc 96.79226069246437 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5801196098327637\n",
      "Train Acc:49.83%, Test Acc:92.43%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.6313232183456421\n",
      "Train Acc:50.21%, Test Acc:92.77%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5836358666419983\n",
      "Train Acc:51.46%, Test Acc:93.05%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5735167860984802\n",
      "Train Acc:52.43%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5309309959411621\n",
      "Train Acc:53.70%, Test Acc:93.05%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5707515478134155\n",
      "Train Acc:54.42%, Test Acc:92.83%\n",
      "\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.5534412860870361\n",
      "Train Acc:53.96%, Test Acc:92.83%\n",
      "\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.5295259356498718\n",
      "Train Acc:56.27%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.5768520832061768\n",
      "Train Acc:55.38%, Test Acc:93.22%\n",
      "\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.5614895224571228\n",
      "Train Acc:56.85%, Test Acc:93.50%\n",
      "\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.5277258157730103\n",
      "Train Acc:58.67%, Test Acc:93.72%\n",
      "\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.5733177661895752\n",
      "Train Acc:58.77%, Test Acc:92.71%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5186680555343628\n",
      "Train Acc:57.88%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.5154883861541748\n",
      "Train Acc:58.31%, Test Acc:93.33%\n",
      "\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.5437881350517273\n",
      "Train Acc:58.56%, Test Acc:93.39%\n",
      "\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.4924887418746948\n",
      "Train Acc:58.52%, Test Acc:93.22%\n",
      "\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.517260730266571\n",
      "Train Acc:59.19%, Test Acc:94.06%\n",
      "\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.5607610940933228\n",
      "Train Acc:58.86%, Test Acc:93.67%\n",
      "\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.5639969110488892\n",
      "Train Acc:60.16%, Test Acc:93.89%\n",
      "\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.5134164690971375\n",
      "Train Acc:59.81%, Test Acc:93.55%\n",
      "\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.5131828784942627\n",
      "Train Acc:62.00%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Class: 5 -> Train Acc 62.0 ; Test Acc 94.05829596412556 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5637227892875671\n",
      "Train Acc:49.91%, Test Acc:96.29%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5213305950164795\n",
      "Train Acc:50.80%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5507563948631287\n",
      "Train Acc:53.67%, Test Acc:96.66%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5327062606811523\n",
      "Train Acc:55.84%, Test Acc:96.87%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5393187999725342\n",
      "Train Acc:58.35%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5549942255020142\n",
      "Train Acc:59.87%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5694816708564758\n",
      "Train Acc:62.24%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5332455635070801\n",
      "Train Acc:63.83%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5384089946746826\n",
      "Train Acc:65.05%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5482410788536072\n",
      "Train Acc:67.50%, Test Acc:97.29%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5157971382141113\n",
      "Train Acc:68.30%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5370394587516785\n",
      "Train Acc:70.27%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.517962634563446\n",
      "Train Acc:70.05%, Test Acc:96.97%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.4806666970252991\n",
      "Train Acc:70.85%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5743381381034851\n",
      "Train Acc:72.51%, Test Acc:97.03%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5342861413955688\n",
      "Train Acc:73.18%, Test Acc:97.23%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5173391103744507\n",
      "Train Acc:74.00%, Test Acc:97.13%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5424497127532959\n",
      "Train Acc:73.33%, Test Acc:97.18%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.4584876000881195\n",
      "Train Acc:73.25%, Test Acc:97.18%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.5290852785110474\n",
      "Train Acc:75.51%, Test Acc:97.08%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5226898193359375\n",
      "Train Acc:75.99%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.5376988649368286\n",
      "Train Acc:76.67%, Test Acc:97.03%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5593709349632263\n",
      "Train Acc:75.63%, Test Acc:97.29%\n",
      "\n",
      "\n",
      "Class: 6 -> Train Acc 76.67164179104478 ; Test Acc 97.28601252609603 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5599358081817627\n",
      "Train Acc:49.88%, Test Acc:95.53%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.557117760181427\n",
      "Train Acc:51.74%, Test Acc:96.06%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.541958212852478\n",
      "Train Acc:54.61%, Test Acc:96.11%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.48048263788223267\n",
      "Train Acc:56.94%, Test Acc:95.91%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.5030351877212524\n",
      "Train Acc:59.74%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.5394090414047241\n",
      "Train Acc:60.89%, Test Acc:96.11%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5543871521949768\n",
      "Train Acc:64.15%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5142567157745361\n",
      "Train Acc:66.30%, Test Acc:96.21%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5405014157295227\n",
      "Train Acc:68.33%, Test Acc:96.16%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.5951653122901917\n",
      "Train Acc:68.13%, Test Acc:96.40%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.5305671691894531\n",
      "Train Acc:69.09%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.5531574487686157\n",
      "Train Acc:70.27%, Test Acc:95.96%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.4998423457145691\n",
      "Train Acc:72.13%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5117654800415039\n",
      "Train Acc:73.28%, Test Acc:96.45%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.5460245609283447\n",
      "Train Acc:72.02%, Test Acc:96.16%\n",
      "\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.5575208067893982\n",
      "Train Acc:72.78%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.5514141321182251\n",
      "Train Acc:73.17%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.5604078769683838\n",
      "Train Acc:74.28%, Test Acc:96.40%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5544518828392029\n",
      "Train Acc:75.14%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.5346813201904297\n",
      "Train Acc:75.34%, Test Acc:96.25%\n",
      "\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.5531907677650452\n",
      "Train Acc:75.91%, Test Acc:96.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.5012615919113159\n",
      "Train Acc:76.29%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.5591448545455933\n",
      "Train Acc:76.98%, Test Acc:96.50%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.5300306081771851\n",
      "Train Acc:78.26%, Test Acc:96.35%\n",
      "\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.5091061592102051\n",
      "Train Acc:76.83%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Class: 7 -> Train Acc 78.25806451612904 ; Test Acc 96.49805447470817 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.6450304985046387\n",
      "Train Acc:50.01%, Test Acc:87.99%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5915955901145935\n",
      "Train Acc:50.91%, Test Acc:88.24%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.6078071594238281\n",
      "Train Acc:52.06%, Test Acc:89.68%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.5573796629905701\n",
      "Train Acc:52.32%, Test Acc:89.58%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.6016493439674377\n",
      "Train Acc:53.43%, Test Acc:89.68%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5828666090965271\n",
      "Train Acc:54.72%, Test Acc:90.14%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5385180115699768\n",
      "Train Acc:55.01%, Test Acc:90.50%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.530825674533844\n",
      "Train Acc:56.04%, Test Acc:90.61%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.5526193976402283\n",
      "Train Acc:56.99%, Test Acc:89.73%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.6052979826927185\n",
      "Train Acc:56.38%, Test Acc:90.45%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.5396416783332825\n",
      "Train Acc:57.48%, Test Acc:90.55%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5757309198379517\n",
      "Train Acc:58.00%, Test Acc:90.76%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.5447659492492676\n",
      "Train Acc:57.60%, Test Acc:90.71%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5651159882545471\n",
      "Train Acc:58.54%, Test Acc:90.50%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5971723794937134\n",
      "Train Acc:59.13%, Test Acc:90.86%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5524383187294006\n",
      "Train Acc:59.01%, Test Acc:91.07%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.622504472732544\n",
      "Train Acc:60.11%, Test Acc:90.76%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.5428398847579956\n",
      "Train Acc:59.12%, Test Acc:91.02%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.5414087176322937\n",
      "Train Acc:58.65%, Test Acc:90.97%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.5529295802116394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:60.00%, Test Acc:91.07%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5907708406448364\n",
      "Train Acc:60.27%, Test Acc:91.12%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.527740478515625\n",
      "Train Acc:60.89%, Test Acc:91.12%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5166277885437012\n",
      "Train Acc:60.98%, Test Acc:91.22%\n",
      "\n",
      "\n",
      "Class: 8 -> Train Acc 60.977777777777774 ; Test Acc 91.22176591375771 \n",
      "\n",
      "Epoch: 0:200,  Loss:0.5678597092628479\n",
      "Train Acc:50.26%, Test Acc:91.28%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.523908793926239\n",
      "Train Acc:51.80%, Test Acc:92.17%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.5640270113945007\n",
      "Train Acc:55.66%, Test Acc:92.67%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.511634111404419\n",
      "Train Acc:57.33%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5540332198143005\n",
      "Train Acc:59.38%, Test Acc:93.06%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.5439659357070923\n",
      "Train Acc:60.40%, Test Acc:92.96%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.5291340351104736\n",
      "Train Acc:62.60%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.5902145504951477\n",
      "Train Acc:63.59%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.563675582408905\n",
      "Train Acc:65.00%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.5548736453056335\n",
      "Train Acc:65.19%, Test Acc:93.16%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.4994131922721863\n",
      "Train Acc:65.79%, Test Acc:92.81%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.5544479489326477\n",
      "Train Acc:66.40%, Test Acc:93.06%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.5234802961349487\n",
      "Train Acc:68.09%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.5429325699806213\n",
      "Train Acc:67.81%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.5664948225021362\n",
      "Train Acc:68.97%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.5179298520088196\n",
      "Train Acc:70.43%, Test Acc:93.16%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.5418621301651001\n",
      "Train Acc:69.59%, Test Acc:92.96%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.505419135093689\n",
      "Train Acc:70.93%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.5523645281791687\n",
      "Train Acc:71.32%, Test Acc:93.26%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.49978867173194885\n",
      "Train Acc:71.41%, Test Acc:93.11%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.5472095012664795\n",
      "Train Acc:71.87%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.6039488911628723\n",
      "Train Acc:72.22%, Test Acc:93.21%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.5674902200698853\n",
      "Train Acc:73.26%, Test Acc:93.36%\n",
      "\n",
      "\n",
      "Class: 9 -> Train Acc 73.25641025641025 ; Test Acc 93.35976214073341 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_idx = 0\n",
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    logNet = LogisticRegression(784)\n",
    "    optimizer = torch.optim.Adam(logNet.parameters(), lr=learning_rate)\n",
    "\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(logNet(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = logNet(xx)\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print(\"\\n\")\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(logNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 72.57731958762886 ; Test Acc 98.87755102040816\n",
      "Class: 1 -> Train Acc 88.0 ; Test Acc 98.54625550660792\n",
      "Class: 2 -> Train Acc 68.3061224489796 ; Test Acc 95.44573643410853\n",
      "Class: 3 -> Train Acc 71.0 ; Test Acc 95.0\n",
      "Class: 4 -> Train Acc 74.0909090909091 ; Test Acc 96.79226069246437\n",
      "Class: 5 -> Train Acc 62.0 ; Test Acc 94.05829596412556\n",
      "Class: 6 -> Train Acc 76.67164179104478 ; Test Acc 97.28601252609603\n",
      "Class: 7 -> Train Acc 78.25806451612904 ; Test Acc 96.49805447470817\n",
      "Class: 8 -> Train Acc 60.977777777777774 ; Test Acc 91.22176591375771\n",
      "Class: 9 -> Train Acc 73.25641025641025 ; Test Acc 93.35976214073341\n",
      "Total Accuracy (Argmax) is : 0.9154000282287598\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    shuffle_data()\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(net(xx).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        \n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:200,  Loss:0.1902083456516266\n",
      "Train Acc:96.30%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.16477316617965698\n",
      "Train Acc:98.49%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.14492975175380707\n",
      "Train Acc:98.76%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11025704443454742\n",
      "Train Acc:99.30%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12073925137519836\n",
      "Train Acc:99.38%, Test Acc:98.83%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13998454809188843\n",
      "Train Acc:99.33%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14511480927467346\n",
      "Train Acc:99.54%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11947750300168991\n",
      "Train Acc:99.52%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.12466155737638474\n",
      "Train Acc:99.62%, Test Acc:99.59%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.13368499279022217\n",
      "Train Acc:99.81%, Test Acc:99.08%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.08891221880912781\n",
      "Train Acc:99.82%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12346048653125763\n",
      "Train Acc:99.80%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12881770730018616\n",
      "Train Acc:99.83%, Test Acc:99.18%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.13905762135982513\n",
      "Train Acc:99.88%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.12862369418144226\n",
      "Train Acc:99.90%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12938882410526276\n",
      "Train Acc:99.95%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13960690796375275\n",
      "Train Acc:99.98%, Test Acc:99.23%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14705486595630646\n",
      "Train Acc:99.96%, Test Acc:99.13%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.12308577448129654\n",
      "Train Acc:100.00%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.10609354078769684\n",
      "Train Acc:99.95%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.11645776778459549\n",
      "Train Acc:99.92%, Test Acc:99.23%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.11739588528871536\n",
      "Train Acc:99.96%, Test Acc:99.39%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10554870963096619\n",
      "Train Acc:99.96%, Test Acc:99.29%\n",
      "\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.59183673469387 \n",
      "\n",
      "1\n",
      "Epoch: 0:200,  Loss:0.1425032764673233\n",
      "Train Acc:97.54%, Test Acc:99.03%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.18024057149887085\n",
      "Train Acc:99.05%, Test Acc:99.16%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10396085679531097\n",
      "Train Acc:99.33%, Test Acc:99.25%\n",
      "\n",
      "\n",
      "Epoch: 2:800,  Loss:0.1667274832725525\n",
      "Train Acc:99.29%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.11828016489744186\n",
      "Train Acc:99.43%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.11114610731601715\n",
      "Train Acc:99.52%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12431404739618301\n",
      "Train Acc:99.56%, Test Acc:99.21%\n",
      "\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.08999494463205338\n",
      "Train Acc:99.77%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.13094817101955414\n",
      "Train Acc:99.73%, Test Acc:99.16%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.15088516473770142\n",
      "Train Acc:99.85%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13319379091262817\n",
      "Train Acc:99.80%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.14544972777366638\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.12383203208446503\n",
      "Train Acc:99.82%, Test Acc:99.52%\n",
      "\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.13052725791931152\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.1400119811296463\n",
      "Train Acc:99.80%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.1131279394030571\n",
      "Train Acc:99.94%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.12418492138385773\n",
      "Train Acc:99.88%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.1175309494137764\n",
      "Train Acc:99.87%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.09147365391254425\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.10080915689468384\n",
      "Train Acc:99.90%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.10214205086231232\n",
      "Train Acc:99.96%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.1218646839261055\n",
      "Train Acc:99.95%, Test Acc:99.34%\n",
      "\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.08219657093286514\n",
      "Train Acc:100.00%, Test Acc:99.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.11717012524604797\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.11913299560546875\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.1223207488656044\n",
      "Train Acc:99.97%, Test Acc:99.30%\n",
      "\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.07791361957788467\n",
      "Train Acc:99.96%, Test Acc:99.43%\n",
      "\n",
      "\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:200,  Loss:0.2650079131126404\n",
      "Train Acc:91.53%, Test Acc:93.85%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.17949020862579346\n",
      "Train Acc:94.35%, Test Acc:94.91%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.21905013918876648\n",
      "Train Acc:95.25%, Test Acc:94.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.22428405284881592\n",
      "Train Acc:94.34%, Test Acc:94.86%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.24380725622177124\n",
      "Train Acc:95.18%, Test Acc:94.62%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.25583207607269287\n",
      "Train Acc:95.20%, Test Acc:95.16%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.20520855486392975\n",
      "Train Acc:95.18%, Test Acc:94.96%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.24707399308681488\n",
      "Train Acc:95.70%, Test Acc:95.83%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.19025787711143494\n",
      "Train Acc:96.58%, Test Acc:96.51%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.21622955799102783\n",
      "Train Acc:97.14%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.1838093400001526\n",
      "Train Acc:97.22%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.1830339878797531\n",
      "Train Acc:97.20%, Test Acc:96.75%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.21658693253993988\n",
      "Train Acc:97.63%, Test Acc:97.04%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.19069938361644745\n",
      "Train Acc:98.02%, Test Acc:97.34%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1710907369852066\n",
      "Train Acc:97.77%, Test Acc:97.19%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.13751934468746185\n",
      "Train Acc:97.89%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.20875801146030426\n",
      "Train Acc:98.19%, Test Acc:97.19%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.19916895031929016\n",
      "Train Acc:98.40%, Test Acc:97.04%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.14467047154903412\n",
      "Train Acc:98.41%, Test Acc:95.98%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.13490961492061615\n",
      "Train Acc:98.41%, Test Acc:97.58%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09605809301137924\n",
      "Train Acc:98.57%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.13726423680782318\n",
      "Train Acc:99.00%, Test Acc:97.43%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.18312187492847443\n",
      "Train Acc:98.68%, Test Acc:98.11%\n",
      "\n",
      "\n",
      "Class: 2 -> Train Acc 99.0 ; Test Acc 98.11046511627907 \n",
      "\n",
      "3\n",
      "Epoch: 0:200,  Loss:0.2091067135334015\n",
      "Train Acc:91.95%, Test Acc:95.00%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.21398845314979553\n",
      "Train Acc:96.09%, Test Acc:96.49%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.15884657204151154\n",
      "Train Acc:96.69%, Test Acc:97.28%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.15473070740699768\n",
      "Train Acc:97.61%, Test Acc:97.23%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.17709587514400482\n",
      "Train Acc:98.25%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.1611410528421402\n",
      "Train Acc:98.20%, Test Acc:98.12%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13801859319210052\n",
      "Train Acc:98.54%, Test Acc:97.57%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1486503928899765\n",
      "Train Acc:99.06%, Test Acc:96.78%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.17162330448627472\n",
      "Train Acc:99.10%, Test Acc:97.57%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1379823535680771\n",
      "Train Acc:99.50%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13652536273002625\n",
      "Train Acc:99.23%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.13030242919921875\n",
      "Train Acc:99.45%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12380668520927429\n",
      "Train Acc:99.56%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11410797387361526\n",
      "Train Acc:99.70%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.14267805218696594\n",
      "Train Acc:99.62%, Test Acc:96.68%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1022457405924797\n",
      "Train Acc:100.00%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.11268606036901474\n",
      "Train Acc:99.69%, Test Acc:97.77%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.10178079456090927\n",
      "Train Acc:99.77%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.12797637283802032\n",
      "Train Acc:99.76%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.11219677329063416\n",
      "Train Acc:99.84%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12077539414167404\n",
      "Train Acc:99.89%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.14364905655384064\n",
      "Train Acc:99.77%, Test Acc:98.27%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.09243347495794296\n",
      "Train Acc:99.80%, Test Acc:98.12%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.1254236400127411\n",
      "Train Acc:99.79%, Test Acc:97.92%\n",
      "\n",
      "\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.46534653465346 \n",
      "\n",
      "4\n",
      "Epoch: 0:200,  Loss:0.1942884773015976\n",
      "Train Acc:93.83%, Test Acc:96.59%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1209755688905716\n",
      "Train Acc:97.40%, Test Acc:97.10%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.12575745582580566\n",
      "Train Acc:98.41%, Test Acc:97.05%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.1885463148355484\n",
      "Train Acc:98.57%, Test Acc:97.86%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.1258462369441986\n",
      "Train Acc:99.19%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.126350998878479\n",
      "Train Acc:99.20%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14359787106513977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.27%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1950913816690445\n",
      "Train Acc:99.45%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11146356910467148\n",
      "Train Acc:99.57%, Test Acc:98.47%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.14711014926433563\n",
      "Train Acc:99.64%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.113343246281147\n",
      "Train Acc:99.72%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12928034365177155\n",
      "Train Acc:99.73%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.10810442268848419\n",
      "Train Acc:99.77%, Test Acc:98.22%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.13461264967918396\n",
      "Train Acc:99.82%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.12525875866413116\n",
      "Train Acc:99.83%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.14600667357444763\n",
      "Train Acc:99.77%, Test Acc:98.37%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.08760692924261093\n",
      "Train Acc:99.84%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1081419587135315\n",
      "Train Acc:99.89%, Test Acc:98.42%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.1541793942451477\n",
      "Train Acc:99.75%, Test Acc:98.73%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.10984005779027939\n",
      "Train Acc:100.00%, Test Acc:98.52%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1074351817369461\n",
      "Train Acc:99.91%, Test Acc:98.73%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.14575433731079102\n",
      "Train Acc:99.91%, Test Acc:98.78%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.083954356610775\n",
      "Train Acc:99.95%, Test Acc:98.57%\n",
      "\n",
      "\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 98.77800407331976 \n",
      "\n",
      "5\n",
      "Epoch: 0:200,  Loss:0.2653432786464691\n",
      "Train Acc:89.22%, Test Acc:92.49%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.18085817992687225\n",
      "Train Acc:94.11%, Test Acc:95.40%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.22077317535877228\n",
      "Train Acc:96.37%, Test Acc:96.19%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.16246886551380157\n",
      "Train Acc:97.44%, Test Acc:97.20%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.16317467391490936\n",
      "Train Acc:97.83%, Test Acc:97.48%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.18375374376773834\n",
      "Train Acc:98.16%, Test Acc:96.52%\n",
      "\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.15390074253082275\n",
      "Train Acc:98.57%, Test Acc:97.53%\n",
      "\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.18342651426792145\n",
      "Train Acc:98.81%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.11918728798627853\n",
      "Train Acc:99.19%, Test Acc:97.93%\n",
      "\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.1653881072998047\n",
      "Train Acc:99.11%, Test Acc:97.93%\n",
      "\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.1895546019077301\n",
      "Train Acc:99.67%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.17011955380439758\n",
      "Train Acc:98.62%, Test Acc:97.59%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.14244131743907928\n",
      "Train Acc:99.16%, Test Acc:97.87%\n",
      "\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.14232788980007172\n",
      "Train Acc:99.24%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.1428632289171219\n",
      "Train Acc:99.30%, Test Acc:97.53%\n",
      "\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.19023753702640533\n",
      "Train Acc:99.48%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.1283695548772812\n",
      "Train Acc:99.59%, Test Acc:97.42%\n",
      "\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.1343390792608261\n",
      "Train Acc:99.66%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.1733662486076355\n",
      "Train Acc:99.80%, Test Acc:97.31%\n",
      "\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.1050264835357666\n",
      "Train Acc:99.83%, Test Acc:97.25%\n",
      "\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.13140344619750977\n",
      "Train Acc:99.77%, Test Acc:97.59%\n",
      "\n",
      "\n",
      "Class: 5 -> Train Acc 99.82978723404256 ; Test Acc 97.92600896860986 \n",
      "\n",
      "6\n",
      "Epoch: 0:200,  Loss:0.21975171566009521\n",
      "Train Acc:95.09%, Test Acc:96.92%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.15290133655071259\n",
      "Train Acc:97.66%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.13201545178890228\n",
      "Train Acc:98.17%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.23125258088111877\n",
      "Train Acc:98.31%, Test Acc:98.64%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12622028589248657\n",
      "Train Acc:98.92%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1256931871175766\n",
      "Train Acc:99.47%, Test Acc:98.33%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13129252195358276\n",
      "Train Acc:99.03%, Test Acc:98.54%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14880673587322235\n",
      "Train Acc:99.08%, Test Acc:98.75%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.21152105927467346\n",
      "Train Acc:99.18%, Test Acc:98.38%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.12566490471363068\n",
      "Train Acc:99.54%, Test Acc:98.85%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14844170212745667\n",
      "Train Acc:99.46%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11350587755441666\n",
      "Train Acc:99.60%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.13516652584075928\n",
      "Train Acc:99.40%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.08306332677602768\n",
      "Train Acc:99.47%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1243082731962204\n",
      "Train Acc:99.55%, Test Acc:98.85%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.09841680526733398\n",
      "Train Acc:99.63%, Test Acc:98.17%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1040099635720253\n",
      "Train Acc:99.76%, Test Acc:98.96%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1320495903491974\n",
      "Train Acc:99.73%, Test Acc:98.70%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.13816772401332855\n",
      "Train Acc:99.50%, Test Acc:98.75%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.12540659308433533\n",
      "Train Acc:99.75%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1041460931301117\n",
      "Train Acc:99.70%, Test Acc:98.90%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.09659463167190552\n",
      "Train Acc:99.78%, Test Acc:98.80%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.13001559674739838\n",
      "Train Acc:99.88%, Test Acc:98.70%\n",
      "\n",
      "\n",
      "Class: 6 -> Train Acc 99.87628865979381 ; Test Acc 98.95615866388309 \n",
      "\n",
      "7\n",
      "Epoch: 0:200,  Loss:0.27841052412986755\n",
      "Train Acc:94.72%, Test Acc:96.94%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.19970981776714325\n",
      "Train Acc:97.89%, Test Acc:97.71%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.18252994120121002\n",
      "Train Acc:98.55%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.17395229637622833\n",
      "Train Acc:98.85%, Test Acc:98.35%\n",
      "\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.0873308777809143\n",
      "Train Acc:98.76%, Test Acc:97.76%\n",
      "\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.1079740971326828\n",
      "Train Acc:99.08%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12549486756324768\n",
      "Train Acc:99.27%, Test Acc:98.35%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.10918160527944565\n",
      "Train Acc:99.57%, Test Acc:98.44%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.12883906066417694\n",
      "Train Acc:99.40%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.11894822120666504\n",
      "Train Acc:99.52%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.1695152074098587\n",
      "Train Acc:99.66%, Test Acc:98.05%\n",
      "\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12374649941921234\n",
      "Train Acc:99.56%, Test Acc:98.30%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12817677855491638\n",
      "Train Acc:99.58%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.14169339835643768\n",
      "Train Acc:99.59%, Test Acc:98.39%\n",
      "\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.10039728134870529\n",
      "Train Acc:99.64%, Test Acc:97.81%\n",
      "\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.1316038817167282\n",
      "Train Acc:99.67%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.0883878543972969\n",
      "Train Acc:99.80%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.16316041350364685\n",
      "Train Acc:99.77%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.15016324818134308\n",
      "Train Acc:100.00%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.10201253741979599\n",
      "Train Acc:99.71%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.12771181762218475\n",
      "Train Acc:99.87%, Test Acc:98.25%\n",
      "\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.14596575498580933\n",
      "Train Acc:99.76%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.08972277492284775\n",
      "Train Acc:99.88%, Test Acc:98.30%\n",
      "\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.10538426041603088\n",
      "Train Acc:99.81%, Test Acc:98.10%\n",
      "\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.1100492849946022\n",
      "Train Acc:99.89%, Test Acc:98.20%\n",
      "\n",
      "\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.44357976653697 \n",
      "\n",
      "8\n",
      "Epoch: 0:200,  Loss:0.28693848848342896\n",
      "Train Acc:87.46%, Test Acc:91.17%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.17757894098758698\n",
      "Train Acc:92.12%, Test Acc:93.63%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.30962327122688293\n",
      "Train Acc:94.29%, Test Acc:91.79%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.1659069061279297\n",
      "Train Acc:94.97%, Test Acc:94.71%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.5102066993713379\n",
      "Train Acc:95.50%, Test Acc:94.30%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.11353139579296112\n",
      "Train Acc:96.80%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.25027263164520264\n",
      "Train Acc:96.28%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1976333111524582\n",
      "Train Acc:96.92%, Test Acc:95.79%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.14143520593643188\n",
      "Train Acc:97.12%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1587873101234436\n",
      "Train Acc:97.57%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.15649491548538208\n",
      "Train Acc:98.24%, Test Acc:96.51%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.14578481018543243\n",
      "Train Acc:98.52%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.16020254790782928\n",
      "Train Acc:98.80%, Test Acc:95.94%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.20853091776371002\n",
      "Train Acc:98.54%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.13930489122867584\n",
      "Train Acc:98.91%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.15137332677841187\n",
      "Train Acc:99.05%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.11882646381855011\n",
      "Train Acc:99.05%, Test Acc:96.56%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1670100837945938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.31%, Test Acc:96.30%\n",
      "\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.13254430890083313\n",
      "Train Acc:99.30%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.15160377323627472\n",
      "Train Acc:99.60%, Test Acc:96.20%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.14640316367149353\n",
      "Train Acc:99.41%, Test Acc:96.61%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.13230390846729279\n",
      "Train Acc:99.58%, Test Acc:96.46%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.13300004601478577\n",
      "Train Acc:99.70%, Test Acc:96.82%\n",
      "\n",
      "\n",
      "Class: 8 -> Train Acc 99.70370370370371 ; Test Acc 96.81724845995893 \n",
      "\n",
      "9\n",
      "Epoch: 0:200,  Loss:0.25558242201805115\n",
      "Train Acc:89.37%, Test Acc:92.77%\n",
      "\n",
      "\n",
      "Epoch: 1:400,  Loss:0.3021601736545563\n",
      "Train Acc:93.90%, Test Acc:93.95%\n",
      "\n",
      "\n",
      "Epoch: 2:600,  Loss:0.24361030757427216\n",
      "Train Acc:95.05%, Test Acc:94.90%\n",
      "\n",
      "\n",
      "Epoch: 3:800,  Loss:0.21518684923648834\n",
      "Train Acc:95.74%, Test Acc:94.55%\n",
      "\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.2558193504810333\n",
      "Train Acc:95.71%, Test Acc:95.14%\n",
      "\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.21317631006240845\n",
      "Train Acc:97.00%, Test Acc:95.09%\n",
      "\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.1474662572145462\n",
      "Train Acc:96.36%, Test Acc:95.19%\n",
      "\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.16789157688617706\n",
      "Train Acc:97.20%, Test Acc:95.24%\n",
      "\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.16784095764160156\n",
      "Train Acc:97.27%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.23495197296142578\n",
      "Train Acc:97.48%, Test Acc:95.64%\n",
      "\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.1686965376138687\n",
      "Train Acc:97.52%, Test Acc:95.39%\n",
      "\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.1322912871837616\n",
      "Train Acc:98.00%, Test Acc:95.14%\n",
      "\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.1451498121023178\n",
      "Train Acc:97.84%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.18508347868919373\n",
      "Train Acc:97.88%, Test Acc:94.55%\n",
      "\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1693272590637207\n",
      "Train Acc:97.99%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1751531958580017\n",
      "Train Acc:98.45%, Test Acc:95.44%\n",
      "\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.18300408124923706\n",
      "Train Acc:98.79%, Test Acc:95.74%\n",
      "\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.18110504746437073\n",
      "Train Acc:98.67%, Test Acc:95.69%\n",
      "\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1183856874704361\n",
      "Train Acc:98.29%, Test Acc:95.99%\n",
      "\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.15409910678863525\n",
      "Train Acc:98.55%, Test Acc:95.94%\n",
      "\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1327930986881256\n",
      "Train Acc:98.56%, Test Acc:95.74%\n",
      "\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.23475204408168793\n",
      "Train Acc:98.71%, Test Acc:95.59%\n",
      "\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.1514241099357605\n",
      "Train Acc:99.05%, Test Acc:95.79%\n",
      "\n",
      "\n",
      "Class: 9 -> Train Acc 99.05128205128206 ; Test Acc 95.98612487611497 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = ConvexNN([784,200,100,1], actf)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "        \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = sigmoid(Net(xx))\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print(\"\\n\")\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.59183673469387\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 99.0 ; Test Acc 98.11046511627907\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.46534653465346\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 98.77800407331976\n",
      "Class: 5 -> Train Acc 99.82978723404256 ; Test Acc 97.92600896860986\n",
      "Class: 6 -> Train Acc 99.87628865979381 ; Test Acc 98.95615866388309\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.44357976653697\n",
      "Class: 8 -> Train Acc 99.70370370370371 ; Test Acc 96.81724845995893\n",
      "Class: 9 -> Train Acc 99.05128205128206 ; Test Acc 95.98612487611497\n",
      "Total Accuracy (Argmax) is : 0.9660000205039978\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:200,  Loss:0.21731796860694885\n",
      "Train Acc:97.29%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.12151513993740082\n",
      "Train Acc:98.92%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.11258745193481445\n",
      "Train Acc:99.44%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11354289203882217\n",
      "Train Acc:99.73%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.1234457939863205\n",
      "Train Acc:99.73%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13944566249847412\n",
      "Train Acc:99.87%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.11360175162553787\n",
      "Train Acc:99.91%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.18856018781661987\n",
      "Train Acc:99.89%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.09785205125808716\n",
      "Train Acc:100.00%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1420046091079712\n",
      "Train Acc:99.96%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.09902246296405792\n",
      "Train Acc:99.94%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11073046922683716\n",
      "Train Acc:99.93%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12462783604860306\n",
      "Train Acc:99.98%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.08134999871253967\n",
      "Train Acc:99.99%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1232866495847702\n",
      "Train Acc:100.00%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1171824187040329\n",
      "Train Acc:99.71%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.11756277084350586\n",
      "Train Acc:99.90%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.10405978560447693\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.1250312775373459\n",
      "Train Acc:100.00%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.09437660872936249\n",
      "Train Acc:99.98%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09628170728683472\n",
      "Train Acc:100.00%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.06665828824043274\n",
      "Train Acc:99.84%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.09571699053049088\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062 \n",
      "\n",
      "1\n",
      "Epoch: 0:200,  Loss:0.11280658096075058\n",
      "Train Acc:97.72%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.13739743828773499\n",
      "Train Acc:99.22%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10042721033096313\n",
      "Train Acc:99.27%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 2:800,  Loss:0.1422419399023056\n",
      "Train Acc:99.37%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.12545478343963623\n",
      "Train Acc:99.60%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.10372818261384964\n",
      "Train Acc:99.72%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12780943512916565\n",
      "Train Acc:99.72%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.11142679303884506\n",
      "Train Acc:99.75%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.1020035445690155\n",
      "Train Acc:99.84%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.12312080711126328\n",
      "Train Acc:99.85%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.13604655861854553\n",
      "Train Acc:99.95%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.08337539434432983\n",
      "Train Acc:99.88%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.13039080798625946\n",
      "Train Acc:99.86%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.11987624317407608\n",
      "Train Acc:99.94%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.11296398937702179\n",
      "Train Acc:100.00%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.13903076946735382\n",
      "Train Acc:99.94%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.1057850643992424\n",
      "Train Acc:99.94%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.08330119401216507\n",
      "Train Acc:99.89%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.11049840599298477\n",
      "Train Acc:100.00%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.12739701569080353\n",
      "Train Acc:99.96%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.09945078194141388\n",
      "Train Acc:99.99%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.12603551149368286\n",
      "Train Acc:100.00%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.08994874358177185\n",
      "Train Acc:100.00%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.11847402900457382\n",
      "Train Acc:99.96%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.12035040557384491\n",
      "Train Acc:100.00%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.10556330531835556\n",
      "Train Acc:99.94%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.09094478189945221\n",
      "Train Acc:99.82%, Test Acc:99.25%\n",
      "\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.47136563876651 \n",
      "\n",
      "2\n",
      "Epoch: 0:200,  Loss:0.1684650480747223\n",
      "Train Acc:96.09%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.12850791215896606\n",
      "Train Acc:98.57%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.12702776491641998\n",
      "Train Acc:98.97%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.09711179882287979\n",
      "Train Acc:99.06%, Test Acc:98.06%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.16804620623588562\n",
      "Train Acc:99.55%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1257413923740387\n",
      "Train Acc:100.00%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12565919756889343\n",
      "Train Acc:99.64%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14851370453834534\n",
      "Train Acc:99.73%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.09349962323904037\n",
      "Train Acc:99.80%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11712131649255753\n",
      "Train Acc:99.98%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14417347311973572\n",
      "Train Acc:99.88%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12189299613237381\n",
      "Train Acc:99.60%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.1315024048089981\n",
      "Train Acc:99.78%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.12759016454219818\n",
      "Train Acc:99.78%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.10396552830934525\n",
      "Train Acc:99.82%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12977881729602814\n",
      "Train Acc:99.94%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13544465601444244\n",
      "Train Acc:99.96%, Test Acc:98.89%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14338910579681396\n",
      "Train Acc:99.87%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1589537113904953\n",
      "Train Acc:99.88%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.13581565022468567\n",
      "Train Acc:100.00%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12278570979833603\n",
      "Train Acc:99.96%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.12121792882680893\n",
      "Train Acc:99.82%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10366504639387131\n",
      "Train Acc:99.76%, Test Acc:99.03%\n",
      "\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798 \n",
      "\n",
      "3\n",
      "Epoch: 0:200,  Loss:0.1435774713754654\n",
      "Train Acc:94.09%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1256464123725891\n",
      "Train Acc:97.81%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.16631370782852173\n",
      "Train Acc:98.54%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.13129572570323944\n",
      "Train Acc:98.94%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12458263337612152\n",
      "Train Acc:99.25%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.17660072445869446\n",
      "Train Acc:99.18%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.10919982194900513\n",
      "Train Acc:99.48%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.09465283155441284\n",
      "Train Acc:99.58%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.10094752907752991\n",
      "Train Acc:99.67%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.10662947595119476\n",
      "Train Acc:99.62%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.15003475546836853\n",
      "Train Acc:99.55%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12275232374668121\n",
      "Train Acc:99.62%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12814965844154358\n",
      "Train Acc:99.76%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11584683507680893\n",
      "Train Acc:99.94%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.10709387809038162\n",
      "Train Acc:100.00%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.10648562759160995\n",
      "Train Acc:100.00%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.12555497884750366\n",
      "Train Acc:99.91%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.10103989392518997\n",
      "Train Acc:99.73%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.1310451626777649\n",
      "Train Acc:99.75%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.09903814643621445\n",
      "Train Acc:99.50%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.13354596495628357\n",
      "Train Acc:100.00%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.11327266693115234\n",
      "Train Acc:99.94%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.09847085177898407\n",
      "Train Acc:99.97%, Test Acc:98.76%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.1424856036901474\n",
      "Train Acc:99.92%, Test Acc:98.56%\n",
      "\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.76237623762376 \n",
      "\n",
      "4\n",
      "Epoch: 0:200,  Loss:0.1681768298149109\n",
      "Train Acc:95.36%, Test Acc:97.56%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.1408187448978424\n",
      "Train Acc:98.53%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.20413099229335785\n",
      "Train Acc:98.77%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11021895706653595\n",
      "Train Acc:99.47%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.13520574569702148\n",
      "Train Acc:99.75%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.13206472992897034\n",
      "Train Acc:99.73%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.10592928528785706\n",
      "Train Acc:99.65%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11278918385505676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.76%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11900530755519867\n",
      "Train Acc:99.95%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11467210948467255\n",
      "Train Acc:99.86%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10531017929315567\n",
      "Train Acc:99.66%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.09614083170890808\n",
      "Train Acc:99.97%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.12361001968383789\n",
      "Train Acc:99.92%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.10536752641201019\n",
      "Train Acc:99.88%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1102680116891861\n",
      "Train Acc:99.86%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12229945510625839\n",
      "Train Acc:99.91%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1066506952047348\n",
      "Train Acc:99.89%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1212250292301178\n",
      "Train Acc:99.84%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.10433226823806763\n",
      "Train Acc:100.00%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.12613998353481293\n",
      "Train Acc:100.00%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.10448730736970901\n",
      "Train Acc:99.97%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.1203690841794014\n",
      "Train Acc:99.90%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10706324875354767\n",
      "Train Acc:99.90%, Test Acc:98.78%\n",
      "\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.13441955193483 \n",
      "\n",
      "5\n",
      "Epoch: 0:200,  Loss:0.21822695434093475\n",
      "Train Acc:95.17%, Test Acc:97.09%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.23354953527450562\n",
      "Train Acc:98.38%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.16614586114883423\n",
      "Train Acc:98.95%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11451909691095352\n",
      "Train Acc:99.15%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.15433953702449799\n",
      "Train Acc:99.61%, Test Acc:97.31%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1350758969783783\n",
      "Train Acc:99.65%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.09992661327123642\n",
      "Train Acc:99.63%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.11335296928882599\n",
      "Train Acc:99.88%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.14044827222824097\n",
      "Train Acc:99.62%, Test Acc:98.77%\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.10905716568231583\n",
      "Train Acc:99.87%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.09525914490222931\n",
      "Train Acc:100.00%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.11986715346574783\n",
      "Train Acc:100.00%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.1282791942358017\n",
      "Train Acc:100.00%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.152114138007164\n",
      "Train Acc:99.82%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.14088626205921173\n",
      "Train Acc:99.64%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.12044303119182587\n",
      "Train Acc:99.79%, Test Acc:97.93%\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.12156578153371811\n",
      "Train Acc:99.97%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.11189134418964386\n",
      "Train Acc:100.00%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.08633020520210266\n",
      "Train Acc:99.98%, Test Acc:99.05%\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.12988026440143585\n",
      "Train Acc:100.00%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.10677160322666168\n",
      "Train Acc:100.00%, Test Acc:98.43%\n",
      "\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 99.04708520179372 \n",
      "\n",
      "6\n",
      "Epoch: 0:200,  Loss:0.13739946484565735\n",
      "Train Acc:96.22%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.11977182328701019\n",
      "Train Acc:98.98%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.140008345246315\n",
      "Train Acc:99.24%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.11301440000534058\n",
      "Train Acc:99.48%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.13390880823135376\n",
      "Train Acc:99.65%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.134500652551651\n",
      "Train Acc:99.87%, Test Acc:98.85%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13298209011554718\n",
      "Train Acc:99.78%, Test Acc:99.06%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.19217710196971893\n",
      "Train Acc:99.90%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11624495685100555\n",
      "Train Acc:99.86%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.134815976023674\n",
      "Train Acc:99.94%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10387366265058517\n",
      "Train Acc:99.97%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11400971561670303\n",
      "Train Acc:99.93%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.126582071185112\n",
      "Train Acc:99.97%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11414030194282532\n",
      "Train Acc:99.72%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.08717513829469681\n",
      "Train Acc:99.88%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12429003417491913\n",
      "Train Acc:99.78%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.12219688296318054\n",
      "Train Acc:99.98%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12916158139705658\n",
      "Train Acc:99.91%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.09990602731704712\n",
      "Train Acc:100.00%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.08749870210886002\n",
      "Train Acc:99.96%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12428361177444458\n",
      "Train Acc:99.98%, Test Acc:99.37%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.0785265862941742\n",
      "Train Acc:99.99%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.11814793944358826\n",
      "Train Acc:99.98%, Test Acc:99.16%\n",
      "\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.37369519832986 \n",
      "\n",
      "7\n",
      "Epoch: 0:200,  Loss:0.23387159407138824\n",
      "Train Acc:96.23%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.11251360177993774\n",
      "Train Acc:98.43%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.11175388097763062\n",
      "Train Acc:99.08%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.10608258843421936\n",
      "Train Acc:98.98%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.10791030526161194\n",
      "Train Acc:99.23%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.16897809505462646\n",
      "Train Acc:99.69%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.1307210475206375\n",
      "Train Acc:99.66%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.11966505646705627\n",
      "Train Acc:99.81%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.1049933210015297\n",
      "Train Acc:100.00%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.1245899423956871\n",
      "Train Acc:99.80%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.11917341500520706\n",
      "Train Acc:99.77%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.12248314172029495\n",
      "Train Acc:99.76%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.10068156570196152\n",
      "Train Acc:99.73%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.09575080126523972\n",
      "Train Acc:100.00%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.10259188711643219\n",
      "Train Acc:99.96%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.11519908159971237\n",
      "Train Acc:99.77%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.08855472505092621\n",
      "Train Acc:99.96%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.13204488158226013\n",
      "Train Acc:99.95%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.09479755163192749\n",
      "Train Acc:99.94%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.1319633573293686\n",
      "Train Acc:99.90%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.1189202293753624\n",
      "Train Acc:99.91%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.07868298143148422\n",
      "Train Acc:99.94%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.1193457767367363\n",
      "Train Acc:99.76%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.0858602225780487\n",
      "Train Acc:99.94%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.1218176856637001\n",
      "Train Acc:99.99%, Test Acc:98.54%\n",
      "\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.92996108949417 \n",
      "\n",
      "8\n",
      "Epoch: 0:200,  Loss:0.22651809453964233\n",
      "Train Acc:92.04%, Test Acc:96.82%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.19030813872814178\n",
      "Train Acc:97.18%, Test Acc:97.18%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10521306842565536\n",
      "Train Acc:98.68%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.09464947879314423\n",
      "Train Acc:98.57%, Test Acc:96.36%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.12465474754571915\n",
      "Train Acc:99.07%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.14757469296455383\n",
      "Train Acc:99.68%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.17273205518722534\n",
      "Train Acc:99.36%, Test Acc:98.00%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.13638873398303986\n",
      "Train Acc:99.39%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.11655915528535843\n",
      "Train Acc:99.69%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.11591080576181412\n",
      "Train Acc:99.60%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.14664477109909058\n",
      "Train Acc:99.86%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12127891182899475\n",
      "Train Acc:99.64%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.1178317666053772\n",
      "Train Acc:99.73%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.1195024698972702\n",
      "Train Acc:99.71%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1601637452840805\n",
      "Train Acc:99.72%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1264120191335678\n",
      "Train Acc:99.56%, Test Acc:98.82%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1459723711013794\n",
      "Train Acc:99.55%, Test Acc:98.41%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.1323627531528473\n",
      "Train Acc:99.65%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.10712697356939316\n",
      "Train Acc:99.70%, Test Acc:98.67%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.13125507533550262\n",
      "Train Acc:100.00%, Test Acc:98.72%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17:4200,  Loss:0.111699178814888\n",
      "Train Acc:99.85%, Test Acc:97.95%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.09885604679584503\n",
      "Train Acc:99.87%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.10521125793457031\n",
      "Train Acc:99.93%, Test Acc:98.61%\n",
      "\n",
      "Class: 8 -> Train Acc 100.0 ; Test Acc 98.81930184804928 \n",
      "\n",
      "9\n",
      "Epoch: 0:200,  Loss:0.16223327815532684\n",
      "Train Acc:92.94%, Test Acc:96.78%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.13000811636447906\n",
      "Train Acc:97.56%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.10350021719932556\n",
      "Train Acc:98.37%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.17198461294174194\n",
      "Train Acc:98.88%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.11707755923271179\n",
      "Train Acc:99.17%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.12492135167121887\n",
      "Train Acc:99.40%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14391696453094482\n",
      "Train Acc:99.33%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.12057922035455704\n",
      "Train Acc:99.63%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.14173611998558044\n",
      "Train Acc:99.58%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.09312642365694046\n",
      "Train Acc:99.79%, Test Acc:98.46%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10936691612005234\n",
      "Train Acc:99.69%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11137087643146515\n",
      "Train Acc:99.80%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12472636997699738\n",
      "Train Acc:99.81%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.1349581480026245\n",
      "Train Acc:99.86%, Test Acc:98.86%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.08916818350553513\n",
      "Train Acc:99.90%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12470358610153198\n",
      "Train Acc:99.81%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13914890587329865\n",
      "Train Acc:99.91%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12555952370166779\n",
      "Train Acc:99.80%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.10935596376657486\n",
      "Train Acc:99.76%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.12687718868255615\n",
      "Train Acc:99.68%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.09335409849882126\n",
      "Train Acc:99.77%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.11881924420595169\n",
      "Train Acc:99.83%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.1114954873919487\n",
      "Train Acc:99.90%, Test Acc:98.41%\n",
      "\n",
      "Class: 9 -> Train Acc 99.91176470588236 ; Test Acc 98.86025768087215 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = nn.Sequential(nn.Linear(784, 200),\n",
    "                       actf(),\n",
    "                       nn.Linear(200,100),\n",
    "                       actf(),\n",
    "                       nn.Linear(100,1))\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = sigmoid(Net(xx))\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.47136563876651\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798\n",
      "Class: 3 -> Train Acc 100.0 ; Test Acc 98.76237623762376\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.13441955193483\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 99.04708520179372\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.37369519832986\n",
      "Class: 7 -> Train Acc 100.0 ; Test Acc 98.92996108949417\n",
      "Class: 8 -> Train Acc 100.0 ; Test Acc 98.81930184804928\n",
      "Class: 9 -> Train Acc 99.91176470588236 ; Test Acc 98.86025768087215\n",
      "Total Accuracy (Argmax) is : 0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invex (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_mixup = True\n",
    "\n",
    "use_check = False\n",
    "check_every = 2\n",
    "check_size = 100\n",
    "\n",
    "m_,s_ = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:237,  Loss:0.12104102969169617, MinVal:0.20007428526878357, gp: 2.4546026907046326e-05\n",
      "Train Acc:95.12%, Test Acc:99.29%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.15531833469867706, MinVal:0.40670931339263916, gp: 7.073840180282787e-09\n",
      "Train Acc:99.12%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.14841140806674957, MinVal:0.33301666378974915, gp: 1.918551788548939e-07\n",
      "Train Acc:99.47%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 3:948,  Loss:0.16003890335559845, MinVal:0.3883458971977234, gp: 1.3284091160414846e-08\n",
      "Train Acc:99.67%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.10901155322790146, MinVal:0.4834924042224884, gp: 2.981085378550574e-10\n",
      "Train Acc:99.76%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.1428469717502594, MinVal:0.5995229482650757, gp: 3.5862903358802045e-12\n",
      "Train Acc:99.83%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.10806393623352051, MinVal:0.5254332423210144, gp: 5.528042607005901e-11\n",
      "Train Acc:99.92%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.11802355200052261, MinVal:0.38442763686180115, gp: 1.5525429830631765e-08\n",
      "Train Acc:99.99%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.11806728690862656, MinVal:0.6914311051368713, gp: 7.301727581940365e-14\n",
      "Train Acc:100.00%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.08808096498250961, MinVal:0.9566757678985596, gp: 3.1297639926377945e-18\n",
      "Train Acc:99.86%, Test Acc:99.54%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.11831024289131165, MinVal:0.2072744518518448, gp: 1.6636944565107115e-05\n",
      "Train Acc:99.94%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.13681869208812714, MinVal:0.3203776776790619, gp: 2.534707448376139e-07\n",
      "Train Acc:99.85%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.07499103248119354, MinVal:0.5243064761161804, gp: 6.016905029770925e-11\n",
      "Train Acc:99.90%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.10310328006744385, MinVal:0.29307177662849426, gp: 6.406176566997601e-07\n",
      "Train Acc:99.91%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.09052112698554993, MinVal:0.7130179405212402, gp: 3.0472728561412726e-14\n",
      "Train Acc:99.98%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.09382501989603043, MinVal:0.8967036008834839, gp: 1.9631963859921187e-17\n",
      "Train Acc:99.97%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.09273158758878708, MinVal:0.508712112903595, gp: 1.0788128723682178e-10\n",
      "Train Acc:99.95%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.10009707510471344, MinVal:0.9225433468818665, gp: 1.2417603095602162e-17\n",
      "Train Acc:99.97%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11895333975553513, MinVal:1.3878813982009888, gp: 9.602335413092902e-26\n",
      "Train Acc:99.88%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.12047312408685684, MinVal:1.3464715480804443, gp: 3.0178278220443732e-25\n",
      "Train Acc:99.76%, Test Acc:99.49%\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062 \n",
      "\n",
      "1\n",
      "Epoch: 0:270,  Loss:0.11417754739522934, MinVal:0.9134758710861206, gp: 2.861177041534785e-17\n",
      "Train Acc:96.99%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 1:540,  Loss:0.18683898448944092, MinVal:0.8235716819763184, gp: 8.338977955829911e-16\n",
      "Train Acc:99.20%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 2:810,  Loss:0.1116795763373375, MinVal:1.044044017791748, gp: 1.5970451049804318e-19\n",
      "Train Acc:99.44%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 3:1080,  Loss:0.12642154097557068, MinVal:0.5232222676277161, gp: 8.24999998871867e-11\n",
      "Train Acc:99.62%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 4:1350,  Loss:0.11160744726657867, MinVal:0.792725145816803, gp: 2.871568110859456e-15\n",
      "Train Acc:99.64%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 5:1620,  Loss:0.10325624793767929, MinVal:0.3146011233329773, gp: 3.392303824512055e-07\n",
      "Train Acc:99.81%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 6:1890,  Loss:0.06590598821640015, MinVal:0.8813419342041016, gp: 6.158421864439355e-17\n",
      "Train Acc:99.78%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 7:2160,  Loss:0.10174931585788727, MinVal:0.8588230013847351, gp: 1.565332503695912e-16\n",
      "Train Acc:99.80%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 8:2430,  Loss:0.0964931845664978, MinVal:0.8534197807312012, gp: 1.6979785249804255e-16\n",
      "Train Acc:99.90%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 9:2700,  Loss:0.12266232073307037, MinVal:0.46877437829971313, gp: 7.208780239409407e-10\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 10:2970,  Loss:0.08475199341773987, MinVal:0.6796404719352722, gp: 1.83753511538709e-13\n",
      "Train Acc:99.86%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 11:3240,  Loss:0.11421090364456177, MinVal:0.6815885305404663, gp: 2.0254136638264003e-13\n",
      "Train Acc:99.91%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 12:3510,  Loss:0.0992351695895195, MinVal:0.5583353042602539, gp: 3.766970416152482e-11\n",
      "Train Acc:99.96%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 13:3780,  Loss:0.1138167753815651, MinVal:0.3583641052246094, gp: 5.9558413312288394e-08\n",
      "Train Acc:99.89%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 14:4050,  Loss:0.09774736315011978, MinVal:0.6200100779533386, gp: 1.733426119657211e-12\n",
      "Train Acc:99.86%, Test Acc:99.56%\n",
      "\n",
      "Epoch: 15:4320,  Loss:0.136495441198349, MinVal:0.5030361413955688, gp: 2.4695095968141345e-10\n",
      "Train Acc:99.90%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 16:4590,  Loss:0.13127295672893524, MinVal:0.3009015619754791, gp: 5.865888965672639e-07\n",
      "Train Acc:99.97%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 17:4860,  Loss:0.09836218506097794, MinVal:0.2261144518852234, gp: 1.2646547475014813e-05\n",
      "Train Acc:99.99%, Test Acc:99.47%\n",
      "\n",
      "Epoch: 18:5130,  Loss:0.14059771597385406, MinVal:0.2752749025821686, gp: 2.098715413012542e-06\n",
      "Train Acc:99.96%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.1314781904220581, MinVal:0.3090417683124542, gp: 4.297059774671652e-07\n",
      "Train Acc:99.96%, Test Acc:99.43%\n",
      "\n",
      "Class: 1 -> Train Acc 99.98516760605162 ; Test Acc 99.55947136563876 \n",
      "\n",
      "2\n",
      "Epoch: 0:239,  Loss:0.1820642054080963, MinVal:0.39507922530174255, gp: 3.0871294853795916e-08\n",
      "Train Acc:93.92%, Test Acc:95.98%\n",
      "\n",
      "Epoch: 1:478,  Loss:0.11478608846664429, MinVal:0.46836525201797485, gp: 1.897499490866039e-09\n",
      "Train Acc:98.22%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 2:717,  Loss:0.13785207271575928, MinVal:0.9677907824516296, gp: 3.3095808568927876e-18\n",
      "Train Acc:98.86%, Test Acc:97.53%\n",
      "\n",
      "Epoch: 3:956,  Loss:0.08516976237297058, MinVal:0.24044650793075562, gp: 1.3380787095229607e-05\n",
      "Train Acc:99.12%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 4:1195,  Loss:0.1409170925617218, MinVal:0.4457988739013672, gp: 3.8491649867467e-09\n",
      "Train Acc:99.35%, Test Acc:97.72%\n",
      "\n",
      "Epoch: 5:1434,  Loss:0.1805400252342224, MinVal:0.2179221212863922, gp: 3.8418598705902696e-05\n",
      "Train Acc:99.54%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 6:1673,  Loss:0.15485289692878723, MinVal:0.7904204726219177, gp: 3.962125783306446e-15\n",
      "Train Acc:99.44%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 7:1912,  Loss:0.16616275906562805, MinVal:1.3034194707870483, gp: 4.85540297846414e-24\n",
      "Train Acc:99.62%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 8:2151,  Loss:0.18751958012580872, MinVal:1.4685001373291016, gp: 6.626000195548956e-27\n",
      "Train Acc:99.64%, Test Acc:98.45%\n",
      "\n",
      "Epoch: 9:2390,  Loss:0.15421181917190552, MinVal:0.6193053722381592, gp: 6.490493472538494e-12\n",
      "Train Acc:99.60%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 10:2629,  Loss:0.10447905957698822, MinVal:0.4584362208843231, gp: 2.316124847467904e-09\n",
      "Train Acc:99.73%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 11:2868,  Loss:0.18943557143211365, MinVal:0.486440509557724, gp: 8.172754695223716e-10\n",
      "Train Acc:99.82%, Test Acc:98.45%\n",
      "\n",
      "Epoch: 12:3107,  Loss:0.16569244861602783, MinVal:0.46653664112091064, gp: 1.78762082914119e-09\n",
      "Train Acc:99.69%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 13:3346,  Loss:0.0645274817943573, MinVal:0.41722938418388367, gp: 1.3628357109496392e-08\n",
      "Train Acc:99.82%, Test Acc:98.40%\n",
      "\n",
      "Epoch: 14:3585,  Loss:0.13228201866149902, MinVal:0.4872360825538635, gp: 1.0581507892126751e-09\n",
      "Train Acc:99.88%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 15:3824,  Loss:0.07640483230352402, MinVal:0.4175553619861603, gp: 1.7693434273269304e-08\n",
      "Train Acc:99.87%, Test Acc:98.74%\n",
      "\n",
      "Epoch: 16:4063,  Loss:0.09342578053474426, MinVal:0.40067172050476074, gp: 2.3713138119774158e-08\n",
      "Train Acc:99.96%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 17:4302,  Loss:0.12111686915159225, MinVal:0.556755542755127, gp: 7.523483225302385e-11\n",
      "Train Acc:99.94%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 18:4541,  Loss:0.1363493651151657, MinVal:0.44373106956481934, gp: 4.2070960049045425e-09\n",
      "Train Acc:99.71%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 19:4780,  Loss:0.11228346824645996, MinVal:0.549945592880249, gp: 7.928077638830189e-11\n",
      "Train Acc:99.75%, Test Acc:98.69%\n",
      "\n",
      "Class: 2 -> Train Acc 99.95803961060759 ; Test Acc 98.98255813953489 \n",
      "\n",
      "3\n",
      "Epoch: 0:246,  Loss:0.08757055550813675, MinVal:1.0613924264907837, gp: 1.0814117303878451e-19\n",
      "Train Acc:92.81%, Test Acc:96.24%\n",
      "\n",
      "Epoch: 1:492,  Loss:0.17288927733898163, MinVal:0.7505826950073242, gp: 2.6228395540520144e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.33%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 2:738,  Loss:0.2579522430896759, MinVal:0.9157487154006958, gp: 3.522387172901498e-17\n",
      "Train Acc:98.33%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 3:984,  Loss:0.0866110697388649, MinVal:1.067868947982788, gp: 8.058648790258751e-20\n",
      "Train Acc:98.50%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 4:1230,  Loss:0.08276137709617615, MinVal:1.4664192199707031, gp: 9.542370428716439e-27\n",
      "Train Acc:99.09%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 5:1476,  Loss:0.06854762881994247, MinVal:0.9897899031639099, gp: 1.8174632507231894e-18\n",
      "Train Acc:99.31%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 6:1722,  Loss:0.11424312740564346, MinVal:0.7926135063171387, gp: 4.839157249420705e-15\n",
      "Train Acc:99.53%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 7:1968,  Loss:0.13340745866298676, MinVal:0.6408939361572266, gp: 3.2939872617737675e-12\n",
      "Train Acc:99.76%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 8:2214,  Loss:0.11985883861780167, MinVal:0.9218805432319641, gp: 3.0532831213553254e-17\n",
      "Train Acc:99.68%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 9:2460,  Loss:0.09526341408491135, MinVal:0.6121306419372559, gp: 8.694459215086159e-12\n",
      "Train Acc:99.63%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 10:2706,  Loss:0.16848285496234894, MinVal:0.710889458656311, gp: 1.2862394526205745e-13\n",
      "Train Acc:99.71%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 11:2952,  Loss:0.1182451844215393, MinVal:0.7233850359916687, gp: 7.716537912122456e-14\n",
      "Train Acc:99.81%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 12:3198,  Loss:0.10049854964017868, MinVal:0.5914279222488403, gp: 1.5125142457939056e-11\n",
      "Train Acc:99.80%, Test Acc:98.61%\n",
      "\n",
      "Epoch: 13:3444,  Loss:0.0893341675400734, MinVal:0.8625127673149109, gp: 3.399483353999389e-16\n",
      "Train Acc:99.72%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 14:3690,  Loss:0.026187798008322716, MinVal:0.5819549560546875, gp: 2.209303573419419e-11\n",
      "Train Acc:99.77%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 15:3936,  Loss:0.06401387602090836, MinVal:0.9148613214492798, gp: 3.644912804827548e-17\n",
      "Train Acc:99.83%, Test Acc:98.56%\n",
      "\n",
      "Epoch: 16:4182,  Loss:0.021639004349708557, MinVal:1.2216323614120483, gp: 1.707923365957624e-22\n",
      "Train Acc:99.88%, Test Acc:98.66%\n",
      "\n",
      "Epoch: 17:4428,  Loss:0.0894574299454689, MinVal:1.257363200187683, gp: 4.086716954235884e-23\n",
      "Train Acc:99.93%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 18:4674,  Loss:0.08344393968582153, MinVal:1.228719711303711, gp: 2.382767364647784e-22\n",
      "Train Acc:99.96%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 19:4920,  Loss:0.21368373930454254, MinVal:0.5064894556999207, gp: 4.596315827942732e-10\n",
      "Train Acc:99.89%, Test Acc:98.12%\n",
      "\n",
      "Class: 3 -> Train Acc 99.95922361768064 ; Test Acc 98.7128712871287 \n",
      "\n",
      "4\n",
      "Epoch: 0:234,  Loss:0.1376389116048813, MinVal:0.4892598092556, gp: 3.1778515929836715e-10\n",
      "Train Acc:94.67%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 1:468,  Loss:0.11606220155954361, MinVal:0.3939242660999298, gp: 1.4362583122817796e-08\n",
      "Train Acc:98.28%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 2:702,  Loss:0.17235104739665985, MinVal:0.18529359996318817, gp: 5.46864430361893e-05\n",
      "Train Acc:98.95%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 3:936,  Loss:0.18634279072284698, MinVal:0.43033674359321594, gp: 5.318308460289245e-09\n",
      "Train Acc:99.33%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 4:1170,  Loss:0.11108372360467911, MinVal:0.20376211404800415, gp: 2.5725854357006028e-05\n",
      "Train Acc:99.33%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 5:1404,  Loss:0.11979851871728897, MinVal:0.3427588939666748, gp: 1.150427877405491e-07\n",
      "Train Acc:99.51%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 6:1638,  Loss:0.09552671015262604, MinVal:0.4102053642272949, gp: 7.754483277722102e-09\n",
      "Train Acc:99.70%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 7:1872,  Loss:0.0930260494351387, MinVal:0.4739093780517578, gp: 1.2561635065466703e-09\n",
      "Train Acc:99.71%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 8:2106,  Loss:0.1182083934545517, MinVal:0.4683852195739746, gp: 8.088660297111971e-10\n",
      "Train Acc:99.80%, Test Acc:98.68%\n",
      "\n",
      "Epoch: 9:2340,  Loss:0.18024520576000214, MinVal:0.36279433965682983, gp: 4.983678181247342e-08\n",
      "Train Acc:99.79%, Test Acc:98.68%\n",
      "\n",
      "Epoch: 10:2574,  Loss:0.14035402238368988, MinVal:0.6628997921943665, gp: 7.928526541897685e-13\n",
      "Train Acc:99.85%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 11:2808,  Loss:0.1324768364429474, MinVal:0.4296874403953552, gp: 3.4410148064267787e-09\n",
      "Train Acc:99.83%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 12:3042,  Loss:0.09849759936332703, MinVal:0.4863131046295166, gp: 3.5813124688033326e-10\n",
      "Train Acc:99.87%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 13:3276,  Loss:0.08560661971569061, MinVal:0.4536130726337433, gp: 2.203241145082302e-09\n",
      "Train Acc:99.81%, Test Acc:98.68%\n",
      "\n",
      "Epoch: 14:3510,  Loss:0.14578509330749512, MinVal:0.42964842915534973, gp: 3.5490890226697047e-09\n",
      "Train Acc:99.83%, Test Acc:98.57%\n",
      "\n",
      "Epoch: 15:3744,  Loss:0.09256594628095627, MinVal:0.47471535205841064, gp: 6.031454780064394e-10\n",
      "Train Acc:99.91%, Test Acc:98.98%\n",
      "\n",
      "Epoch: 16:3978,  Loss:0.13939324021339417, MinVal:0.4275989830493927, gp: 3.765648681763878e-09\n",
      "Train Acc:99.97%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 17:4212,  Loss:0.09465555846691132, MinVal:1.0663806200027466, gp: 2.9993872741553955e-20\n",
      "Train Acc:99.67%, Test Acc:98.52%\n",
      "\n",
      "Epoch: 18:4446,  Loss:0.14598265290260315, MinVal:0.6786147952079773, gp: 2.1789869713260968e-13\n",
      "Train Acc:99.77%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 19:4680,  Loss:0.11115565896034241, MinVal:0.5594217777252197, gp: 2.818692675099488e-11\n",
      "Train Acc:99.89%, Test Acc:98.78%\n",
      "\n",
      "Class: 4 -> Train Acc 99.9743238616912 ; Test Acc 99.13441955193483 \n",
      "\n",
      "5\n",
      "Epoch: 0:217,  Loss:0.15758800506591797, MinVal:0.8624125123023987, gp: 9.906606183510678e-17\n",
      "Train Acc:92.37%, Test Acc:97.65%\n",
      "\n",
      "Epoch: 1:434,  Loss:0.16341836750507355, MinVal:0.4283501207828522, gp: 4.362581407235666e-09\n",
      "Train Acc:97.95%, Test Acc:98.21%\n",
      "\n",
      "Epoch: 2:651,  Loss:0.09837363660335541, MinVal:0.3474361300468445, gp: 7.432853976752085e-08\n",
      "Train Acc:98.56%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 3:868,  Loss:0.1316596269607544, MinVal:0.6126563549041748, gp: 4.381693358840311e-12\n",
      "Train Acc:99.24%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 4:1085,  Loss:0.11135745048522949, MinVal:0.4918249547481537, gp: 3.7846648037742625e-10\n",
      "Train Acc:99.43%, Test Acc:97.98%\n",
      "\n",
      "Epoch: 5:1302,  Loss:0.15911944210529327, MinVal:0.06880344450473785, gp: 0.0016621436225250363\n",
      "Train Acc:99.50%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 6:1519,  Loss:0.14004573225975037, MinVal:0.29594680666923523, gp: 7.651600526514812e-07\n",
      "Train Acc:99.70%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 7:1736,  Loss:0.10386979579925537, MinVal:0.15922126173973083, gp: 0.00015036218974273652\n",
      "Train Acc:99.87%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 8:1953,  Loss:0.0797654539346695, MinVal:0.24135826528072357, gp: 6.028744337527314e-06\n",
      "Train Acc:99.87%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 9:2170,  Loss:0.12901245057582855, MinVal:0.30444401502609253, gp: 5.885839300390217e-07\n",
      "Train Acc:99.84%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 10:2387,  Loss:0.11806164681911469, MinVal:0.24115656316280365, gp: 1.1024269042536616e-05\n",
      "Train Acc:99.82%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 11:2604,  Loss:0.12474808841943741, MinVal:0.21799613535404205, gp: 1.2365706425043754e-05\n",
      "Train Acc:99.83%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 12:2821,  Loss:0.12891611456871033, MinVal:0.3882181942462921, gp: 2.1965655960798358e-08\n",
      "Train Acc:99.83%, Test Acc:98.37%\n",
      "\n",
      "Epoch: 13:3038,  Loss:0.15270709991455078, MinVal:0.36151883006095886, gp: 1.1355078299857269e-07\n",
      "Train Acc:99.71%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 14:3255,  Loss:0.08408983051776886, MinVal:0.3307883143424988, gp: 5.062955779067124e-07\n",
      "Train Acc:99.82%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 15:3472,  Loss:0.09664778411388397, MinVal:0.347971111536026, gp: 1.3053525549366896e-07\n",
      "Train Acc:99.99%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 16:3689,  Loss:0.08836281299591064, MinVal:0.2525511384010315, gp: 6.782317086617695e-06\n",
      "Train Acc:99.98%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 17:3906,  Loss:0.1168135479092598, MinVal:0.3223634660243988, gp: 2.2939813959510502e-07\n",
      "Train Acc:100.00%, Test Acc:98.71%\n",
      "\n",
      "Epoch: 18:4123,  Loss:0.09556758403778076, MinVal:0.41981491446495056, gp: 4.40830039138973e-09\n",
      "Train Acc:99.71%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 19:4340,  Loss:0.12322495877742767, MinVal:0.45124396681785583, gp: 1.1893435125642782e-09\n",
      "Train Acc:99.91%, Test Acc:98.65%\n",
      "\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 98.71076233183857 \n",
      "\n",
      "6\n",
      "Epoch: 0:237,  Loss:0.1639200896024704, MinVal:0.6224480867385864, gp: 1.4636836664569386e-12\n",
      "Train Acc:96.11%, Test Acc:98.23%\n",
      "\n",
      "Epoch: 1:474,  Loss:0.1252259612083435, MinVal:0.8019399046897888, gp: 1.9699930180655566e-15\n",
      "Train Acc:98.99%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 2:711,  Loss:0.13410252332687378, MinVal:0.5184560418128967, gp: 9.463771433182444e-11\n",
      "Train Acc:99.44%, Test Acc:99.01%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:948,  Loss:0.1171061173081398, MinVal:0.8065006732940674, gp: 1.2391737323283751e-15\n",
      "Train Acc:99.65%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 4:1185,  Loss:0.13307207822799683, MinVal:0.6736098527908325, gp: 1.8935219603215259e-13\n",
      "Train Acc:99.76%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 5:1422,  Loss:0.10934246331453323, MinVal:0.367171049118042, gp: 3.948982296719805e-08\n",
      "Train Acc:99.83%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 6:1659,  Loss:0.17450660467147827, MinVal:0.9343262910842896, gp: 5.9458751590658944e-18\n",
      "Train Acc:99.82%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 7:1896,  Loss:0.15111902356147766, MinVal:0.6262035369873047, gp: 1.346725465520282e-12\n",
      "Train Acc:99.86%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 8:2133,  Loss:0.12530896067619324, MinVal:0.7280295491218567, gp: 2.135929440586458e-14\n",
      "Train Acc:99.88%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 9:2370,  Loss:0.1148197129368782, MinVal:0.7322417497634888, gp: 1.8047602258139395e-14\n",
      "Train Acc:99.97%, Test Acc:99.48%\n",
      "\n",
      "Epoch: 10:2607,  Loss:0.12849532067775726, MinVal:1.0373705625534058, gp: 9.03214149730107e-20\n",
      "Train Acc:99.99%, Test Acc:99.16%\n",
      "\n",
      "Epoch: 11:2844,  Loss:0.05622490122914314, MinVal:1.4269710779190063, gp: 1.683566452028075e-26\n",
      "Train Acc:99.97%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 12:3081,  Loss:0.09197407215833664, MinVal:0.6839932799339294, gp: 1.243289190133376e-13\n",
      "Train Acc:99.98%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 13:3318,  Loss:0.10695012658834457, MinVal:0.6661312580108643, gp: 2.5434873391488866e-13\n",
      "Train Acc:99.96%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 14:3555,  Loss:0.13178527355194092, MinVal:1.0797396898269653, gp: 1.658659979351917e-20\n",
      "Train Acc:99.85%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 15:3792,  Loss:0.1225159540772438, MinVal:0.5586274862289429, gp: 1.8738049306632476e-11\n",
      "Train Acc:99.97%, Test Acc:99.22%\n",
      "\n",
      "Epoch: 16:4029,  Loss:0.12244471907615662, MinVal:0.34650158882141113, gp: 1.69882483191941e-07\n",
      "Train Acc:99.97%, Test Acc:99.27%\n",
      "\n",
      "Epoch: 17:4266,  Loss:0.11319983005523682, MinVal:0.5052989721298218, gp: 1.5824731802727143e-10\n",
      "Train Acc:99.99%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 18:4503,  Loss:0.11041702330112457, MinVal:0.38861334323883057, gp: 1.684298744919488e-08\n",
      "Train Acc:100.00%, Test Acc:99.32%\n",
      "\n",
      "Epoch: 19:4740,  Loss:0.10791698098182678, MinVal:0.3559267520904541, gp: 6.183208256516082e-08\n",
      "Train Acc:99.97%, Test Acc:99.43%\n",
      "\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.47807933194154 \n",
      "\n",
      "7\n",
      "Epoch: 0:251,  Loss:0.12151302397251129, MinVal:1.0608646869659424, gp: 4.282276226448091e-20\n",
      "Train Acc:94.92%, Test Acc:97.23%\n",
      "\n",
      "Epoch: 1:502,  Loss:0.14672569930553436, MinVal:1.1445866823196411, gp: 2.3512285794393033e-21\n",
      "Train Acc:98.24%, Test Acc:97.23%\n",
      "\n",
      "Epoch: 2:753,  Loss:0.14114949107170105, MinVal:0.6741918921470642, gp: 2.2081106745581308e-13\n",
      "Train Acc:98.80%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 3:1004,  Loss:0.11456184089183807, MinVal:0.9472424983978271, gp: 5.78351904356613e-18\n",
      "Train Acc:98.99%, Test Acc:98.44%\n",
      "\n",
      "Epoch: 4:1255,  Loss:0.12349618971347809, MinVal:0.9341859817504883, gp: 6.729120073383168e-18\n",
      "Train Acc:99.41%, Test Acc:98.30%\n",
      "\n",
      "Epoch: 5:1506,  Loss:0.13857777416706085, MinVal:1.4557561874389648, gp: 5.984930146842366e-27\n",
      "Train Acc:99.47%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 6:1757,  Loss:0.13869105279445648, MinVal:1.2634812593460083, gp: 1.3071047335138565e-23\n",
      "Train Acc:99.63%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 7:2008,  Loss:0.12381967157125473, MinVal:0.3211055099964142, gp: 3.0045291055103007e-07\n",
      "Train Acc:99.66%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 8:2259,  Loss:0.07794448733329773, MinVal:1.1732861995697021, gp: 4.770381490697246e-22\n",
      "Train Acc:99.79%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 9:2510,  Loss:0.1152351051568985, MinVal:0.5285539031028748, gp: 7.484249331390913e-11\n",
      "Train Acc:99.82%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 10:2761,  Loss:0.12153489142656326, MinVal:1.0990554094314575, gp: 9.351372144552878e-21\n",
      "Train Acc:99.90%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 11:3012,  Loss:0.12082528322935104, MinVal:0.5114902853965759, gp: 2.0610819995159346e-10\n",
      "Train Acc:99.91%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 12:3263,  Loss:0.11115211993455887, MinVal:0.6531882882118225, gp: 5.6154505958389e-13\n",
      "Train Acc:99.91%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 13:3514,  Loss:0.10937079787254333, MinVal:0.4576159417629242, gp: 1.2807830351846405e-09\n",
      "Train Acc:99.91%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 14:3765,  Loss:0.09413520991802216, MinVal:0.5233079195022583, gp: 9.605984063743023e-11\n",
      "Train Acc:99.99%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 15:4016,  Loss:0.11921094357967377, MinVal:0.43015506863594055, gp: 3.8960297210621775e-09\n",
      "Train Acc:99.91%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 16:4267,  Loss:0.09619181603193283, MinVal:0.5201216340065002, gp: 1.0482203299799764e-10\n",
      "Train Acc:99.90%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 17:4518,  Loss:0.16405168175697327, MinVal:0.5140032768249512, gp: 2.0543582113230485e-10\n",
      "Train Acc:99.91%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 18:4769,  Loss:0.126776322722435, MinVal:0.4235774576663971, gp: 4.985368562415715e-09\n",
      "Train Acc:99.95%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 19:5020,  Loss:0.13009698688983917, MinVal:0.7303772568702698, gp: 4.4775374543042784e-14\n",
      "Train Acc:99.95%, Test Acc:98.74%\n",
      "\n",
      "Class: 7 -> Train Acc 99.99201915403033 ; Test Acc 98.88132295719845 \n",
      "\n",
      "8\n",
      "Epoch: 0:235,  Loss:0.3348391354084015, MinVal:1.7040836811065674, gp: 4.256603470542256e-30\n",
      "Train Acc:90.75%, Test Acc:96.46%\n",
      "\n",
      "Epoch: 1:470,  Loss:0.6415475010871887, MinVal:2.4853127002716064, gp: 1.5134023414708024e-43\n",
      "Train Acc:97.50%, Test Acc:97.79%\n",
      "\n",
      "Epoch: 2:705,  Loss:0.0667952448129654, MinVal:1.485923171043396, gp: 2.6236034593453563e-26\n",
      "Train Acc:98.09%, Test Acc:97.59%\n",
      "\n",
      "Epoch: 3:940,  Loss:0.011751178652048111, MinVal:0.8640974760055542, gp: 1.663863240708354e-15\n",
      "Train Acc:98.79%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 4:1175,  Loss:0.14257171750068665, MinVal:1.172027826309204, gp: 7.444434065901883e-21\n",
      "Train Acc:98.83%, Test Acc:97.38%\n",
      "\n",
      "Epoch: 5:1410,  Loss:0.27829739451408386, MinVal:1.4032440185546875, gp: 7.164445588054676e-25\n",
      "Train Acc:99.27%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 6:1645,  Loss:0.021871456876397133, MinVal:0.4665489196777344, gp: 1.3395495379597833e-08\n",
      "Train Acc:99.30%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 7:1880,  Loss:0.011641282588243484, MinVal:7.163778305053711, gp: 0.0\n",
      "Train Acc:99.31%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 8:2115,  Loss:0.10384523868560791, MinVal:1.5144171714782715, gp: 8.392804415327075e-27\n",
      "Train Acc:99.60%, Test Acc:98.25%\n",
      "\n",
      "Epoch: 9:2350,  Loss:0.04792565107345581, MinVal:0.6038145422935486, gp: 5.529392915759601e-11\n",
      "Train Acc:99.50%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 10:2585,  Loss:0.018648939207196236, MinVal:1.2281233072280884, gp: 7.894803314255658e-22\n",
      "Train Acc:99.45%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 11:2820,  Loss:0.016413984820246696, MinVal:1.3356086015701294, gp: 1.0718413258001647e-23\n",
      "Train Acc:99.65%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 12:3055,  Loss:0.025975871831178665, MinVal:0.9935540556907654, gp: 9.380517659565727e-18\n",
      "Train Acc:99.55%, Test Acc:97.84%\n",
      "\n",
      "Epoch: 13:3290,  Loss:0.021359950304031372, MinVal:1.828373908996582, gp: 2.9506656753486265e-32\n",
      "Train Acc:99.69%, Test Acc:98.20%\n",
      "\n",
      "Epoch: 14:3525,  Loss:0.0509054996073246, MinVal:2.7558300495147705, gp: 0.0\n",
      "Train Acc:99.70%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 15:3760,  Loss:0.07551871985197067, MinVal:1.5164469480514526, gp: 7.738334131253426e-27\n",
      "Train Acc:99.79%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 16:3995,  Loss:0.015499887056648731, MinVal:1.3954992294311523, gp: 9.868689367360119e-25\n",
      "Train Acc:99.74%, Test Acc:98.31%\n",
      "\n",
      "Epoch: 17:4230,  Loss:0.16789574921131134, MinVal:1.0684751272201538, gp: 4.685071890354273e-19\n",
      "Train Acc:99.85%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 18:4465,  Loss:0.021311284974217415, MinVal:0.8862075209617615, gp: 6.871112209885571e-16\n",
      "Train Acc:99.81%, Test Acc:98.00%\n",
      "\n",
      "Epoch: 19:4700,  Loss:0.016772229224443436, MinVal:1.938590407371521, gp: 5.641159277865252e-34\n",
      "Train Acc:99.84%, Test Acc:98.36%\n",
      "\n",
      "Class: 8 -> Train Acc 99.84618014014698 ; Test Acc 98.35728952772074 \n",
      "\n",
      "9\n",
      "Epoch: 0:238,  Loss:0.24021345376968384, MinVal:0.45277678966522217, gp: 9.796706779141573e-10\n",
      "Train Acc:91.56%, Test Acc:95.14%\n",
      "\n",
      "Epoch: 1:476,  Loss:0.18931804597377777, MinVal:0.7158143520355225, gp: 2.6466574429024475e-14\n",
      "Train Acc:97.18%, Test Acc:96.88%\n",
      "\n",
      "Epoch: 2:714,  Loss:0.17749129235744476, MinVal:0.954651951789856, gp: 1.9843320500547368e-18\n",
      "Train Acc:97.97%, Test Acc:96.93%\n",
      "\n",
      "Epoch: 3:952,  Loss:0.1599443256855011, MinVal:0.4732038080692291, gp: 4.375777795662117e-10\n",
      "Train Acc:98.52%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 4:1190,  Loss:0.16074831783771515, MinVal:0.5350167155265808, gp: 3.671087045464816e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.93%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 5:1428,  Loss:0.191964253783226, MinVal:0.6854758262634277, gp: 8.92496796953135e-14\n",
      "Train Acc:99.18%, Test Acc:96.93%\n",
      "\n",
      "Epoch: 6:1666,  Loss:0.15352167189121246, MinVal:0.7116934657096863, gp: 3.0837887853105844e-14\n",
      "Train Acc:99.48%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 7:1904,  Loss:0.1408618539571762, MinVal:0.5017245411872864, gp: 1.370228097652415e-10\n",
      "Train Acc:99.45%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 8:2142,  Loss:0.174640491604805, MinVal:0.4571504294872284, gp: 8.127520323419901e-10\n",
      "Train Acc:99.44%, Test Acc:96.88%\n",
      "\n",
      "Epoch: 9:2380,  Loss:0.09769801050424576, MinVal:0.46102654933929443, gp: 1.3471307402923571e-09\n",
      "Train Acc:99.51%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 10:2618,  Loss:0.1708209365606308, MinVal:0.4782849848270416, gp: 4.617541626839028e-10\n",
      "Train Acc:99.65%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 11:2856,  Loss:0.10379713773727417, MinVal:0.5849847197532654, gp: 5.180172263363758e-12\n",
      "Train Acc:99.69%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 12:3094,  Loss:0.11098400503396988, MinVal:0.4378759264945984, gp: 2.041806501651422e-09\n",
      "Train Acc:99.66%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 13:3332,  Loss:0.12907032668590546, MinVal:0.33918043971061707, gp: 1.2448415986909822e-07\n",
      "Train Acc:99.82%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 14:3570,  Loss:0.0994953140616417, MinVal:0.45335331559181213, gp: 2.743679949901434e-09\n",
      "Train Acc:99.66%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 15:3808,  Loss:0.1418127715587616, MinVal:0.20992837846279144, gp: 1.5841205822653137e-05\n",
      "Train Acc:99.55%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 16:4046,  Loss:0.144117072224617, MinVal:0.6158959865570068, gp: 1.5148221219063451e-12\n",
      "Train Acc:99.87%, Test Acc:98.27%\n",
      "\n",
      "Epoch: 17:4284,  Loss:0.1075025126338005, MinVal:0.4740535020828247, gp: 4.3624634460392997e-10\n",
      "Train Acc:99.90%, Test Acc:98.36%\n",
      "\n",
      "Epoch: 18:4522,  Loss:0.0952480286359787, MinVal:0.41767287254333496, gp: 3.955478611317176e-09\n",
      "Train Acc:99.95%, Test Acc:98.51%\n",
      "\n",
      "Epoch: 19:4760,  Loss:0.1352195292711258, MinVal:0.35573121905326843, gp: 5.4567426133189656e-08\n",
      "Train Acc:99.88%, Test Acc:98.27%\n",
      "\n",
      "Class: 9 -> Train Acc 99.94957135653051 ; Test Acc 98.51337958374629 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    lips_net = nn.Sequential(nn.Linear(784, 200),\n",
    "                       actf(),\n",
    "                       nn.Linear(200,100),\n",
    "                       actf(),\n",
    "                       nn.Linear(100,1))\n",
    "    Net = BasicInvexNet(784, lips_net, lambda_)\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if use_check and epoch%check_every == 0:\n",
    "                rand_inp = torch.rand(check_size, 784)*m_+s_\n",
    "                Net(rand_inp)\n",
    "                Net.compute_penalty_and_clipper()\n",
    "                Net.gp.backward(retain_graph=True)\n",
    "            \n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))   \n",
    "            Net.compute_penalty_and_clipper()\n",
    "            loss = criterion(yout, y_mix) + Net.gp\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             if index%200 == 0:\n",
    "        train_accs.append(float(train_acc)/train_count*100)\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "\n",
    "        min_val, gp = float(Net.cond.min()) , float(Net.gp)\n",
    "        print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}, MinVal:{min_val}, gp: {gp}')\n",
    "        test_count = 0\n",
    "        test_acc = 0\n",
    "        for xx, yy in test_loader:\n",
    "#                     with torch.no_grad():\n",
    "            yout = sigmoid(Net(xx))\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "            test_acc += correct\n",
    "            test_count += len(xx)\n",
    "        test_accs.append(float(test_acc)/test_count*100)\n",
    "        print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "        print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.54081632653062\n",
      "Class: 1 -> Train Acc 99.98516760605162 ; Test Acc 99.55947136563876\n",
      "Class: 2 -> Train Acc 99.95803961060759 ; Test Acc 98.98255813953489\n",
      "Class: 3 -> Train Acc 99.95922361768064 ; Test Acc 98.7128712871287\n",
      "Class: 4 -> Train Acc 99.9743238616912 ; Test Acc 99.13441955193483\n",
      "Class: 5 -> Train Acc 100.0 ; Test Acc 98.71076233183857\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.47807933194154\n",
      "Class: 7 -> Train Acc 99.99201915403033 ; Test Acc 98.88132295719845\n",
      "Class: 8 -> Train Acc 99.84618014014698 ; Test Acc 98.35728952772074\n",
      "Class: 9 -> Train Acc 99.94957135653051 ; Test Acc 98.51337958374629\n",
      "Total Accuracy (Argmax) is : 0.9746999740600586\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177985"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 100.0000% on 70000 input points\n",
      "Class: 1 -> Correct 99.9957% on 70000 input points\n",
      "Class: 2 -> Correct 99.9529% on 70000 input points\n",
      "Class: 3 -> Correct 99.9986% on 70000 input points\n",
      "Class: 4 -> Correct 99.9986% on 70000 input points\n",
      "Class: 5 -> Correct 100.0000% on 70000 input points\n",
      "Class: 6 -> Correct 99.9986% on 70000 input points\n",
      "Class: 7 -> Correct 100.0000% on 70000 input points\n",
      "Class: 8 -> Correct 100.0000% on 70000 input points\n",
      "Class: 9 -> Correct 100.0000% on 70000 input points\n"
     ]
    }
   ],
   "source": [
    "## only on training and testing data\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 706.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Correct 99.9951% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 708.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1 -> Correct 99.9997% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 696.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 2 -> Correct 93.0134% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 692.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 3 -> Correct 7.0199% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 701.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 4 -> Correct 99.9999% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:29<00:00, 677.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 5 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:29<00:00, 680.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 6 -> Correct 31.1949% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 690.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 7 -> Correct 88.7164% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:28<00:00, 711.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 8 -> Correct 99.9999% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 20000/20000 [00:29<00:00, 684.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 9 -> Correct 100.0000% on 1070000 input points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Check the constraint on large number of points, including training and test data.\n",
    "from tqdm import tqdm\n",
    "for class_idx in range(10):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    net = net_list[class_idx]\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "        \n",
    "    for index in range(len(train_label) // batch_size):\n",
    "        xx = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    for i in tqdm(range(20000)):\n",
    "        xx = torch.rand(batch_size, 784)\n",
    "        net(xx)\n",
    "        net.compute_penalty_and_clipper()\n",
    "        correct += (net.cond>0).type(torch.float32).sum()\n",
    "        count += len(xx)\n",
    "\n",
    "    print(f\"Class: {class_idx} -> Correct {correct/count*100:.4f}% on {count} input points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(10,4))\n",
    "for i in range(10):\n",
    "    invNet = net_list[i]\n",
    "    icenter = invNet.center.data\n",
    "    j, k = i//5, i%5\n",
    "#     print(i, j, k)\n",
    "    axs[j,k].imshow(icenter.data.cpu().reshape(28, 28))\n",
    "    axs[j,k].set_title(f\"{i}\")\n",
    "    axs[j,k].set_axis_off()\n",
    "# fig.tight_layout()\n",
    "plt.savefig(\"./invex_out/MNIST_BasicInvex_mlp_centroids.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invertible+Cone = Invex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflib.flows import SequentialFlow, ActNorm, ActNorm2D, AffineConstantFlow\n",
    "from nflib import coupling_flows as icf\n",
    "from nflib import res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import DistanceRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvexInvertible_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        actf = irf.LeakyReLU\n",
    "        flows = [\n",
    "            ActNorm(784),\n",
    "            irf.ResidualFlow(784, [200], activation=actf),\n",
    "            ActNorm(784),\n",
    "            irf.ResidualFlow(784, [100], activation=actf),\n",
    "            ActNorm(784),\n",
    "            DistanceRegressor(784)\n",
    "                ]\n",
    "        self.model = nn.Sequential(*flows)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0:200,  Loss:2.017425537109375\n",
      "Train Acc:50.35%, Test Acc:52.19%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.6552376747131348\n",
      "Train Acc:87.50%, Test Acc:95.51%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.2072739452123642\n",
      "Train Acc:96.78%, Test Acc:97.14%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.17310529947280884\n",
      "Train Acc:98.18%, Test Acc:98.01%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.16602550446987152\n",
      "Train Acc:99.12%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.16733378171920776\n",
      "Train Acc:99.47%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.12613587081432343\n",
      "Train Acc:99.15%, Test Acc:99.13%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.13674357533454895\n",
      "Train Acc:99.30%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.14135807752609253\n",
      "Train Acc:99.63%, Test Acc:98.88%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.13091380894184113\n",
      "Train Acc:99.62%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.09841427206993103\n",
      "Train Acc:99.79%, Test Acc:99.23%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.11937825381755829\n",
      "Train Acc:99.93%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.136350616812706\n",
      "Train Acc:99.78%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.13035541772842407\n",
      "Train Acc:99.89%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.10898475348949432\n",
      "Train Acc:99.95%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.14035989344120026\n",
      "Train Acc:99.95%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.11418278515338898\n",
      "Train Acc:100.00%, Test Acc:99.49%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14449986815452576\n",
      "Train Acc:99.96%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.12329304963350296\n",
      "Train Acc:100.00%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.0767289251089096\n",
      "Train Acc:99.97%, Test Acc:99.39%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.13682562112808228\n",
      "Train Acc:99.99%, Test Acc:99.44%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.10833118110895157\n",
      "Train Acc:99.99%, Test Acc:99.18%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.05893910303711891\n",
      "Train Acc:100.00%, Test Acc:99.29%\n",
      "\n",
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.48979591836735 \n",
      "\n",
      "1\n",
      "Epoch: 0:200,  Loss:0.47507452964782715\n",
      "Train Acc:55.56%, Test Acc:84.98%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.2998107969760895\n",
      "Train Acc:95.11%, Test Acc:97.58%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.20869116485118866\n",
      "Train Acc:98.17%, Test Acc:98.81%\n",
      "\n",
      "Epoch: 2:800,  Loss:0.18828792870044708\n",
      "Train Acc:98.23%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.16527502238750458\n",
      "Train Acc:98.80%, Test Acc:99.12%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.15391944348812103\n",
      "Train Acc:99.02%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.14248202741146088\n",
      "Train Acc:99.24%, Test Acc:98.99%\n",
      "\n",
      "Epoch: 5:1600,  Loss:0.16929511725902557\n",
      "Train Acc:99.26%, Test Acc:99.07%\n",
      "\n",
      "Epoch: 6:1800,  Loss:0.14390899240970612\n",
      "Train Acc:99.42%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.13501687347888947\n",
      "Train Acc:99.60%, Test Acc:99.25%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.12922044098377228\n",
      "Train Acc:99.80%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 8:2400,  Loss:0.13881908357143402\n",
      "Train Acc:99.63%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 9:2600,  Loss:0.10654770582914352\n",
      "Train Acc:99.66%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 10:2800,  Loss:0.11208924651145935\n",
      "Train Acc:99.90%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.1506509631872177\n",
      "Train Acc:99.67%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 11:3200,  Loss:0.08663684129714966\n",
      "Train Acc:99.81%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 12:3400,  Loss:0.1469683200120926\n",
      "Train Acc:99.86%, Test Acc:99.34%\n",
      "\n",
      "Epoch: 13:3600,  Loss:0.1294894814491272\n",
      "Train Acc:99.87%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 14:3800,  Loss:0.1027914434671402\n",
      "Train Acc:100.00%, Test Acc:99.52%\n",
      "\n",
      "Epoch: 14:4000,  Loss:0.14286042749881744\n",
      "Train Acc:99.85%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 15:4200,  Loss:0.10704374313354492\n",
      "Train Acc:99.96%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 16:4400,  Loss:0.05898052826523781\n",
      "Train Acc:99.90%, Test Acc:99.21%\n",
      "\n",
      "Epoch: 17:4600,  Loss:0.11143060028553009\n",
      "Train Acc:100.00%, Test Acc:99.43%\n",
      "\n",
      "Epoch: 17:4800,  Loss:0.13681726157665253\n",
      "Train Acc:99.92%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 18:5000,  Loss:0.12309083342552185\n",
      "Train Acc:99.94%, Test Acc:99.30%\n",
      "\n",
      "Epoch: 19:5200,  Loss:0.11148068308830261\n",
      "Train Acc:99.94%, Test Acc:99.38%\n",
      "\n",
      "Epoch: 19:5400,  Loss:0.12489578127861023\n",
      "Train Acc:99.93%, Test Acc:99.38%\n",
      "\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265 \n",
      "\n",
      "2\n",
      "Epoch: 0:200,  Loss:0.8335642218589783\n",
      "Train Acc:50.12%, Test Acc:50.00%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.2879284620285034\n",
      "Train Acc:80.29%, Test Acc:90.99%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.22243580222129822\n",
      "Train Acc:95.80%, Test Acc:95.16%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.25722840428352356\n",
      "Train Acc:97.42%, Test Acc:96.75%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.13315464556217194\n",
      "Train Acc:98.00%, Test Acc:97.38%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.15265542268753052\n",
      "Train Acc:97.60%, Test Acc:97.77%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.1455812007188797\n",
      "Train Acc:98.42%, Test Acc:98.01%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14095301926136017\n",
      "Train Acc:98.65%, Test Acc:98.01%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.16107802093029022\n",
      "Train Acc:98.85%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.12255110591650009\n",
      "Train Acc:99.34%, Test Acc:98.55%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.16359010338783264\n",
      "Train Acc:99.39%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.12049679458141327\n",
      "Train Acc:99.80%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.12040501832962036\n",
      "Train Acc:99.69%, Test Acc:98.50%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.09675820171833038\n",
      "Train Acc:99.57%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1305238902568817\n",
      "Train Acc:99.89%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12692390382289886\n",
      "Train Acc:99.91%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.135165274143219\n",
      "Train Acc:99.74%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.08482173085212708\n",
      "Train Acc:100.00%, Test Acc:98.64%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.10217027366161346\n",
      "Train Acc:99.97%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.12833534181118011\n",
      "Train Acc:99.93%, Test Acc:98.69%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.14423929154872894\n",
      "Train Acc:99.97%, Test Acc:98.84%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.09643153846263885\n",
      "Train Acc:100.00%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.1333252489566803\n",
      "Train Acc:100.00%, Test Acc:99.03%\n",
      "\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798 \n",
      "\n",
      "3\n",
      "Epoch: 0:200,  Loss:3.097482919692993\n",
      "Train Acc:49.96%, Test Acc:51.24%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.4785638451576233\n",
      "Train Acc:77.81%, Test Acc:88.71%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.37435752153396606\n",
      "Train Acc:92.52%, Test Acc:93.51%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.24657711386680603\n",
      "Train Acc:95.13%, Test Acc:95.45%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.19776304066181183\n",
      "Train Acc:95.38%, Test Acc:96.04%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.16484764218330383\n",
      "Train Acc:96.57%, Test Acc:96.24%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.18181030452251434\n",
      "Train Acc:97.21%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14904361963272095\n",
      "Train Acc:98.05%, Test Acc:97.33%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.17849498987197876\n",
      "Train Acc:98.05%, Test Acc:97.43%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.17668651044368744\n",
      "Train Acc:98.88%, Test Acc:96.93%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.15979231894016266\n",
      "Train Acc:98.41%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.13568302989006042\n",
      "Train Acc:98.89%, Test Acc:97.33%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.14637690782546997\n",
      "Train Acc:99.04%, Test Acc:97.67%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.12174946069717407\n",
      "Train Acc:99.49%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.12000802904367447\n",
      "Train Acc:99.50%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.13210374116897583\n",
      "Train Acc:96.00%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.13948169350624084\n",
      "Train Acc:99.79%, Test Acc:98.22%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.13127951323986053\n",
      "Train Acc:99.81%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.11664082854986191\n",
      "Train Acc:99.93%, Test Acc:98.12%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.11091962456703186\n",
      "Train Acc:99.84%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.15035299956798553\n",
      "Train Acc:99.89%, Test Acc:97.52%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.13110920786857605\n",
      "Train Acc:99.80%, Test Acc:97.57%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.11425739526748657\n",
      "Train Acc:99.65%, Test Acc:98.02%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.1395522654056549\n",
      "Train Acc:99.71%, Test Acc:98.32%\n",
      "\n",
      "Class: 3 -> Train Acc 99.92727272727274 ; Test Acc 98.31683168316832 \n",
      "\n",
      "4\n",
      "Epoch: 0:200,  Loss:0.8211427330970764\n",
      "Train Acc:50.20%, Test Acc:50.10%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.2916356325149536\n",
      "Train Acc:82.52%, Test Acc:91.34%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.21928513050079346\n",
      "Train Acc:95.64%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.16695915162563324\n",
      "Train Acc:97.29%, Test Acc:96.95%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.21238979697227478\n",
      "Train Acc:97.94%, Test Acc:97.56%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1599055975675583\n",
      "Train Acc:98.33%, Test Acc:97.66%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.20436455309391022\n",
      "Train Acc:98.54%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.15348686277866364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.97%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.10955020785331726\n",
      "Train Acc:99.35%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.1232694610953331\n",
      "Train Acc:99.62%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.11858807504177094\n",
      "Train Acc:99.70%, Test Acc:98.42%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.14607833325862885\n",
      "Train Acc:99.70%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.12774574756622314\n",
      "Train Acc:99.92%, Test Acc:98.83%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.11941848695278168\n",
      "Train Acc:99.74%, Test Acc:98.73%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.1337575912475586\n",
      "Train Acc:99.78%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.12724687159061432\n",
      "Train Acc:99.84%, Test Acc:98.47%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.13762296736240387\n",
      "Train Acc:99.95%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.09280382096767426\n",
      "Train Acc:99.78%, Test Acc:98.93%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.1346178650856018\n",
      "Train Acc:99.82%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.12188203632831573\n",
      "Train Acc:100.00%, Test Acc:98.63%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.10668226331472397\n",
      "Train Acc:99.97%, Test Acc:98.78%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.14068131148815155\n",
      "Train Acc:99.93%, Test Acc:99.03%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.12751315534114838\n",
      "Train Acc:99.97%, Test Acc:98.98%\n",
      "\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.03258655804481 \n",
      "\n",
      "5\n",
      "Epoch: 0:200,  Loss:1.9955496788024902\n",
      "Train Acc:50.12%, Test Acc:50.06%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.3757857382297516\n",
      "Train Acc:75.56%, Test Acc:89.24%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.26745760440826416\n",
      "Train Acc:93.51%, Test Acc:94.73%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.20618808269500732\n",
      "Train Acc:96.52%, Test Acc:97.09%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.21942715346813202\n",
      "Train Acc:97.79%, Test Acc:97.42%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.1636001020669937\n",
      "Train Acc:98.26%, Test Acc:97.20%\n",
      "\n",
      "Epoch: 6:1400,  Loss:0.1903594732284546\n",
      "Train Acc:98.47%, Test Acc:97.65%\n",
      "\n",
      "Epoch: 7:1600,  Loss:0.18919874727725983\n",
      "Train Acc:98.69%, Test Acc:97.93%\n",
      "\n",
      "Epoch: 8:1800,  Loss:0.16098590195178986\n",
      "Train Acc:99.16%, Test Acc:97.76%\n",
      "\n",
      "Epoch: 9:2000,  Loss:0.1266394555568695\n",
      "Train Acc:99.36%, Test Acc:98.15%\n",
      "\n",
      "Epoch: 10:2200,  Loss:0.14245013892650604\n",
      "Train Acc:99.80%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 11:2400,  Loss:0.1248561441898346\n",
      "Train Acc:99.69%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.14620336890220642\n",
      "Train Acc:99.68%, Test Acc:98.32%\n",
      "\n",
      "Epoch: 12:2800,  Loss:0.12449398636817932\n",
      "Train Acc:99.71%, Test Acc:98.26%\n",
      "\n",
      "Epoch: 13:3000,  Loss:0.13551369309425354\n",
      "Train Acc:99.79%, Test Acc:98.09%\n",
      "\n",
      "Epoch: 14:3200,  Loss:0.10273129492998123\n",
      "Train Acc:99.84%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 15:3400,  Loss:0.1510399878025055\n",
      "Train Acc:99.89%, Test Acc:98.49%\n",
      "\n",
      "Epoch: 16:3600,  Loss:0.10605909675359726\n",
      "Train Acc:99.89%, Test Acc:98.65%\n",
      "\n",
      "Epoch: 17:3800,  Loss:0.14503732323646545\n",
      "Train Acc:99.98%, Test Acc:98.60%\n",
      "\n",
      "Epoch: 18:4000,  Loss:0.11781775206327438\n",
      "Train Acc:99.81%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 19:4200,  Loss:0.12393075227737427\n",
      "Train Acc:99.92%, Test Acc:98.09%\n",
      "\n",
      "Class: 5 -> Train Acc 99.98198198198199 ; Test Acc 98.65470852017937 \n",
      "\n",
      "6\n",
      "Epoch: 0:200,  Loss:1.886164903640747\n",
      "Train Acc:50.19%, Test Acc:51.57%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.3168736696243286\n",
      "Train Acc:83.46%, Test Acc:88.36%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.31801512837409973\n",
      "Train Acc:92.78%, Test Acc:93.37%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.29357415437698364\n",
      "Train Acc:95.44%, Test Acc:95.35%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.27435728907585144\n",
      "Train Acc:97.12%, Test Acc:97.03%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.19470718502998352\n",
      "Train Acc:97.60%, Test Acc:97.34%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.13334447145462036\n",
      "Train Acc:97.90%, Test Acc:97.49%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.14695793390274048\n",
      "Train Acc:98.37%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.13995271921157837\n",
      "Train Acc:98.95%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.12059754133224487\n",
      "Train Acc:99.13%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10112027078866959\n",
      "Train Acc:99.22%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.16122756898403168\n",
      "Train Acc:99.60%, Test Acc:98.54%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.11101140081882477\n",
      "Train Acc:99.44%, Test Acc:98.43%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.15291030704975128\n",
      "Train Acc:99.37%, Test Acc:98.70%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.11063946038484573\n",
      "Train Acc:99.60%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.09053581953048706\n",
      "Train Acc:99.50%, Test Acc:98.96%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.14217308163642883\n",
      "Train Acc:99.76%, Test Acc:98.80%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12771230936050415\n",
      "Train Acc:99.73%, Test Acc:99.01%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.12517131865024567\n",
      "Train Acc:100.00%, Test Acc:98.59%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.10972505807876587\n",
      "Train Acc:99.79%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.1016172245144844\n",
      "Train Acc:99.82%, Test Acc:98.90%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.1157144233584404\n",
      "Train Acc:99.96%, Test Acc:99.11%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.13653889298439026\n",
      "Train Acc:100.00%, Test Acc:99.16%\n",
      "\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.16492693110646 \n",
      "\n",
      "7\n",
      "Epoch: 0:200,  Loss:0.8889394998550415\n",
      "Train Acc:50.34%, Test Acc:52.87%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.4139295518398285\n",
      "Train Acc:83.83%, Test Acc:89.25%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.34211960434913635\n",
      "Train Acc:93.06%, Test Acc:93.82%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.21423709392547607\n",
      "Train Acc:95.96%, Test Acc:95.82%\n",
      "\n",
      "Epoch: 3:1000,  Loss:0.1873602271080017\n",
      "Train Acc:97.11%, Test Acc:97.13%\n",
      "\n",
      "Epoch: 4:1200,  Loss:0.15985246002674103\n",
      "Train Acc:97.74%, Test Acc:97.23%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.17185325920581818\n",
      "Train Acc:98.46%, Test Acc:97.52%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.16272570192813873\n",
      "Train Acc:98.70%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.1725895255804062\n",
      "Train Acc:98.51%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 7:2000,  Loss:0.15154984593391418\n",
      "Train Acc:98.84%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 8:2200,  Loss:0.1227782666683197\n",
      "Train Acc:99.00%, Test Acc:97.47%\n",
      "\n",
      "Epoch: 9:2400,  Loss:0.15364371240139008\n",
      "Train Acc:99.19%, Test Acc:97.71%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.13791465759277344\n",
      "Train Acc:99.47%, Test Acc:97.91%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.10041652619838715\n",
      "Train Acc:99.59%, Test Acc:97.71%\n",
      "\n",
      "Epoch: 11:3000,  Loss:0.10215585678815842\n",
      "Train Acc:99.42%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 12:3200,  Loss:0.16127197444438934\n",
      "Train Acc:99.49%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 13:3400,  Loss:0.11378076672554016\n",
      "Train Acc:99.69%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 14:3600,  Loss:0.11155922710895538\n",
      "Train Acc:99.88%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.13135471940040588\n",
      "Train Acc:99.83%, Test Acc:97.81%\n",
      "\n",
      "Epoch: 15:4000,  Loss:0.08643238246440887\n",
      "Train Acc:99.71%, Test Acc:97.91%\n",
      "\n",
      "Epoch: 16:4200,  Loss:0.12680494785308838\n",
      "Train Acc:99.80%, Test Acc:97.86%\n",
      "\n",
      "Epoch: 17:4400,  Loss:0.10595368593931198\n",
      "Train Acc:99.88%, Test Acc:97.96%\n",
      "\n",
      "Epoch: 18:4600,  Loss:0.12878453731536865\n",
      "Train Acc:99.83%, Test Acc:98.10%\n",
      "\n",
      "Epoch: 19:4800,  Loss:0.11555788666009903\n",
      "Train Acc:99.74%, Test Acc:98.35%\n",
      "\n",
      "Epoch: 19:5000,  Loss:0.11635084450244904\n",
      "Train Acc:99.88%, Test Acc:97.91%\n",
      "\n",
      "Class: 7 -> Train Acc 99.88372093023256 ; Test Acc 98.34630350194551 \n",
      "\n",
      "8\n",
      "Epoch: 0:200,  Loss:1.8536784648895264\n",
      "Train Acc:49.99%, Test Acc:50.00%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.5378556251525879\n",
      "Train Acc:77.04%, Test Acc:84.70%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.4654370844364166\n",
      "Train Acc:88.31%, Test Acc:89.89%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.2972230613231659\n",
      "Train Acc:92.04%, Test Acc:92.09%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.3285243511199951\n",
      "Train Acc:94.77%, Test Acc:94.87%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.2333819419145584\n",
      "Train Acc:96.72%, Test Acc:95.89%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.17588165402412415\n",
      "Train Acc:96.83%, Test Acc:96.56%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.17870594561100006\n",
      "Train Acc:97.32%, Test Acc:97.33%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.23950998485088348\n",
      "Train Acc:97.78%, Test Acc:97.13%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.17750780284404755\n",
      "Train Acc:98.52%, Test Acc:96.92%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.11202436685562134\n",
      "Train Acc:98.87%, Test Acc:97.23%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.15657056868076324\n",
      "Train Acc:99.12%, Test Acc:97.54%\n",
      "\n",
      "Epoch: 11:2600,  Loss:0.0981847271323204\n",
      "Train Acc:99.07%, Test Acc:97.48%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.14158953726291656\n",
      "Train Acc:99.27%, Test Acc:97.79%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.18086595833301544\n",
      "Train Acc:99.31%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1638341099023819\n",
      "Train Acc:99.71%, Test Acc:97.90%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.1493006944656372\n",
      "Train Acc:99.76%, Test Acc:98.05%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.14247408509254456\n",
      "Train Acc:99.76%, Test Acc:97.69%\n",
      "\n",
      "Epoch: 16:3800,  Loss:0.12181970477104187\n",
      "Train Acc:99.70%, Test Acc:97.84%\n",
      "\n",
      "Epoch: 17:4000,  Loss:0.1419197916984558\n",
      "Train Acc:97.20%, Test Acc:97.28%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17:4200,  Loss:0.11203169822692871\n",
      "Train Acc:99.21%, Test Acc:97.95%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.13841086626052856\n",
      "Train Acc:99.54%, Test Acc:97.54%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.12653276324272156\n",
      "Train Acc:99.76%, Test Acc:97.18%\n",
      "\n",
      "Class: 8 -> Train Acc 99.76363636363637 ; Test Acc 98.04928131416838 \n",
      "\n",
      "9\n",
      "Epoch: 0:200,  Loss:3.8268680572509766\n",
      "Train Acc:50.65%, Test Acc:58.92%\n",
      "\n",
      "Epoch: 1:400,  Loss:0.39498671889305115\n",
      "Train Acc:84.62%, Test Acc:89.54%\n",
      "\n",
      "Epoch: 2:600,  Loss:0.39874622225761414\n",
      "Train Acc:91.58%, Test Acc:92.77%\n",
      "\n",
      "Epoch: 3:800,  Loss:0.2958671748638153\n",
      "Train Acc:94.65%, Test Acc:93.95%\n",
      "\n",
      "Epoch: 4:1000,  Loss:0.18153978884220123\n",
      "Train Acc:96.38%, Test Acc:95.44%\n",
      "\n",
      "Epoch: 5:1200,  Loss:0.16779470443725586\n",
      "Train Acc:97.60%, Test Acc:96.33%\n",
      "\n",
      "Epoch: 5:1400,  Loss:0.24734318256378174\n",
      "Train Acc:97.24%, Test Acc:96.63%\n",
      "\n",
      "Epoch: 6:1600,  Loss:0.1678840070962906\n",
      "Train Acc:97.92%, Test Acc:97.08%\n",
      "\n",
      "Epoch: 7:1800,  Loss:0.15801995992660522\n",
      "Train Acc:98.22%, Test Acc:97.22%\n",
      "\n",
      "Epoch: 8:2000,  Loss:0.13928534090518951\n",
      "Train Acc:98.56%, Test Acc:97.18%\n",
      "\n",
      "Epoch: 9:2200,  Loss:0.10926856100559235\n",
      "Train Acc:98.69%, Test Acc:97.27%\n",
      "\n",
      "Epoch: 10:2400,  Loss:0.16719423234462738\n",
      "Train Acc:98.80%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 10:2600,  Loss:0.13561980426311493\n",
      "Train Acc:98.95%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 11:2800,  Loss:0.15182486176490784\n",
      "Train Acc:99.00%, Test Acc:97.62%\n",
      "\n",
      "Epoch: 12:3000,  Loss:0.18733413517475128\n",
      "Train Acc:99.47%, Test Acc:97.97%\n",
      "\n",
      "Epoch: 13:3200,  Loss:0.1155623123049736\n",
      "Train Acc:99.45%, Test Acc:98.07%\n",
      "\n",
      "Epoch: 14:3400,  Loss:0.12451344728469849\n",
      "Train Acc:99.47%, Test Acc:97.87%\n",
      "\n",
      "Epoch: 15:3600,  Loss:0.12408740073442459\n",
      "Train Acc:99.80%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 15:3800,  Loss:0.12669669091701508\n",
      "Train Acc:99.68%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 16:4000,  Loss:0.1032940000295639\n",
      "Train Acc:99.75%, Test Acc:98.17%\n",
      "\n",
      "Epoch: 17:4200,  Loss:0.12818732857704163\n",
      "Train Acc:99.75%, Test Acc:97.92%\n",
      "\n",
      "Epoch: 18:4400,  Loss:0.1188657209277153\n",
      "Train Acc:99.69%, Test Acc:97.82%\n",
      "\n",
      "Epoch: 19:4600,  Loss:0.11819127947092056\n",
      "Train Acc:99.56%, Test Acc:97.77%\n",
      "\n",
      "Class: 9 -> Train Acc 99.8 ; Test Acc 98.16650148662042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_per_class = []\n",
    "net_list = []\n",
    "for class_idx in range(10):\n",
    "    print(class_idx)\n",
    "    train_dataset = MNIST_OneClass_Balanced(train_data, train_label, class_idx)\n",
    "    test_dataset = MNIST_OneClass_Balanced(test_data, test_label, class_idx)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch.manual_seed(network_seed)\n",
    "    Net = InvexInvertible_MNIST()\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    index = 0\n",
    "    for epoch in range(20):\n",
    "        train_acc = 0\n",
    "        train_count = 0\n",
    "        for xx, yy in train_loader:\n",
    "            index += 1\n",
    "\n",
    "            if use_mixup:\n",
    "                rand_indx = np.random.permutation(len(xx))\n",
    "                rand_lambda = 1-torch.rand(len(xx), 1)*0.1\n",
    "                x_mix = rand_lambda*xx+(1-rand_lambda)*xx[rand_indx]\n",
    "                y_mix = rand_lambda*yy+(1-rand_lambda)*yy[rand_indx]\n",
    "            else:\n",
    "                x_mix = xx\n",
    "                y_mix = yy\n",
    "\n",
    "            yout = sigmoid(Net(x_mix))    \n",
    "            loss = criterion(yout, y_mix)\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "            preds = (yy.data.cpu().numpy() > 0.5).astype(float)\n",
    "            correct = (outputs == preds).astype(float).sum()\n",
    "            train_acc += correct\n",
    "            train_count += len(outputs)\n",
    "\n",
    "            if index%200 == 0:\n",
    "                train_accs.append(float(train_acc)/train_count*100)\n",
    "                train_acc = 0\n",
    "                train_count = 0\n",
    "\n",
    "                print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "                test_count = 0\n",
    "                test_acc = 0\n",
    "                for xx, yy in test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        yout = sigmoid(Net(xx))\n",
    "                    outputs = (yout.data.cpu().numpy() > 0.5).astype(float)\n",
    "                    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                    test_acc += correct\n",
    "                    test_count += len(xx)\n",
    "                test_accs.append(float(test_acc)/test_count*100)\n",
    "                print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "                print()\n",
    "                \n",
    "    ### after each class index is finished training\n",
    "    stat_per_class.append(\n",
    "    f'Class: {class_idx} -> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}'\n",
    "    )\n",
    "    print(stat_per_class[-1], '\\n')\n",
    "    net_list.append(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 -> Train Acc 100.0 ; Test Acc 99.48979591836735\n",
      "Class: 1 -> Train Acc 100.0 ; Test Acc 99.51541850220265\n",
      "Class: 2 -> Train Acc 100.0 ; Test Acc 99.03100775193798\n",
      "Class: 3 -> Train Acc 99.92727272727274 ; Test Acc 98.31683168316832\n",
      "Class: 4 -> Train Acc 100.0 ; Test Acc 99.03258655804481\n",
      "Class: 5 -> Train Acc 99.98198198198199 ; Test Acc 98.65470852017937\n",
      "Class: 6 -> Train Acc 100.0 ; Test Acc 99.16492693110646\n",
      "Class: 7 -> Train Acc 99.88372093023256 ; Test Acc 98.34630350194551\n",
      "Class: 8 -> Train Acc 99.76363636363637 ; Test Acc 98.04928131416838\n",
      "Class: 9 -> Train Acc 99.8 ; Test Acc 98.16650148662042\n",
      "Total Accuracy (Argmax) is : 0.9725000262260437\n"
     ]
    }
   ],
   "source": [
    "## find the classification error from classification per class network.\n",
    "acc_test = 0\n",
    "count_test = 0\n",
    "with torch.no_grad():\n",
    "    for index in range(len(test_label) // batch_size):\n",
    "        xx = test_data[index * batch_size:(index + 1) * batch_size]\n",
    "        yy = test_label[index * batch_size:(index + 1) * batch_size]\n",
    "        yout = []\n",
    "        for net in net_list:\n",
    "            yout.append(sigmoid(net(xx)).reshape(-1))\n",
    "        yout = torch.stack(yout, dim=1).argmax(dim=1)\n",
    "        acc = (yout == yy).type(torch.float32).sum()\n",
    "        count_test += len(xx)\n",
    "        acc_test += acc\n",
    "        \n",
    "for s in stat_per_class:\n",
    "    print(s)\n",
    "print(f\"Total Accuracy (Argmax) is : {float(acc_test/count_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477758"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5, figsize=(10,4))\n",
    "for i in range(10):\n",
    "    invNet = net_list[i]\n",
    "    invertible = SequentialFlow([*invNet.model[:-1]])## excluding distance regressor\n",
    "    icenter = invertible.inverse(invNet.model[-1].centers.data)\n",
    "    j, k = i//5, i%5\n",
    "#     print(i, j, k)\n",
    "    axs[j,k].imshow(icenter.data.cpu().reshape(28, 28))\n",
    "    axs[j,k].set_title(f\"{i}\")\n",
    "    axs[j,k].set_axis_off()\n",
    "# fig.tight_layout()\n",
    "plt.savefig(\"./invex_out/MNIST_InvertibleInvex_mlp_centroids.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
